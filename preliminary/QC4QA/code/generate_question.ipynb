{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "293f29f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_generation_prompt = \"\"\"\n",
    "Given the context, generate a question based on the specified question type (ABBR, DESC, ENTY, HUM, LOC, NUM). \n",
    "\n",
    "Question Type: ABBR (Abbreviation)\n",
    "Example: \n",
    "  Input: \"NASA is the United States government agency responsible for the civilian space program.\"\n",
    "  Output: \"What does the abbreviation 'NASA' stand for?\"\n",
    "  \n",
    "Question Type: DESC (Description)\n",
    "Example: \n",
    "  Input: \"Photosynthesis is the process by which green plants use sunlight to synthesize foods from carbon dioxide and water.\"\n",
    "  Output: \"Can you describe the process of photosynthesis?\"\n",
    "\n",
    "Question Type: ENTY (Entity)\n",
    "Example: \n",
    "  Input: \"Albert Einstein was a theoretical physicist who developed the theory of relativity.\"\n",
    "  Output: \"Who was Albert Einstein?\"\n",
    "\n",
    "Question Type: HUM (Human)\n",
    "Example: \n",
    "  Input: \"The first president of the United States was George Washington.\"\n",
    "  Output: \"Who was the first president of the United States?\"\n",
    "\n",
    "Question Type: LOC (Location)\n",
    "Example: \n",
    "  Input: \"The Eiffel Tower is located in Paris, France.\"\n",
    "  Output: \"Where is the Eiffel Tower located?\"\n",
    "\n",
    "Question Type: NUM (Number)\n",
    "Example: \n",
    "  Input: \"There are seven continents on Earth.\"\n",
    "  Output: \"How many continents are there on Earth?\"\n",
    "\n",
    "Input: [target_context]\n",
    "Output: [generated_question]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9bdcd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gayeon39/miniconda3/envs/da/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['-- two of the most influential papers for voters in Iowa and New Hampshire -- the first two states to weigh in at the polls in 2008 -- both endorsed John McCain in the GOP presidential race , but differed in their choice in the Democratic contest . the Register backs Hillary Clinton , while the Globe picks Obama . the Register backed Hillary Clinton , while the Globe picked Obama , in excerpts of sunday \\'s editorials posted on their papers \\' web sites saturday night . the Iowa caucuses are january 3 , and New Hampshire \\'s primary follows five days later . the Globe \\'s editorial board dismissed concerns over the Illinois senator \\'s relative lack of Washington experience . \" it is true that all the other Democratic contenders have more conventional resumes , and have spent more time in Washington , \" the board wrote . \" but that exposure has tended to give them a sense of government \\'s constraints . Obama is more open to its possibilities . \" but the Register \\'s editorial board -- which noted that Obama \" demonstrates the potential to be a fine president \" -- still gave the edge to the senator from New York , saying it made the nods in both parties \\' primaries based on competence and readiness to lead . \" when Obama speaks before a crowd , he can be more inspirational than Clinton , \" the board wrote . \" yet , with his relative inexperience , it \\'s hard to feel as confident he could accomplish the daunting agenda that lies ahead . \" the Iowa paper \\'s endorsement is widely viewed as a major boost for Clinton , and a blow to the campaign of former North Carolina sen. Edwards , whose register endorsement during the 2004 race was followed by a surprisingly strong showing in the state \\'s Democratic caucuses . Obama spokesman Robert Gibbs told CNN \\'s Mike Roselli that the campaign was \" not surprised \" by the Register \\'s decision , adding \" that it was a bigger surprise to get the Globe \\'s , \" and noting that the Register paper \" said good things about us . \" Obama told CNN , \" i think we are doing pretty good . we split it today between the Globe and the Register . \" the Clinton campaign immediately sent out a news release containing the full text of the paper \\'s endorsement , which took Edwards to task for recent campaign trail rhetoric , writing that \" we too seldom saw the \\' positive , optimistic \\' campaign we found appealing in 2004 . \" \" Obama , [ Clinton \\'s ] chief rival , inspired our imaginations , \" the Register board wrote . \" but it was Clinton who inspired our confidence . \" Clinton spokesman Daley told CNN \\'s Suzanne Malveaux that the campaign is incredibly pleased and honored . \" but we know we have a few weeks left to go before the caucuses and a lot of work to do , \" Daley said , adding that after Clinton \\'s thursday debate performance , her friday endorsement by Iowa \\'s Democratic rep. Leonard Boswell and saturday \\'s Register nod , \" we feel good about our campaign heading into the final weeks . \" the three Democratic are battling for the lead in Iowa , placing within just a few points of one another in most recent state polls . watch a report about who might win in Iowa » on the GOP side , the Register \\'s board wrote that the endorsement went to the senator from Arizona because \" time after time , John McCain has stuck to his beliefs in the face of opposition from other elected leaders and the public . \" the force of John McCain \\'s moral authority could go a long way toward restoring United States \\' trust in government and inspiring new generations to believe in the goodness and greatness of United States , \" they wrote . meanwhile , the Globe \\'s board passed over former Massachusetts gov. Mitt Romney , saying that while John McCain \\'s views might differ from theirs , his \" honesty has served him well . \" \" as a lawmaker and as a candidate , he has done more than his share to transcend partisanship and promote an honest discussion of the problems facing the United States , \" the board wrote . in 2004 , the newspaper stuck with the native son on the ballot , giving the nod in the Democratic primary to Massachusetts sen. John Kerry , who went on to win the New Hampshire primary . the Globe \\'s endorsements are influential in neighboring New Hampshire , especially the southern part of the state , where many residents make the daily weekday commute to work in Boston . and the endorsement weighs even greater with Democratic voters there , since the state \\'s main newspaper -- the New Hampshire Union Leader -- has a conservative editorial board and makes only one primary endorsement , which is almost always a GOP . John McCain \\'s Globe endorsement follows a recent nod from the New Hampshire Union Leader . political pundits almost left John McCain for dead this summer , after his campaign nearly ran out of cash and hemorrhaged staff , and the candidate sank in the polls . now , the senator is in second place or tied for second in the most recent New Hampshire polls . John McCain won New Hampshire \\'s GOP primary during his 2000 presidential run . e-mail to a friend CNN \\'s Suzanne Malveaux and Mark Preston contributed to this report .\\n',\n",
       " '-- federal agents say a missing New Jersey woman may be one of 11 victims believed to have been slain by admitted serial killer Israel Keyes . investigators believe the woman Debra Feldman , 49 , was last seen at her Hackensack home on april 8 , 2009 . she has not been heard from since . the FBI said Keyes admitted that on april 9 , 2009 , he abducted a female from a state on the East Coast and transported her over multiple state lines into New York . Keyes said he killed the victim and buried her in upstate New York . FBI special agent Woodruff told CNN thursday that Keyes -- before he committed suicide last year -- was shown pictures of unsolved murder victims and people who had gone missing to see whether he would admit to being involved in any of those cases . when Keyes was shown a picture of Debra Feldman , he paused , looking at it a long time , before saying , \" i \\'m not ready to talk about that one , \" according to Woodruff . footage on the FBI website shows Keyes during the interviews with federal agents , telling them he would release certain information or details about his victims , and then changing his mind . detailed interactive map of Keyes \\' travels \" he did enjoy the cat and mouse game , \" Woodruff said . Keyes committed suicide in his Alaska jail cell last december by slitting his wrist and strangling himself with bedding . investigators described Keyes as a kind of a murder addict who hunted victims in remote locations such as parks , campgrounds or hiking trails . an Army veteran and traveling contractor , Keyes studied other serial killers , but liked to say that he had not patterned himself after any other killer . serial killer a murder addict a multi-agency effort by the Anchorage police , the FBI and local law enforcement agencies in Lufkin , Texas , arrested Keyes in march 2012 for the abduction of Samantha Koenig , an 18 - year - old barista . her body was found in a lake in april 2012 . Keyes left many unanswered questions and a four - page note that expressed no remorse or clues to other slayings when he took his life . authorities are asking that anyone who may have information about Keyes or Debra Feldman , or information about her around the time of her disappearance to contact the Hackensack Police Department or call 1 - 800 - call - FBI . CNN \\'s Matt Smith , Mayra Cuevas and Brad Lendon contributed to this report\\n',\n",
       " '-- New York City officials are preparing to transport more than 150,000 students after a school bus drivers union announced that it is planning to strike this wednesday if an agreement ca n\\'t be reached . Union officials representing Amalgamated Transit Union Local 1181 , who are seeking job security , announced monday afternoon that they plan to strike on wednesday if they ca n\\'t reach a suitable agreement with the city . mayor Bloomberg bid out contracts for nearly 1,100 bus routes currently handled by local 1181 drivers . last year , the city bid out contracts for preschool bus routes , and the new contracts will save taxpayers $ 95 million over five years . Bloomberg on monday urged the union to avoid going on strike and added that a strike would \" jeopardize the education and safety of more than 150,000 students who take school buses every single day , in a year when our students have already missed a week or more of school because of Hurricane Sandy . \"\\n']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"NCCL_P2P_DISABLE\"] = \"1\"\n",
    "os.environ[\"NCCL_IB_DISABLE\"] = \"1\"\n",
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, TrainingArguments, Trainer, DataCollatorForSeq2Seq\n",
    "from datasets import load_dataset, Dataset\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "train_squad_path = '/home/gayeon39/gayeon/[DA]/model/QC4QA/data/squad/train-v1.1_classified.json'\n",
    "dev_squad_path = '/home/gayeon39/gayeon/[DA]/model/QC4QA/data/squad/dev-v1.1.json'\n",
    "train_cnn_path = '/home/gayeon39/gayeon/[DA]/model/QC4QA/data/target/cnn_train_classified.json'\n",
    "dev_cnn_path = '/home/gayeon39/gayeon/[DA]/model/QC4QA/data/target/cnn_dev.json'\n",
    "\n",
    "with open(train_squad_path, 'r') as f:\n",
    "    train_squad_data = json.load(f)\n",
    "with open(dev_squad_path, 'r') as f:\n",
    "    dev_squad_data = json.load(f)\n",
    "with open(train_cnn_path, 'r') as f:\n",
    "    train_cnn_data = json.load(f)\n",
    "with open(dev_cnn_path, 'r') as f:\n",
    "    dev_cnn_data = json.load(f)\n",
    "    \n",
    "target_context = []\n",
    "for article in train_cnn_data['data']:\n",
    "    for para in article['paragraphs']:\n",
    "        target_context.append(para['context'])\n",
    "target_context[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "036df5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "/home/gayeon39/miniconda3/envs/da/lib/python3.12/site-packages/accelerate/utils/modeling.py:1614: UserWarning: The following device_map keys do not match any submodules in the model: ['decoder.embed_tokens', 'encoder.embed_tokens']\n",
      "  warnings.warn(\n",
      "We've detected an older driver with an RTX 4000 series GPU. These drivers have issues with P2P. This can affect the multi-gpu inference when using accelerate device_map.Please make sure to update your driver to the latest version which resolves this.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load base model (FLAN-T5)\n",
    "model_name = \"google/flan-t5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=torch.float16)\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\"\n",
    ")\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb68c1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 6/6 [00:00<00:00, 589.34 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Prepare the dataset\n",
    "def create_prompt(input_text, question_type):\n",
    "    # Define the prompt format for each question type\n",
    "    prompt = f\"\"\"\n",
    "    Given the context, generate a question based on the specified question type ({question_type}).\n",
    "    \n",
    "    Question Type: {question_type}\n",
    "    Example: \n",
    "      Input: \"{input_text}\"\n",
    "      Output: [generated_question]\n",
    "    \"\"\"\n",
    "    return prompt.strip()\n",
    "\n",
    "# Sample data for fine-tuning (you can replace this with your own dataset)\n",
    "data = [\n",
    "    {\n",
    "        \"target_context\": \"NASA is the United States government agency responsible for the civilian space program.\",\n",
    "        \"question_type\": \"ABBR\",\n",
    "        \"generated_question\": \"What does the abbreviation 'NASA' stand for?\"\n",
    "    },\n",
    "    {\n",
    "        \"target_context\": \"Photosynthesis is the process by which green plants use sunlight to synthesize foods from carbon dioxide and water.\",\n",
    "        \"question_type\": \"DESC\",\n",
    "        \"generated_question\": \"Can you describe the process of photosynthesis?\"\n",
    "    },\n",
    "    {\n",
    "        \"target_context\": \"Albert Einstein was a theoretical physicist who developed the theory of relativity.\",\n",
    "        \"question_type\": \"ENTY\",\n",
    "        \"generated_question\": \"Who was Albert Einstein?\"\n",
    "    },\n",
    "    {\n",
    "        \"target_context\": \"The first president of the United States was George Washington.\",\n",
    "        \"question_type\": \"HUM\",\n",
    "        \"generated_question\": \"Who was the first president of the United States?\"\n",
    "    },\n",
    "    {\n",
    "        \"target_context\": \"The Eiffel Tower is located in Paris, France.\",\n",
    "        \"question_type\": \"LOC\",\n",
    "        \"generated_question\": \"Where is the Eiffel Tower located?\"\n",
    "    },\n",
    "    {\n",
    "        \"target_context\": \"There are seven continents on Earth.\",\n",
    "        \"question_type\": \"NUM\",\n",
    "        \"generated_question\": \"How many continents are there on Earth?\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Step 3: Tokenize the data\n",
    "def tokenize_data(example):\n",
    "    prompt = create_prompt(example[\"target_context\"], example[\"question_type\"])\n",
    "    inputs = tokenizer(prompt, padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    targets = tokenizer(example[\"generated_question\"], padding=\"max_length\", truncation=True, max_length=64, return_tensors=\"pt\")\n",
    "    return {\"input_ids\": inputs[\"input_ids\"].squeeze(), \"attention_mask\": inputs[\"attention_mask\"].squeeze(), \"labels\": targets[\"input_ids\"].squeeze()}\n",
    "\n",
    "# Convert data into a Dataset object\n",
    "dataset = Dataset.from_pandas(pd.DataFrame(data))\n",
    "\n",
    "# Apply the tokenizer to the dataset\n",
    "tokenized_dataset = dataset.map(tokenize_data, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fd9cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3403160/1853238094.py:30: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:01, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 4: Define training arguments\n",
    "# args = TrainingArguments(\n",
    "#     output_dir=\"./results\",         # Output directory for model checkpoints\n",
    "#     learning_rate=5e-5,             # Learning rate\n",
    "#     per_device_train_batch_size=8,  # Batch size\n",
    "#     per_device_eval_batch_size=8,   # Evaluation batch size\n",
    "#     num_train_epochs=10,             # Number of training epochs\n",
    "#     save_steps=10_000,              # Save model checkpoints every 10,000 steps\n",
    "#     save_total_limit=2,             # Keep only the last 2 checkpoints\n",
    "#     logging_dir=\"./logs\",           # Log directory\n",
    "#     logging_steps=500,              # Log every 500 steps\n",
    "# )\n",
    "args = TrainingArguments(\n",
    "output_dir=\"./flan_t5_domain_qa\",\n",
    "    per_device_train_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=5e-4,\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2,\n",
    "    fp16=True,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# Step 5: Train the model using the Trainer API\n",
    "trainer = Trainer(\n",
    "    model=model,                    # Model to train\n",
    "    args=args,              # Training arguments\n",
    "    train_dataset=tokenized_dataset, # Training dataset\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    ")\n",
    "\n",
    "# Start the training\n",
    "trainer.train()\n",
    "trainer.save_model(\"./fine_tuned_t5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93919dd",
   "metadata": {},
   "source": [
    "- Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d387f177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the fine-tuned model and tokenizer\n",
    "model_name = \"./fine_tuned_t5\"  \n",
    "# model_name = \"./results/checkpoint-10\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba27d88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Question: What was Albert Einstein's occupation?\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Define a function to generate questions based on the context and question type\n",
    "def generate_question(context, question_type):\n",
    "    # Create the prompt for the T5 model\n",
    "    prompt = f\"\"\"\n",
    "    Given the context, generate a question based on the specified question type ({question_type}).\n",
    "\n",
    "    Question Type: {question_type}\n",
    "    Example: \n",
    "      Input: \"{context}\"\n",
    "      Output: [generated_question]\n",
    "    \"\"\"\n",
    "\n",
    "    # Tokenize the prompt\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "    # Generate the question using the model\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"], \n",
    "        attention_mask=inputs[\"attention_mask\"], \n",
    "        max_length=64,  # Limit the length of the generated question\n",
    "        num_beams=4,    # Use beam search for better quality\n",
    "        early_stopping=True\n",
    "    )\n",
    "\n",
    "    # Decode the generated question\n",
    "    generated_question = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return generated_question\n",
    "\n",
    "# Step 3: Test with an example context\n",
    "context = \"Albert Einstein was a theoretical physicist who developed the theory of relativity.\"\n",
    "question_type = \"ENTY\"  # Choose the question type (ABBR, DESC, ENTY, HUM, LOC, NUM)\n",
    "\n",
    "# Generate the question\n",
    "generated_question = generate_question(context, question_type)\n",
    "\n",
    "# Print the generated question\n",
    "print(f\"Generated Question: {generated_question}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebd2d533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question Type: DESC\n",
      "Context: Shakespeare was an English playwright and poet. He is widely regarded as one of the greatest writers in the English language.\n",
      "Generated Question: What is the full name of the person who wrote Shakespeare?\n",
      "--------------------------------------------------\n",
      "Context: The Amazon River is the largest river in the world by discharge of water. It flows through South America, primarily in Brazil.\n",
      "Generated Question: What is the largest river in the world by discharge of water?\n",
      "--------------------------------------------------\n",
      "Question Type: ENTY\n",
      "Context: Shakespeare was an English playwright and poet. He is widely regarded as one of the greatest writers in the English language.\n",
      "Generated Question: What was Shakespeare's occupation?\n",
      "--------------------------------------------------\n",
      "Context: The Amazon River is the largest river in the world by discharge of water. It flows through South America, primarily in Brazil.\n",
      "Generated Question: What is the largest river in the world by discharge of water?\n",
      "--------------------------------------------------\n",
      "Question Type: ABBR\n",
      "Context: Shakespeare was an English playwright and poet. He is widely regarded as one of the greatest writers in the English language.\n",
      "Generated Question: What is the name of Shakespeare's most famous play?\n",
      "--------------------------------------------------\n",
      "Context: The Amazon River is the largest river in the world by discharge of water. It flows through South America, primarily in Brazil.\n",
      "Generated Question: What is the largest river in the world by discharge of water?\n",
      "--------------------------------------------------\n",
      "Question Type: HUM\n",
      "Context: Shakespeare was an English playwright and poet. He is widely regarded as one of the greatest writers in the English language.\n",
      "Generated Question: What is the name of Shakespeare's most famous play?\n",
      "--------------------------------------------------\n",
      "Context: The Amazon River is the largest river in the world by discharge of water. It flows through South America, primarily in Brazil.\n",
      "Generated Question: What is the largest river in the world by discharge of water?\n",
      "--------------------------------------------------\n",
      "Question Type: LOC\n",
      "Context: Shakespeare was an English playwright and poet. He is widely regarded as one of the greatest writers in the English language.\n",
      "Generated Question: What is the name of Shakespeare's most famous play?\n",
      "--------------------------------------------------\n",
      "Context: The Amazon River is the largest river in the world by discharge of water. It flows through South America, primarily in Brazil.\n",
      "Generated Question: What is the largest river in the world by discharge of water?\n",
      "--------------------------------------------------\n",
      "Question Type: NUM\n",
      "Context: Shakespeare was an English playwright and poet. He is widely regarded as one of the greatest writers in the English language.\n",
      "Generated Question: What is the name of Shakespeare's most famous play?\n",
      "--------------------------------------------------\n",
      "Context: The Amazon River is the largest river in the world by discharge of water. It flows through South America, primarily in Brazil.\n",
      "Generated Question: What is the largest river in the world by discharge of water?\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "question_type_list = ['DESC', 'ENTY', 'ABBR', 'HUM', 'LOC', 'NUM']\n",
    "# context_list = [\n",
    "#     \"NASA is the United States government agency responsible for the civilian space program.\",\n",
    "#     \"Albert Einstein was a theoretical physicist who developed the theory of relativity.\",\n",
    "#     \"The Eiffel Tower is located in Paris, France.\",]\n",
    "context_list = [\n",
    "    \"Shakespeare was an English playwright and poet. He is widely regarded as one of the greatest writers in the English language.\",\n",
    "    \"The Amazon River is the largest river in the world by discharge of water. It flows through South America, primarily in Brazil.\"]\n",
    "\n",
    "for i in question_type_list:\n",
    "    print(f\"Question Type: {i}\")\n",
    "    for j in context_list:\n",
    "        print(f\"Context: {j}\")\n",
    "        print(f\"Generated Question: {generate_question(j, i)}\")\n",
    "        print('-'*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "da",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
