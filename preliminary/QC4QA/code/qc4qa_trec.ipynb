{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44907461",
   "metadata": {},
   "source": [
    "- 데이터 파일을 읽어 질문과 ID를 추출\n",
    "- InferSent 모델 및 Google USE 임베딩 함수 준비\n",
    "- 분류기(MLP) 모델 로드\n",
    "- 질문을 배치 단위로 임베딩 생성 → 분류기 예측 → 질문 유형(q_type) 리스트 생성\n",
    "- 결과를 원본 데이터에 반영하여 새 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343589cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQuAD 데이터 형식\n",
    "## - data: 문서 리스트\n",
    "##   - title: 문서 제목\n",
    "##   - paragraphs: 문서 내 단락 리스트\n",
    "##     - context: 단락 텍스트\n",
    "##     - qas: 단락 내 질문 리스트\n",
    "##       - question: 질문 텍스트\n",
    "##       - id: 질문 ID\n",
    "##       - answers: 정답 리스트\n",
    "##         - text: 정답 텍스트\n",
    "##         - answer_start: 정답 시작 위치(인덱스)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fefcdd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 14:25:16.056037: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "from __future__ import absolute_import, division\n",
    "from tensorflow.python.framework.ops import enable_eager_execution\n",
    "enable_eager_execution()\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import json\n",
    "import torch\n",
    "import nltk\n",
    "import numpy as np\n",
    "import re\n",
    "from infersent import InferSent\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.logging.set_verbosity(0)\n",
    "import tensorflow_hub as hub\n",
    "# nltk.download('punkt_tab')\n",
    "\n",
    "# Set PATHs\n",
    "PATH_SENTEVAL = '../SentEval'  # specify SentEval root if not installed\n",
    "PATH_TO_DATA = ''  # not necessary for inference\n",
    "MODEL_VERSION = 1\n",
    "# 300차원의 사전 단어 임베딩 벡터\n",
    "PATH_TO_W2V = '../SentEval/glove/glove.840B.300d.txt' if MODEL_VERSION == 1 else '../SentEval/fasttext/crawl-300d-2M.vec'\n",
    "# 사전 학습된 임베딩 모델 Infersent1\n",
    "MODEL_PATH = \"../SentEval/encoder/infersent%s.pkl\" % MODEL_VERSION\n",
    "V = 1 # version of InferSent\n",
    "\n",
    "## glove.txt: 각 단어를 300차원의 벡터로 표현하는 사전 임베딩 파일\n",
    "# ->infersent모델이 입력 문장 임베딩할 때, 각 단어 벡터로 변환에 사용\n",
    "## infersent1.pkl: 사전 학습된 문장 임베딩 모델의 가중치 파일\n",
    "# ->여러 단어 임베딩(GloVe)받아 문장 전체의 의미를 하나의 벡터로 변환\n",
    "# -> GloVe:단어를 벡터로 / InferSent:문장을 벡터로\n",
    "\n",
    "sys.path.insert(0, PATH_SENTEVAL)\n",
    "import senteval\n",
    "from senteval.tools.classifier import MLP\n",
    "\n",
    "# 경로(폴더 위치), 현재 작업 경로\n",
    "# os.getcwd()\n",
    "# 모듈 찾을 때 참조하는 경로 리스트, 상대 경로 해석(sys.path.insert로 수정)\n",
    "# sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22bb6645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadFile(fpath):\n",
    "    \"\"\"\n",
    "    MRQA 스타일 데이터 파일을 읽어 질문과 질문 ID를 추출\n",
    "    파일 한 줄씩 읽어 JSON으로 파싱->각 질문 토큰화하여 저장\n",
    "    \"\"\"\n",
    "    qa_data = []\n",
    "    qa_ids = []\n",
    "    # tgt2idx = {'ABBR': 0, 'DESC': 1, 'ENTY': 2,\n",
    "    #             'HUM': 3, 'LOC': 4, 'NUM': 5}\n",
    "    with io.open(fpath, 'r', encoding='utf-8') as f:\n",
    "        for example in f:\n",
    "            if \"header\" in json.loads(example):\n",
    "                continue\n",
    "            paragraph = json.loads(example)\n",
    "            for qa in paragraph['qas']:\n",
    "                qa_data.append(qa['question'].split())\n",
    "                qa_ids.append(qa['qid'])\n",
    "    return qa_data, qa_ids\n",
    "\n",
    "def loadSQuAD(fpath):\n",
    "    \"\"\"\n",
    "    SQuAD 스타일 데이터 파일을 읽어 질문과 질문 ID를 추출\n",
    "    파일 한 줄씩 읽어 JSON으로 파싱->각 질문 토큰화하여 저장\n",
    "    \"\"\"\n",
    "    qa_data = []\n",
    "    qa_ids = []\n",
    "    # tgt2idx = {'ABBR': 0, 'DESC': 1, 'ENTY': 2,\n",
    "    #             'HUM': 3, 'LOC': 4, 'NUM': 5}\n",
    "    with io.open(fpath, 'r', encoding='utf-8') as f:\n",
    "        input_data = json.load(f)[\"data\"]\n",
    "    for entry in input_data:\n",
    "        for paragraph in entry[\"paragraphs\"]:\n",
    "            for qa in paragraph[\"qas\"]:\n",
    "                qa_data.append(qa['question'].split())\n",
    "                qa_ids.append(qa['id'])\n",
    "    return qa_data, qa_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12912096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "squad question example:  ['To', 'whom', 'did', 'the', 'Virgin', 'Mary', 'allegedly', 'appear', 'in', '1858', 'in', 'Lourdes', 'France?']\n",
      "squad question id example:  5733be284776f41900661182\n",
      "File: ../data/squad/train-v1.1.json\n",
      "len:  500\n"
     ]
    }
   ],
   "source": [
    "# MRQA style input\n",
    "# file_path = '../data/mrqa/train/HotpotQA.jsonl'\n",
    "# 질문과 질문 ID 불러오기\n",
    "# all_qs, all_q_ids = loadFile(file_path)\n",
    "# SQuAD style input\n",
    "file_path = '../data/squad/train-v1.1.json'\n",
    "# 질문과 질문 ID 불러오기\n",
    "all_qs, all_q_ids = loadSQuAD(file_path)\n",
    "all_qs, all_q_ids = all_qs[:500], all_q_ids[:500]\n",
    "\n",
    "print('squad question example: ', all_qs[0])\n",
    "print('squad question id example: ', all_q_ids[0])\n",
    "\n",
    "q_type = []\n",
    "print('File:', file_path)\n",
    "print('len: ', len(all_q_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b1cafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(text: str) -> str:\n",
    "    # 소유격, 축약형 's 분리\n",
    "    text = re.sub(r\"(\\w+)'s\", r\"\\1 's\", text)\n",
    "    # 축약형 단순 변환\n",
    "    text = text.replace(\"n't\", \" not\")\n",
    "    text = text.replace(\"'re\", \" are\")\n",
    "    text = text.replace(\"'ve\", \" have\")\n",
    "    text = text.replace(\"'ll\", \" will\")\n",
    "    text = text.replace(\"'d\", \" would\")\n",
    "    text = text.replace(\"'m\", \" am\")\n",
    "    text = text.replace(\"What's\", \"What is\") \n",
    "    # 하이픈 단어 분리\n",
    "    text = re.sub(r\"(\\w+)-(\\w+)\", r\"\\1 \\2\", text)\n",
    "    # 불필요한 특수문자 제거\n",
    "    text = re.sub(r\"[^A-Za-z0-9\\s\\?]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "def preprocess_sentences(sent_list):\n",
    "    return [clean_sentence(s) for s in sent_list]\n",
    "\n",
    "def prepare(params, samples):\n",
    "    # InferSent 모델에 사용할 단어 사전을 구축하는 함수\n",
    "    # samples: 문장(질문) 리스트\n",
    "    # 각 문장을 띄어쓰기로 합쳐서 build_vocab에 전달\n",
    "    \n",
    "    # 축약형·소유격·하이픈 결합 단어 전처리 \n",
    "    sentences = [' '.join(sent) if sent != [] else '.' for sent in samples]\n",
    "    sentences = preprocess_sentences(sentences)\n",
    "    params['infersent'].build_vocab(sentences, tokenize=False) \n",
    "\n",
    "def batcher(params, batch):\n",
    "    # 입력된 질문 배치를 임베딩 벡터로 변환하는 함수\n",
    "    # 1. 각 질문(토큰 리스트)을 문자열로 합침\n",
    "    sentences = [' '.join(sent) if sent != [] else '.' for sent in batch]\n",
    "    # 2. 축약형·소유격·하이픈 결합 단어 전처리\n",
    "    sentences = preprocess_sentences(sentences)\n",
    "    # 3. InferSent 모델로 임베딩 생성\n",
    "    embeddings1 = params['infersent'].encode(sentences, bsize=params['classifier']['batch_size'], tokenize=False)\n",
    "    # 4. Google USE 인코더용으로 문장 준비 (빈 문장은 '.'으로 대체)\n",
    "    batch = [' '.join(sent) if sent != [] else '.' for sent in batch]\n",
    "    # 5. 축약형·소유격·하이픈 결합 단어 전처리\n",
    "    batch = preprocess_sentences(batch)\n",
    "    # 6. Google Universal Sentence Encoder로 임베딩 생성\n",
    "    embeddings2 = params['google_use'](batch)\n",
    "    \n",
    "    # 7. 두 임베딩을 합쳐서 반환 (문장 의미를 더 풍부하게 표현)\n",
    "    # return np.concatenate((embeddings1, embeddings2), axis=-1)\n",
    "    return embeddings1\n",
    "\n",
    "def getEmbeddings(qa_data, params):\n",
    "    # 전체 질문 리스트를 배치 단위로 나눠 임베딩을 생성하는 함수\n",
    "    out_embeds = []\n",
    "    # 배치 크기만큼 반복하며 임베딩 생성\n",
    "    for ii in range(0, len(qa_data), params['classifier']['batch_size']):\n",
    "        batch = qa_data[ii:ii + params['classifier']['batch_size']]\n",
    "        # batcher 함수로 임베딩 생성\n",
    "        embeddings = batcher(params, batch)\n",
    "        out_embeds.append(embeddings)\n",
    "    # 모든 배치 임베딩을 하나로 합쳐 반환(행렬 세로 방향으로 이어붙임)\n",
    "    # 입력: [batch_size개의 문장] -> 출력: (batch_size, emb_dim)\n",
    "    return np.vstack(out_embeds) # (N, 4096+512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9a9b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_senteval = {'task_path': PATH_TO_DATA, 'usepytorch': True, 'kfold': 5}\n",
    "params_senteval['classifier'] = {'nhid': 512, 'optim': 'rmsprop', 'batch_size': 16,\n",
    "                                 'tenacity': 5, 'epoch_size': 4}\n",
    "params_model = {'bsize': 16, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,\n",
    "                'pool_type': 'max', 'dpout_model': 0.0, 'version': V}\n",
    "model = InferSent(params_model)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "model.set_w2v_path(PATH_TO_W2V)\n",
    "params_senteval['infersent'] = model.cuda().eval()\n",
    "\n",
    "def make_embed_fn(module):\n",
    "    embed = hub.load(module)\n",
    "    f = embed.signatures[\"default\"]\n",
    "    return lambda x: f(tf.constant(x))[\"default\"]\n",
    "\n",
    "encoder = make_embed_fn(\"https://tfhub.dev/google/universal-sentence-encoder-large/3\")\n",
    "params_senteval['google_use'] = encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c3dbae",
   "metadata": {},
   "source": [
    "- 전처리 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a789b1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_data = []\n",
    "qa_ids = []\n",
    "with io.open(file_path, 'r', encoding='utf-8') as f:\n",
    "    input_data = json.load(f)[\"data\"]\n",
    "    input_data = input_data[42:43]\n",
    "for entry in input_data:\n",
    "    for paragraph in entry[\"paragraphs\"]:\n",
    "        for qa in paragraph[\"qas\"]:\n",
    "            qa_data.append(qa['question'].split())\n",
    "            qa_ids.append(qa['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7030ab55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
       " 'What is in front of the Notre Dame Main Building?',\n",
       " 'The Basilica of the Sacred heart at Notre Dame is beside to which structure?']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = all_qs[0:10]\n",
    "sentences = [' '.join(sent) if sent != [] else '.' for sent in batch]\n",
    "sentences_clean = preprocess_sentences(sentences)\n",
    "sentences_clean[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe24300",
   "metadata": {},
   "source": [
    "- Embedding1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efadd18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 54(/63) words with w2v vectors\n",
      "Vocab size : 54\n",
      "Nb words kept : 98/128 (76.6%)\n",
      "Speed : 27.1 sentences/s (gpu mode, bsize=16)\n"
     ]
    }
   ],
   "source": [
    "params_senteval['infersent'].build_vocab(sentences_clean, tokenize=False)\n",
    "embeddings1 = params_senteval['infersent'].encode(sentences_clean, bsize=params_senteval['classifier']['batch_size'], tokenize=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1219e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 54(/63) words with w2v vectors\n",
      "Vocab size : 54\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 4096)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs = all_qs[0:10]\n",
    "prepare(params_senteval, qs)\n",
    "embeddings1 = getEmbeddings(qs, params_senteval)\n",
    "embeddings1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a92a0a",
   "metadata": {},
   "source": [
    "- Embedding2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84874746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 512)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings2 = params_senteval['google_use'](sentences)\n",
    "embeddings2 = embeddings2.numpy()\n",
    "embeddings2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea2d9dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 4608)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_embeds = []\n",
    "embeddings = np.concatenate((embeddings1, embeddings2), axis=-1)\n",
    "out_embeds.append(embeddings)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed6a7f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2223245/287952112.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  clf.model.load_state_dict(torch.load('../model/qc4qa_model.pth'))\n"
     ]
    }
   ],
   "source": [
    "# TREC Classifier MLP 로드\n",
    "clf = MLP(params_senteval['classifier'], inputdim=4096+512, nclasses=6, batch_size=16)\n",
    "# 학습된 가중치 불러오기\n",
    "clf.model.load_state_dict(torch.load('../model/qc4qa_model.pth'))  \n",
    "# 모델을 GPU에 올리고 평가 모드로 변경\n",
    "clf.model.eval()\n",
    "out = clf.predict(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ca82dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2, 2, 2, 2, 5, 5, 2, 5, 5]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_type = []\n",
    "q_type += np.array(out).squeeze().astype(int).tolist()\n",
    "q_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398b1c5c",
   "metadata": {},
   "source": [
    "### Function ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c21d5d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(text: str) -> str:\n",
    "    # 소유격, 축약형 's 분리\n",
    "    text = re.sub(r\"(\\w+)'s\", r\"\\1 's\", text)\n",
    "    # 축약형 단순 변환\n",
    "    text = text.replace(\"n't\", \" not\")\n",
    "    text = text.replace(\"'re\", \" are\")\n",
    "    text = text.replace(\"'ve\", \" have\")\n",
    "    text = text.replace(\"'ll\", \" will\")\n",
    "    text = text.replace(\"'d\", \" would\")\n",
    "    text = text.replace(\"'m\", \" am\")\n",
    "    text = text.replace(\"What's\", \"What is\") \n",
    "    # 하이픈 단어 분리\n",
    "    text = re.sub(r\"(\\w+)-(\\w+)\", r\"\\1 \\2\", text)\n",
    "    # 불필요한 특수문자 제거\n",
    "    text = re.sub(r\"[^A-Za-z0-9\\s\\?]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "def preprocess_sentences(sent_list):\n",
    "    return [clean_sentence(s) for s in sent_list]\n",
    "\n",
    "def loadFile(fpath):\n",
    "    \"\"\"\n",
    "    MRQA 스타일 데이터 파일을 읽어 질문과 질문 ID를 추출\n",
    "    파일 한 줄씩 읽어 JSON으로 파싱->각 질문 토큰화하여 저장\n",
    "    \"\"\"\n",
    "    qa_data = []\n",
    "    qa_ids = []\n",
    "    # tgt2idx = {'ABBR': 0, 'DESC': 1, 'ENTY': 2,\n",
    "    #             'HUM': 3, 'LOC': 4, 'NUM': 5}\n",
    "    with io.open(fpath, 'r', encoding='utf-8') as f:\n",
    "        for example in f:\n",
    "            if \"header\" in json.loads(example):\n",
    "                continue\n",
    "            paragraph = json.loads(example)\n",
    "            for qa in paragraph['qas']:\n",
    "                qa_data.append(qa['question'].split())\n",
    "                qa_ids.append(qa['qid'])\n",
    "    return qa_data, qa_ids\n",
    "\n",
    "def loadSQuAD(fpath):\n",
    "    \"\"\"\n",
    "    SQuAD 스타일 데이터 파일을 읽어 질문과 질문 ID를 추출\n",
    "    파일 한 줄씩 읽어 JSON으로 파싱->각 질문 토큰화하여 저장\n",
    "    \"\"\"\n",
    "    qa_data = []\n",
    "    qa_ids = []\n",
    "    # tgt2idx = {'ABBR': 0, 'DESC': 1, 'ENTY': 2,\n",
    "    #             'HUM': 3, 'LOC': 4, 'NUM': 5}\n",
    "    with io.open(fpath, 'r', encoding='utf-8') as f:\n",
    "        input_data = json.load(f)[\"data\"]\n",
    "        input_data = input_data ################ 개수 줄이기 ################ [:30]\n",
    "    for entry in input_data:\n",
    "        for paragraph in entry[\"paragraphs\"]:\n",
    "            for qa in paragraph[\"qas\"]:\n",
    "                qa_data.append(qa['question'].split())\n",
    "                qa_ids.append(qa['id'])\n",
    "    return qa_data, qa_ids\n",
    "\n",
    "def prepare(params, samples):\n",
    "    # InferSent 모델에 사용할 단어 사전을 구축하는 함수\n",
    "    # samples: 문장(질문) 리스트\n",
    "    \n",
    "    # 축약형·소유격·하이픈 결합 단어 전처리 \n",
    "    sentences = [' '.join(sent) if sent != [] else '.' for sent in samples]\n",
    "    sentences = preprocess_sentences(sentences)\n",
    "    params['infersent'].build_vocab(sentences, tokenize=False) # 모델 불러옴\n",
    "\n",
    "def batcher(params, batch):\n",
    "    # 입력된 질문 배치를 임베딩 벡터로 변환하는 함수\n",
    "    # 1. 각 질문(토큰 리스트)을 문자열로 합침\n",
    "    sentences = [' '.join(sent) if sent != [] else '.' for sent in batch]\n",
    "    # 2. 축약형·소유격·하이픈 결합 단어 전처리\n",
    "    sentences = preprocess_sentences(sentences)\n",
    "    # 3. InferSent 모델로 임베딩 생성\n",
    "    embeddings1 = params['infersent'].encode(sentences, bsize=params['classifier']['batch_size'], tokenize=False)\n",
    "    # 4. Google Universal Sentence Encoder로 임베딩 생성\n",
    "    embeddings2 = params['google_use'](sentences)\n",
    "    embeddings2 = embeddings2.numpy()\n",
    "    # 5. 두 임베딩을 합쳐서 반환 (문장 의미를 더 풍부하게 표현)\n",
    "    return np.concatenate((embeddings1, embeddings2), axis=-1)\n",
    "\n",
    "def make_embed_fn(module):\n",
    "    embed = hub.load(module)\n",
    "    f = embed.signatures[\"default\"]\n",
    "    return lambda x: f(tf.constant(x))[\"default\"]\n",
    "\n",
    "def getEmbeddings(qa_data, params):\n",
    "    # 전체 질문 리스트를 배치 단위로 나눠 임베딩을 생성하는 함수\n",
    "    out_embeds = []\n",
    "    # 배치 크기만큼 반복하며 임베딩 생성\n",
    "    for ii in range(0, len(qa_data), params['classifier']['batch_size']):\n",
    "        batch = qa_data[ii:ii + params['classifier']['batch_size']]\n",
    "        # batcher 함수로 임베딩 생성\n",
    "        embeddings = batcher(params, batch)\n",
    "        out_embeds.append(embeddings)\n",
    "    # 모든 배치 임베딩을 하나로 합쳐 반환(행렬 세로 방향으로 이어붙임)\n",
    "    # 입력: [batch_size개의 문장] -> 출력: (batch_size, emb_dim)\n",
    "    return np.vstack(out_embeds) # (N, 4096+512)\n",
    "\n",
    "def updateFile(fpath, q_type, q_ids):\n",
    "    # MRQA 스타일 데이터 파일에 질문 유형(q_type)을 추가하는 함수\n",
    "    paragraphs = []\n",
    "    # 원본 파일을 한 줄씩 읽어서 JSON 객체로 파싱\n",
    "    with io.open(fpath, 'r', encoding='utf-8') as f:\n",
    "        for example in f:\n",
    "            # header가 포함된 줄은 건너뜀\n",
    "            if \"header\" in json.loads(example):\n",
    "                continue\n",
    "            paragraph = json.loads(example)\n",
    "            paragraphs.append(paragraph)\n",
    "    \n",
    "    total_idx = 0\n",
    "    # 각 paragraph의 qas 리스트를 순회하며 질문 ID(qid)와 분류 결과(q_type)를 매칭\n",
    "    for paragraph in paragraphs:\n",
    "        for qa in paragraph['qas']:\n",
    "            # 예측된 질문 유형을 해당 질문에 추가\n",
    "            if qa['qid'] == q_ids[total_idx]:\n",
    "                qa['q_type'] = q_type[total_idx]\n",
    "                total_idx += 1\n",
    "            else:\n",
    "                # 질문 ID가 맞지 않으면 경고 출력\n",
    "                print('Can not match qid:', q_ids[total_idx])\n",
    "    \n",
    "    # 새로운 파일로 결과 저장 (원본 파일명에서 .jsonl을 _classified.jsonl로 변경)\n",
    "    with open(fpath[:-6]+'_classified_tmp.jsonl', 'w') as f:\n",
    "        for sample in paragraphs:\n",
    "            f.write(json.dumps(sample)+'\\n')\n",
    "    f.close()\n",
    "\n",
    "def updateSQuAD(fpath, q_type, q_ids):\n",
    "    # SQuAD 스타일 데이터 파일에 질문 유형(q_type)을 추가하는 함수\n",
    "    with io.open(fpath, 'r', encoding='utf-8') as f:\n",
    "        input_data = json.load(f)[\"data\"]\n",
    "        input_data = input_data ################ 개수 줄이기 ################\n",
    "    total_idx = 0\n",
    "    # SQuAD 구조에 맞게 각 질문에 대해 분류 결과를 추가\n",
    "    for entry in input_data:\n",
    "        for paragraph in entry[\"paragraphs\"]:\n",
    "            for qa in paragraph['qas']:\n",
    "                # 예측된 질문 유형을 해당 질문에 추가\n",
    "                if qa['id'] == q_ids[total_idx]:\n",
    "                    qa['q_type'] = q_type[total_idx]\n",
    "                    total_idx += 1\n",
    "                else:\n",
    "                    # 질문 ID가 맞지 않으면 경고 출력\n",
    "                    print('Can not match qid:', q_ids[total_idx])\n",
    "    \n",
    "    # 새로운 파일로 결과 저장 (원본 파일명에서 .json을 _classified.json로 변경)\n",
    "    with open(fpath[:-5]+'_classified_tmp.json', 'w') as f:\n",
    "        f.write(json.dumps({\"data\": input_data})+'\\n')\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5fa9096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_0:0' shape=(35297, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1757913921.869194 2248967 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21876 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:02:00.0, compute capability: 8.9\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_0:0' shape=(35297, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_1:0' shape=(35297, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_1:0' shape=(35297, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_2:0' shape=(35297, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_2:0' shape=(35297, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_3:0' shape=(35297, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_3:0' shape=(35297, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_4:0' shape=(35297, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_4:0' shape=(35297, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_0:0' shape=(35297, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_0:0' shape=(35297, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_1:0' shape=(35297, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_1:0' shape=(35297, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_2:0' shape=(35297, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_2:0' shape=(35297, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_3:0' shape=(35297, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_3:0' shape=(35297, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_4:0' shape=(35297, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_4:0' shape=(35297, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_0:0' shape=(35297, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_0:0' shape=(35297, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_1:0' shape=(35297, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_1:0' shape=(35297, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_2:0' shape=(35297, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_2:0' shape=(35297, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_3:0' shape=(35297, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_3:0' shape=(35297, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_4:0' shape=(35297, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_4:0' shape=(35297, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_0:0' shape=(35297, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_0:0' shape=(35297, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_1:0' shape=(35297, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_1:0' shape=(35297, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_2:0' shape=(35297, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_2:0' shape=(35297, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_3:0' shape=(35297, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_3:0' shape=(35297, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_4:0' shape=(35297, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_4:0' shape=(35297, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "/tmp/ipykernel_2248967/1828915119.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(MODEL_PATH))\n",
      "/tmp/ipykernel_2248967/1828915119.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  clf.model.load_state_dict(torch.load('../model/qc4qa_model.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=4608, out_features=512, bias=True)\n",
       "  (1): Dropout(p=0.0, inplace=False)\n",
       "  (2): Sigmoid()\n",
       "  (3): Linear(in_features=512, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set\n",
    "encoder = make_embed_fn(\"https://tfhub.dev/google/universal-sentence-encoder-large/3\")\n",
    "params_senteval = {'task_path': PATH_TO_DATA, 'usepytorch': True, 'kfold': 5}\n",
    "params_senteval['classifier'] = {'nhid': 512, 'optim': 'rmsprop', 'batch_size': 16,\n",
    "                                 'tenacity': 5, 'epoch_size': 4}\n",
    "params_senteval['google_use'] = encoder\n",
    "params_model = {'bsize': 16, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,\n",
    "                'pool_type': 'max', 'dpout_model': 0.0, 'version': V}\n",
    "model = InferSent(params_model)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "model.set_w2v_path(PATH_TO_W2V)\n",
    "params_senteval['infersent'] = model.cuda().eval()\n",
    "\n",
    "# Set Parameter\n",
    "file_path = '../data/squad/train-v1.1.json'\n",
    "all_qs, all_q_ids = loadSQuAD(file_path)\n",
    "q_type = []\n",
    "clf = MLP(params_senteval['classifier'], inputdim=4096+512, nclasses=6, batch_size=16)\n",
    "clf.model.load_state_dict(torch.load('../model/qc4qa_model.pth'))  \n",
    "clf.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b13361",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad(): \n",
    "    # 질문을 배치 단위로 임베딩->MLP예측->결과 누적\n",
    "    for i in range(0, len(all_qs), 1000): \n",
    "        qs = all_qs[i:1000+i] # 현재 배치에 해당하는 질문 1000개 선택\n",
    "        prepare(params_senteval, qs) # InferSent모델에 맞게 단어 사전 구축\n",
    "        # 선택된 질문을 InferSent와 Google USE로 임베딩 벡터로 변환\n",
    "        embeds = getEmbeddings(qs, params_senteval) \n",
    "        # 임베딩된 질문을 MLP 분류기에 입력하여 질문 유형 예측\n",
    "        out = clf.predict(embeds)\n",
    "        # 예측 결과를 리스트로 변환하여 전체 결과(q_type)에 추가\n",
    "        q_type += np.array(out).squeeze().astype(int).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a8343f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len input_data: 442\n"
     ]
    }
   ],
   "source": [
    "# SQuAD sytle update\n",
    "updateSQuAD(file_path, q_type, all_q_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f18363cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['context', 'qas'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '../data/squad/train-v1.1_classified_tmp.json'\n",
    "with io.open(file_path, 'r', encoding='utf-8') as f:\n",
    "    tmp_data = json.load(f)['data']\n",
    "tmp_data[0]['paragraphs'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9de14fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'answers': [{'answer_start': 105, 'text': 'Nepal'}],\n",
       "  'question': 'What country is Kathmandu the capital of?',\n",
       "  'id': '57359bbcdc94161900571ee9',\n",
       "  'q_type': 3},\n",
       " {'answers': [{'answer_start': 332, 'text': 'Sub-Metropolitan City'}],\n",
       "  'question': 'What does Upa-Mahanagar mean in English?',\n",
       "  'id': '57359bbcdc94161900571eea',\n",
       "  'q_type': 3},\n",
       " {'answers': [{'answer_start': 615, 'text': 'tri-city'}],\n",
       "  'question': 'Along with \"KTM,\" what is another nickname of Kathmandu?',\n",
       "  'id': '57359bbcdc94161900571eeb',\n",
       "  'q_type': 1},\n",
       " {'answers': [{'answer_start': 704, 'text': '975,453'}],\n",
       "  'question': 'How many people lived in Kathmandu in 2011?',\n",
       "  'id': '57359bbcdc94161900571eec',\n",
       "  'q_type': 1},\n",
       " {'answers': [{'answer_start': 725, 'text': '49.45'}],\n",
       "  'question': 'How many square kilometers in size is Kathmandu?',\n",
       "  'id': '57359bbcdc94161900571eed',\n",
       "  'q_type': 1}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_data[441]['paragraphs'][0]['qas']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qc4qa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
