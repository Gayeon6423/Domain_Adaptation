{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c05814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "\n",
    "from abc import ABCMeta\n",
    "import argparse\n",
    "import datetime \n",
    "import collections\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import sys\n",
    "import io\n",
    "from tqdm import tqdm, trange\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, WeightedRandomSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "from pytorch_pretrained_bert.modeling import BertForQuestionAnswering\n",
    "from pytorch_pretrained_bert.modeling import BertForQuestionAnsweringQC4QA\n",
    "\n",
    "from pytorch_pretrained_bert.optimization import BertAdam\n",
    "from utils.ConfigLogger import config_logger\n",
    "from utils.evaluate import f1_score, exact_match_score, metric_max_over_ground_truths\n",
    "from utils.BERTRandomSampler import BERTRandomSampler\n",
    "\n",
    "PYTORCH_PRETRAINED_BERT_CACHE = Path(os.getenv('PYTORCH_PRETRAINED_BERT_CACHE',\n",
    "                                               Path.home() / '.pytorch_pretrained_bert'))\n",
    "\n",
    "from da_data_utils import * # Question Typeìš© Data_utils íŒŒì¼(ì›ë³¸ì€ data_utils.py)\n",
    "from qada_utils import *\n",
    "############################\n",
    "import importlib, types, argparse\n",
    "from utils.ConfigLogger import config_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8bd1e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_squad_path = '../../../data/squad/train-v1.1_classified_qtype_prob.jsonl'\n",
    "dev_squad_path = '../../../data/squad/dev-v1.1.json'\n",
    "train_cnn_path = '../../../data/cnn/cnn_train_classified_qtype_prob.jsonl'\n",
    "dev_cnn_path = '../../../data/cnn/cnn_dev.json'\n",
    "\n",
    "\n",
    "def open_jsonl(path):\n",
    "    data = []\n",
    "    with io.open(path, 'r', encoding='utf-8') as f:\n",
    "        for example in f:\n",
    "            data.append(json.loads(example))\n",
    "    data = data[:10] # debug size\n",
    "    return data\n",
    "\n",
    "def open_json(path):\n",
    "    with io.open(path, 'r', encoding='utf-8') as f:\n",
    "        input_data = json.load(f)[\"data\"]\n",
    "    input_data = input_data[:10]  # debug size\n",
    "    return input_data\n",
    "\n",
    "train_squad_data = open_jsonl(train_squad_path)\n",
    "dev_squad_data = open_json(dev_squad_path)\n",
    "train_cnn_data = open_jsonl(train_cnn_path)\n",
    "dev_cnn_data = open_json(dev_cnn_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85da19a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answers': [{'answer_start': 515, 'text': 'Saint Bernadette Soubirous'}],\n",
       " 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
       " 'id': '5733be284776f41900661182',\n",
       " 'q_type': 3,\n",
       " 'q_type_prob': [0.0, 0.0, 0.016, 0.983, 0.001, 0.0]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_squad_data[0]['paragraphs'][0]['qas'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbd86efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answers': [{'answer_start': 2070, 'text': 'Globe'}],\n",
       " 'question': 'on the Democratic side , the Register backs Clinton , while the @placeholder picks Obama',\n",
       " 'id': 'training/6dc32db9379e43971ad93007e76c5347e213f21a',\n",
       " 'q_type': 3,\n",
       " 'q_type_prob': [0.001, 0.001, 0.171, 0.76, 0.064, 0.002]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cnn_data[0]['paragraphs'][0]['qas'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6a03f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "args = argparse.Namespace(\n",
    "    debug = True, # sample_limit ì‚¬ì´ì¦ˆë¡œ ë””ë²„ê¹…\n",
    "    bert_model='bert-base-uncased',\n",
    "    do_adaptation=True,\n",
    "    do_predict=False,\n",
    "    do_lower_case=True,\n",
    "    source_train_file=\"../../../data/squad/train-v1.1_classified_qtype_prob.jsonl\",\n",
    "    target_train_file=\"../../../data/cnn/cnn_train_classified_qtype_prob.jsonl\",\n",
    "    target_predict_file=\"../../../data/cnn/cnn_dev.json\",\n",
    "    input_dir=\"model/squad\",\n",
    "    input_model_file=\"best_model_0916.bin\",\n",
    "    output_dir=\"model/squad2target\",\n",
    "    output_model_file=\"adaptation_1031.bin\",\n",
    "    logger_path=\"model/squad2target\",\n",
    "    max_seq_length=512,\n",
    "    seed=42,\n",
    "    gradient_accumulation_steps=1,\n",
    "    train_batch_size=12,\n",
    "    predict_batch_size=12,\n",
    "    num_workers=4,\n",
    "    evaluation_interval=2000,\n",
    "    loss_logging_interval=500,\n",
    "    train_learning_rate=3e-5,\n",
    "    num_train_epochs=2,\n",
    "    warmup_proportion=0.1,\n",
    "    n_best_size=20,\n",
    "    max_answer_length=30,\n",
    "    verbose_logging=False,\n",
    "    use_simple_feature=False,\n",
    "    generate_prob_th=0.6,\n",
    "    keep_previous_generated=False,\n",
    "    use_BN=True,\n",
    "    output_prediction=True,\n",
    "    source_sampling_ratio=3,\n",
    "    doc_stride=128,\n",
    "    max_query_length=64,\n",
    "    adapt_learning_rate=1e-5,\n",
    "    lambda_c=0.1,\n",
    "    sample_limit= 100  ### ë””ë²„ê¹…ìš© ë°ì´í„°ì…‹ í¬ê¸°\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b491535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_stage(args, device, tokenizer, logger, debug=False):\n",
    "    # Load a trained model that you have fine-tuned\n",
    "    output_model_file = os.path.join(args.output_dir, args.output_model_file)\n",
    "    model_state_dict = torch.load(output_model_file)\n",
    "    model = BertForQuestionAnswering.from_pretrained(args.bert_model, state_dict=model_state_dict, args=args)\n",
    "    model.to(device)\n",
    "    # Read prediction samples\n",
    "    read_limit = None\n",
    "    if debug:\n",
    "        read_limit = 100 # ìƒ˜í”Œ 100ê°œë§Œ ì‚¬ìš©\n",
    "    logger.info(\"***** Reading Prediction Samples *****\")\n",
    "    eval_features, eval_examples = read_features_and_examples(args, args.predict_file, tokenizer, logger,\n",
    "            use_simple_feature=False, read_examples=True, limit=read_limit)\n",
    "    acc, f1 = evaluation_stage(args, eval_examples, eval_features, device, model, logger)\n",
    "    logger.info('***** Prediction Performance *****')\n",
    "    logger.info('EM is %.5f, F1 is %.5f', acc, f1)\n",
    "\n",
    "\n",
    "def evaluate_acc_and_f1(predictions, raw_data, logger, threshold=-1, all_probs=None):\n",
    "    f1 = exact_match = total = 0\n",
    "    eval_threshold = True\n",
    "    if threshold is None or all_probs is None:\n",
    "        eval_threshold = False\n",
    "    for sample in raw_data:\n",
    "        if (sample.qas_id not in predictions) or (eval_threshold and sample.qas_id not in all_probs):\n",
    "            message = 'Unanswered question ' + sample.qas_id + ' will receive score 0.'\n",
    "            logger.warn(message)\n",
    "            continue\n",
    "        if not eval_threshold or (eval_threshold and all_probs[sample.qas_id] >= threshold):\n",
    "            ground_truths = sample.orig_answers\n",
    "            prediction = predictions[sample.qas_id]\n",
    "            exact_match += metric_max_over_ground_truths(\n",
    "                exact_match_score, prediction, ground_truths)\n",
    "            f1 += metric_max_over_ground_truths(\n",
    "                f1_score, prediction, ground_truths)\n",
    "            total += 1\n",
    "\n",
    "    exact_match = 100.0 * exact_match / total\n",
    "    f1 = 100.0 * f1 / total\n",
    "\n",
    "    return exact_match, f1\n",
    "\n",
    "\n",
    "def keep_high_prob_samples(all_probs, all_features, prob_threshold, removed_feature_index, all_indices,\n",
    "        keep_generated=False):\n",
    "    '''\n",
    "    ì…€í”„ íŠ¸ë ˆì´ë‹ìš©: ë†’ì€ í™•ë¥ ì˜ ì˜ˆì¸¡ì„ pseudo-labelë¡œ ë³€í™˜\n",
    "    '''\n",
    "    new_train_features = []\n",
    "    for i, feature in enumerate(all_features):\n",
    "        if keep_generated:\n",
    "            if feature.example_index not in removed_feature_index and all_probs[feature.example_index] > prob_threshold:\n",
    "                feature.start_position, feature.end_position = all_indices[i][0] = all_indices[i][1]\n",
    "                new_train_features.append(feature)\n",
    "                removed_feature_index.add(feature.example_index)\n",
    "        else:\n",
    "            if all_probs[feature.example_index] > prob_threshold:\n",
    "                feature.start_position, feature.end_position = all_indices[i][0], all_indices[i][1]\n",
    "                new_train_features.append(feature)\n",
    "    return new_train_features, removed_feature_index\n",
    "\n",
    "\n",
    "def compare_performance(args, best_acc, best_f1, acc, f1, model, logger):\n",
    "    if not (best_f1 is None or best_acc is None):\n",
    "        if best_acc < acc:\n",
    "            logger.info('Current model BEATS previous best model, previous best is EM = %.5F, F1 = %.5f',\n",
    "                best_acc, best_f1)\n",
    "            best_acc, best_f1 = acc, f1\n",
    "            logger.info('Current best model has been saved!')\n",
    "            model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
    "            torch.save(model_to_save.state_dict(), os.path.join(args.output_dir, args.output_model_file))\n",
    "        else:\n",
    "            logger.info('Current model CANNOT beat previous best model, previous best is EM = %.5F, F1 = %.5f',\n",
    "                best_acc, best_f1)\n",
    "    else:\n",
    "        best_acc, best_f1 = acc, f1\n",
    "    return best_acc, best_f1\n",
    "\n",
    "\n",
    "def evaluation_stage(args, eval_examples, eval_features, device, model, logger, generate_prob_th=0.6,\n",
    "        removed_feature_index=None, global_step=None, best_acc=None, best_f1=None, generate_label=False):\n",
    "    if not global_step:\n",
    "        logger.info(\"***** Running Evaluation Stage *****\")\n",
    "    else:\n",
    "        logger.info(\"***** Running Predictions *****\")\n",
    "    logger.info(\"  Num orig examples = %d\", len(eval_examples))\n",
    "    logger.info(\"  Num split examples = %d\", len(eval_features))\n",
    "    logger.info(\"  Batch size = %d\", args.predict_batch_size)\n",
    "\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\n",
    "    all_example_index = torch.arange(all_input_ids.size(0), dtype=torch.long)\n",
    "    eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_example_index)\n",
    "    # Run prediction for full data\n",
    "    eval_sampler = SequentialSampler(eval_data)\n",
    "    eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=args.predict_batch_size)\n",
    "\n",
    "    model.eval()\n",
    "    all_results = []\n",
    "    logger.info(\"Start evaluating\")\n",
    "    for input_ids, input_mask, segment_ids, example_indices in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "        input_ids = input_ids.to(device)\n",
    "        input_mask = input_mask.to(device)\n",
    "        segment_ids = segment_ids.to(device)\n",
    "        with torch.no_grad():\n",
    "             batch_start_logits, batch_end_logits, _ = model(input_ids, segment_ids, input_mask)\n",
    "        for i, example_index in enumerate(example_indices):\n",
    "            start_logits = batch_start_logits[i].detach().cpu().tolist()\n",
    "            end_logits = batch_end_logits[i].detach().cpu().tolist()\n",
    "            eval_feature = eval_features[example_index.item()]\n",
    "            unique_id = int(eval_feature.unique_id)\n",
    "            all_results.append(RawResult(unique_id=unique_id,\n",
    "                start_logits=start_logits,\n",
    "                end_logits=end_logits))\n",
    "\n",
    "    if global_step:\n",
    "        prediction_file_name = 'predictions_' + str(global_step) + f'_{datetime.datetime.now().strftime(\"%Y%m%d_%H:%M:%S\")}.json'\n",
    "        nbest_file_name = 'nbest_predictions_' + str(global_step) + f'_{datetime.datetime.now().strftime(\"%Y%m%d_%H:%M:%S\")}.json'\n",
    "        output_prediction_file = os.path.join(args.output_dir, prediction_file_name)\n",
    "        output_nbest_file = os.path.join(args.output_dir, nbest_file_name)\n",
    "    else:\n",
    "        output_prediction_file = os.path.join(args.output_dir, f'predictions_{datetime.datetime.now().strftime(\"%Y%m%d_%H:%M:%S\")}.json')\n",
    "        output_nbest_file = os.path.join(args.output_dir, f'nbest_predictions_{datetime.datetime.now().strftime(\"%Y%m%d_%H:%M:%S\")}.json')\n",
    "    all_predictions, all_probs, all_indices = write_predictions(args, eval_examples, eval_features, all_results,\n",
    "        args.n_best_size, args.max_answer_length,\n",
    "        args.do_lower_case, output_prediction_file,\n",
    "        output_nbest_file, args.verbose_logging, logger, args.output_prediction)\n",
    "    if generate_label:\n",
    "        return keep_high_prob_samples(all_probs, eval_features, generate_prob_th, removed_feature_index, all_indices,\n",
    "                keep_generated=args.keep_previous_generated)\n",
    "    else:\n",
    "        acc, f1 = evaluate_acc_and_f1(all_predictions, eval_examples, logger)\n",
    "        logger.info('Current EM is %.5f, F1 is %.5f', acc, f1)\n",
    "        if not (best_f1 is None or best_acc is None):\n",
    "            best_acc, best_f1 = compare_performance(args, best_acc, best_f1, acc, f1, model, logger)\n",
    "            return best_acc, best_f1\n",
    "        else:\n",
    "            return acc, f1\n",
    "\n",
    "\n",
    "def generate_self_training_samples(args, train_examples, train_features, device, model, removed_feature_index,\n",
    "        new_generated_train_features, generate_prob_th, logger):\n",
    "    '''\n",
    "    íƒ€ê²Ÿ ë„ë©”ì¸ ë°ì´í„°ì—ì„œ pseudo-label ìƒì„±\n",
    "    '''\n",
    "    logger.info('***** Generating training data for this epoch *****')\n",
    "    if args.keep_previous_generated:\n",
    "        train_features_removed_previous = []\n",
    "        for index in range(len(train_features)):\n",
    "            if index not in removed_feature_index:\n",
    "                train_features_removed_previous.append(train_features[index])\n",
    "    else:\n",
    "        train_features_removed_previous = train_features\n",
    "    cur_train_features, removed_feature_index = \\\n",
    "        evaluation_stage(args, train_examples, train_features_removed_previous, device, model, logger,\n",
    "            removed_feature_index=removed_feature_index, generate_label=True, generate_prob_th=generate_prob_th)\n",
    "    if len(cur_train_features) == 0:\n",
    "        logger.info(\"  No new training samples were generated, training procedure ends\")\n",
    "        return None, None\n",
    "    if args.keep_previous_generated:\n",
    "        new_generated_train_features.extend(cur_train_features)\n",
    "    else:\n",
    "        new_generated_train_features = cur_train_features\n",
    "    return new_generated_train_features, removed_feature_index\n",
    "\n",
    "\n",
    "def get_bert_model_parameters(model):\n",
    "    '''\n",
    "    ì—­í• :BERT optimizer íŒŒë¼ë¯¸í„° ê·¸ë£¹ ìƒì„± (weight decay ì ìš©/ë¯¸ì ìš© ë¶„ë¦¬)\n",
    "    ë°˜í™˜: optimizer_grouped_parameters\n",
    "    '''\n",
    "    # Prepare optimizer\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "\n",
    "    # hack to remove pooler, which is not used\n",
    "    # thus it produce None grad that break apex\n",
    "    param_optimizer = [n for n in param_optimizer if 'pooler' not in n[0]]\n",
    "\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "    return optimizer_grouped_parameters\n",
    "\n",
    "\n",
    "def comb_adversarial_training_stage(args, target_train_features, target_train_examples, source_train_features,\n",
    "            eval_features, eval_examples, removed_feature_index, new_generated_train_features, model, epoch,\n",
    "            device, best_acc, best_f1, logger):\n",
    "    '''\n",
    "    1. Self-training: íƒ€ê²Ÿ ë°ì´í„°ì—ì„œ pseudo-label ìƒì„±\n",
    "    2. Question Type Probability ê¸°ë°˜ Source-Target ë§¤ì¹­:\n",
    "        íƒ€ê²Ÿ ë°°ì¹˜ì˜ ê° ìƒ˜í”Œì—ì„œ q_type_prob ìƒìœ„ 3ê°œë¥¼ ì¶”ì¶œí•˜ì—¬\n",
    "        ê° íƒ€ì…ì— í•´ë‹¹í•˜ëŠ” ì†ŒìŠ¤ ìƒ˜í”Œì„ ìƒ˜í”Œë§ (íƒ€ê²Ÿ 1ê°œ â†’ ì†ŒìŠ¤ 3ê°œ)\n",
    "    3. Combined Training: íƒ€ê²Ÿ(pseudo) + ì†ŒìŠ¤(labeled) ë°ì´í„°ë¥¼ concatí•˜ì—¬ í•™ìŠµ\n",
    "    '''\n",
    "\n",
    "    def sample_source_batch_top3(source_data, source_q_type_dict, sample_pointer, q_type_probs):\n",
    "        \"\"\"\n",
    "        q_type_probs ê¸°ë°˜ ìƒìœ„ 3ê°œ íƒ€ì…ì—ì„œ ì†ŒìŠ¤ ìƒ˜í”Œë§\n",
    "        Args:\n",
    "            q_type_probs: [batch_size, 6] í…ì„œ\n",
    "        Returns:\n",
    "            íƒ€ê²Ÿ ë°°ì¹˜ì˜ ìµœëŒ€ 3ë°° í¬ê¸° ì†ŒìŠ¤ ë°°ì¹˜\n",
    "        \"\"\"\n",
    "        output_idx = []\n",
    "\n",
    "        for q_type_prob in q_type_probs:  # ê° íƒ€ê²Ÿ ìƒ˜í”Œ\n",
    "            # ìƒìœ„ 3ê°œ q_type ì¸ë±ìŠ¤ ì¶”ì¶œ\n",
    "            top3_indices = torch.topk(q_type_prob, k=3).indices.tolist()\n",
    "\n",
    "            for q_type in top3_indices:\n",
    "                # í•´ë‹¹ íƒ€ì…ì— ì†ŒìŠ¤ ìƒ˜í”Œì´ ì—†ìœ¼ë©´ ìŠ¤í‚µ\n",
    "                if len(source_q_type_dict[q_type]) == 0:\n",
    "                    continue\n",
    "\n",
    "                next_q_idx = sample_pointer[q_type] % len(source_q_type_dict[q_type])\n",
    "                output_idx.append(source_q_type_dict[q_type][next_q_idx])\n",
    "                sample_pointer[q_type] += 1\n",
    "\n",
    "        input_ids_source, input_masks_source, segment_ids_source, start_positions_source, end_positions_source, \\\n",
    "            q_types_source = [], [], [], [], [], []\n",
    "        for idx in output_idx:\n",
    "            input_ids_source.append(source_data[idx][0].unsqueeze(0))\n",
    "            input_masks_source.append(source_data[idx][1].unsqueeze(0))\n",
    "            segment_ids_source.append(source_data[idx][2].unsqueeze(0))\n",
    "            start_positions_source.append(source_data[idx][3].unsqueeze(0))\n",
    "            end_positions_source.append(source_data[idx][4].unsqueeze(0))\n",
    "            q_types_source.append(source_data[idx][5].unsqueeze(0))\n",
    "\n",
    "        return torch.vstack(input_ids_source), torch.vstack(input_masks_source), torch.vstack(segment_ids_source), \\\n",
    "            torch.cat(start_positions_source, -1), torch.cat(end_positions_source, -1), torch.cat(q_types_source, -1)\n",
    "\n",
    "    # Generate self-training samples\n",
    "    # 1. Pseudo-label ìƒì„±\n",
    "    new_generated_train_features, removed_feature_index = generate_self_training_samples(args, target_train_examples,\n",
    "        target_train_features, device, model, removed_feature_index, new_generated_train_features, args.generate_prob_th,\n",
    "        logger)\n",
    "    if new_generated_train_features is None:\n",
    "        sys.exit()\n",
    "    \n",
    "    logger.info('\\n')\n",
    "    logger.info('====================  Start Adversarial Training Stage  ====================')\n",
    "    \n",
    "    # q_type_prob ì¶”ì¶œ (ë°ì´í„°ì—ì„œ ê°€ì ¸ì˜¤ê¸°)\n",
    "    all_q_type_probs = []\n",
    "    for f in new_generated_train_features:\n",
    "        # InputFeaturesì— q_type_probê°€ ìˆëŠ”ì§€ í™•ì¸\n",
    "        if hasattr(f, 'q_type_prob') and f.q_type_prob is not None:\n",
    "            all_q_type_probs.append(f.q_type_prob)\n",
    "        else:\n",
    "            # q_type_probê°€ ì—†ìœ¼ë©´ one-hot ì¸ì½”ë”© ì‚¬ìš©\n",
    "            prob = [0.0] * 6\n",
    "            prob[f.q_type] = 1.0\n",
    "            all_q_type_probs.append(prob)\n",
    "    \n",
    "    all_input_ids = torch.tensor([f.input_ids for f in new_generated_train_features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in new_generated_train_features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in new_generated_train_features], dtype=torch.long)\n",
    "    all_start_positions = torch.tensor([f.start_position for f in new_generated_train_features], dtype=torch.long)\n",
    "    all_end_positions = torch.tensor([f.end_position for f in new_generated_train_features], dtype=torch.long)\n",
    "    all_q_types = torch.tensor([f.q_type for f in new_generated_train_features], dtype=torch.long)\n",
    "    all_q_type_probs = torch.tensor(all_q_type_probs, dtype=torch.float)\n",
    "    \n",
    "    train_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids,\n",
    "        all_start_positions, all_end_positions, all_q_types, all_q_type_probs)\n",
    "    \n",
    "    source_input_ids = torch.tensor([f.input_ids for f in source_train_features], dtype=torch.long)\n",
    "    source_input_mask = torch.tensor([f.input_mask for f in source_train_features], dtype=torch.long)\n",
    "    source_segment_ids = torch.tensor([f.segment_ids for f in source_train_features], dtype=torch.long)\n",
    "    source_start_positions = torch.tensor([f.start_position for f in source_train_features], dtype=torch.long)\n",
    "    source_end_positions = torch.tensor([f.end_position for f in source_train_features], dtype=torch.long)\n",
    "    source_q_types = []\n",
    "    source_q_type_dict = {\n",
    "        0: [],\n",
    "        1: [],\n",
    "        2: [],\n",
    "        3: [],\n",
    "        4: [],\n",
    "        5: []\n",
    "    }\n",
    "    for idx, f in enumerate(source_train_features):\n",
    "        source_q_types.append(f.q_type)\n",
    "        source_q_type_dict[f.q_type].append(idx)\n",
    "    source_q_types = torch.tensor(source_q_types, dtype=torch.long)\n",
    "    for key in source_q_type_dict.keys():\n",
    "        random.shuffle(source_q_type_dict[key])\n",
    "    sample_pointer = [0] * 6\n",
    "    source_data = TensorDataset(source_input_ids, source_input_mask, source_segment_ids, source_start_positions, \n",
    "        source_end_positions, source_q_types)\n",
    "\n",
    "    train_sampler = BERTRandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=args.train_batch_size)\n",
    "    \n",
    "    data_len = len(new_generated_train_features)\n",
    "    logger.info(\"  Num split examples = %d\", data_len)\n",
    "    logger.info(\"  Batch size = %d\", args.train_batch_size)\n",
    "    num_train_steps = math.ceil(data_len / args.train_batch_size / args.gradient_accumulation_steps)\n",
    "    if num_train_steps == 0 and data_len > 0:\n",
    "        num_train_steps = 1\n",
    "    t_total = num_train_steps\n",
    "    logger.info(\"  Num steps = %d\", num_train_steps)\n",
    "\n",
    "    loss_sum = 0\n",
    "    optimizer_grouped_parameters = get_bert_model_parameters(model)\n",
    "    optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "            lr=args.adapt_learning_rate,\n",
    "            warmup=args.warmup_proportion,\n",
    "            t_total=t_total)\n",
    "    global_step = 0\n",
    "\n",
    "    # íƒ€ê²Ÿ ë°°ì¹˜ ìˆœíšŒ(pseudo-labeling->ì†ŒìŠ¤ ë§¤ì¹­->ê²°í•© í•™ìŠµ)\n",
    "    for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\")):\n",
    "        model.train()\n",
    "        # ì†ŒìŠ¤ ë°°ì¹˜ ìƒ˜í”Œë§ (question type probability ê¸°ë°˜ ìƒìœ„ 3ê°œ)\n",
    "        batch_source = sample_source_batch_top3(source_data, source_q_type_dict, sample_pointer, batch[-1])\n",
    "        batch = tuple(t.to(device) for t in batch[:-1])  # q_type_probsëŠ” ì œì™¸\n",
    "        batch_source = tuple(t.to(device) for t in batch_source)\n",
    "        input_ids, input_masks, segment_ids, start_positions, end_positions, q_types = batch\n",
    "        input_ids_source, input_masks_source, segment_ids_source, start_positions_source, end_positions_source, q_types_source = batch_source\n",
    "        # íƒ€ê²Ÿ + ì†ŒìŠ¤ concat\n",
    "        input_ids = torch.cat((input_ids, input_ids_source), 0)\n",
    "        input_masks = torch.cat((input_masks, input_masks_source), 0)\n",
    "        segment_ids = torch.cat((segment_ids, segment_ids_source), 0)\n",
    "        start_positions = torch.cat((start_positions, start_positions_source), 0)\n",
    "        end_positions = torch.cat((end_positions, end_positions_source), 0)\n",
    "        q_types = torch.cat((q_types, q_types_source), 0)\n",
    "        # QC4QA loss ê³„ì‚° ë° ì—­ì „íŒŒ\n",
    "        loss = model.forward_ours(input_ids, segment_ids, input_masks, start_positions,\n",
    "                end_positions, q_types, lambda_c=args.lambda_c)\n",
    "        if args.gradient_accumulation_steps > 1:\n",
    "            loss = loss / args.gradient_accumulation_steps\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        if (step + 1) % args.gradient_accumulation_steps == 0:\n",
    "            # modify learning rate with special warm up BERT uses\n",
    "            lr_this_step = args.adapt_learning_rate * warmup_linear(global_step / t_total, args.warmup_proportion)\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr_this_step\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "        \n",
    "    final_acc, final_f1 = None, None\n",
    "    if epoch == args.num_train_epochs - 1:\n",
    "        final_acc, final_f1 = evaluation_stage(args, eval_examples, eval_features, device, model,\n",
    "            global_step=global_step, best_acc=None, best_f1=None, logger=logger)\n",
    "        best_acc, best_f1 = compare_performance(args, best_acc, best_f1, final_acc, final_f1, model, logger)\n",
    "    else:\n",
    "        best_acc, best_f1 = evaluation_stage(args, eval_examples, eval_features, device, model,\n",
    "            global_step=global_step, best_acc=best_acc, best_f1=best_f1, logger=logger)\n",
    "    return best_acc, best_f1, final_acc, final_f1\n",
    "\n",
    "\n",
    "def prepare_model(args, device):\n",
    "    # Source ë„ë©”ì¸ì—ì„œ fine-tuned ëª¨ë¸ ë¡œë“œ(run_source.pyëŠ” ì‚¬ì „í•™ìŠµ ëª¨ë¸ ë¡œë“œ)\n",
    "    input_model_file = os.path.join(args.input_dir, args.input_model_file)\n",
    "    model_state_dict = torch.load(input_model_file)\n",
    "    model = BertForQuestionAnsweringQC4QA.from_pretrained(args.bert_model, state_dict=model_state_dict, args=args)\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "\n",
    "def adaptation_stage(args, tokenizer, device, logger, debug=True):\n",
    "    '''\n",
    "    ì—­í• : ë„ë©”ì¸ ì ì‘ ë©”ì¸ ë£¨í”„\n",
    "    '''\n",
    "    ### ë°ì´í„° ìˆ˜ ì¡°ì ˆ ### \n",
    "    sample_limit = 100\n",
    "    \n",
    "    model = prepare_model(args, device)\n",
    "    best_acc, best_f1 = 0, 0\n",
    "    \n",
    "    read_limit = None\n",
    "    if debug:\n",
    "        read_limit = 50\n",
    "\n",
    "    ## Read target training examples\n",
    "    logger.info(\"***** Reading Target Unlabeled Training Samples *****\")\n",
    "    train_features, train_examples = read_features_and_examples(args, args.target_train_file, tokenizer, logger,\n",
    "        use_simple_feature=False, read_examples=True, limit=read_limit)\n",
    "\n",
    "    ## Read source training examples\n",
    "    logger.info(\"***** Reading Source Training Samples *****\")\n",
    "    source_train_features, _ = read_features_and_examples(args, args.source_train_file, tokenizer, logger,\n",
    "        use_simple_feature=False, read_examples=True, limit=read_limit)\n",
    "\n",
    "    # Read evaluation samples\n",
    "    logger.info(\"***** Reading Evaluation Samples *****\")\n",
    "    eval_features, eval_examples = read_features_and_examples(args, args.target_predict_file, tokenizer, logger,\n",
    "        use_simple_feature=False, read_examples=True, limit=read_limit)\n",
    "\n",
    "    removed_feature_index = set()\n",
    "    new_generated_train_features = []\n",
    "    final_acc, final_f1 = 0.0, 0.0\n",
    "    for epoch in trange(int(args.num_train_epochs), desc=\"Epoch\"):\n",
    "        logger.info('\\n')\n",
    "        logger.info(' ###########  Start Training Epoch %d  ###########', epoch + 1)\n",
    "        logger.info('\\n')\n",
    "        best_acc, best_f1, final_acc, final_f1 = comb_adversarial_training_stage(args, train_features, train_examples,\n",
    "                source_train_features, eval_features, eval_examples, removed_feature_index, new_generated_train_features,\n",
    "                model, epoch, device, best_acc, best_f1, logger)\n",
    "        logger.info('\\n')\n",
    "        logger.info(' ###########  End Training Epoch %d  ###########', epoch + 1)\n",
    "        logger.info('\\n')\n",
    "\n",
    "    # Save the final trained model\n",
    "    model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
    "    output_model_file = os.path.join(args.output_dir, args.output_model_file + '.final')\n",
    "    torch.save(model_to_save.state_dict(), output_model_file)\n",
    "    logger.info('The final model has been save')\n",
    "    logger.info('*** The Training Stage is Ended ***')\n",
    "    logger.info('\\n\\nBest EM is %.5f. Best F1 is %.5f', best_acc, best_f1)\n",
    "    logger.info('\\n\\nFinal EM is %.5f. Best F1 is %.5f', final_acc, final_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9468b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/04/2025 14:51:50 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/gayeon39/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = cuda\n"
     ]
    }
   ],
   "source": [
    "# filepath: /home/gayeon39/gayeon/[DA]/preliminary/QC4QA/src/run_qc4qa.ipynb\n",
    "# 3) ë¡œê±°/ë””ë°”ì´ìŠ¤/í† í¬ë‚˜ì´ì € ì¤€ë¹„\n",
    "logger = config_logger(args.logger_path)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = BertTokenizer.from_pretrained(args.bert_model, do_lower_case=args.do_lower_case)\n",
    "\n",
    "print(f\"device = {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45e6e9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2255560/2878386538.py:360: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_state_dict = torch.load(input_model_file)\n",
      "11/04/2025 14:51:51 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/gayeon39/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "11/04/2025 14:51:51 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /home/gayeon39/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpwkiaxkji\n",
      "11/04/2025 14:51:53 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_seq_length\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_BN\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4) ì…ë ¥ ëª¨ë¸ ë¡œë“œ ë° ì ì‘ ë‹¨ê³„ ì‹¤í–‰\n",
    "model = prepare_model(args, device)\n",
    "# adaptation_stage(args, tokenizer, device, logger, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81480207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ” DATA PIPELINE TEST - ë°ì´í„° íë¦„ í™•ì¸\n",
      "================================================================================\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“„ STEP 1: Raw JSON Data\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "âœ“ Question: To whom did the Virgin Mary allegedly appear in 1858 in Lour...\n",
      "âœ“ q_type: 3\n",
      "âœ“ q_type_prob: [0.0, 0.0, 0.016, 0.983, 0.001, 0.0]\n",
      "âœ“ Top-3 types: [(3, 0.983), (2, 0.016), (4, 0.001)]\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# ğŸ§ª í…ŒìŠ¤íŠ¸ ì½”ë“œ: ë°ì´í„° íŒŒì´í”„ë¼ì¸ ê²€ì¦\n",
    "###############################################################################\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ” DATA PIPELINE TEST - ë°ì´í„° íë¦„ í™•ì¸\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Step 1: Raw JSON ë°ì´í„° í™•ì¸\n",
    "print(\"\\n\" + \"â”€\"*80)\n",
    "print(\"ğŸ“„ STEP 1: Raw JSON Data\")\n",
    "print(\"â”€\"*80)\n",
    "sample_qa = train_squad_data[0]['paragraphs'][0]['qas'][0]\n",
    "print(f\"âœ“ Question: {sample_qa['question'][:60]}...\")\n",
    "print(f\"âœ“ q_type: {sample_qa['q_type']}\")\n",
    "print(f\"âœ“ q_type_prob: {sample_qa['q_type_prob']}\")\n",
    "print(f\"âœ“ Top-3 types: {sorted(enumerate(sample_qa['q_type_prob']), key=lambda x: x[1], reverse=True)[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d14cfebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“¦ STEP 2: SquadExample Creation\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "âœ“ Total examples: 87599\n",
      "âœ“ Example[0] type: <class 'da_data_utils.SquadExample'>\n",
      "âœ“ Example[0].q_type: 3\n",
      "âœ“ Example[0].q_type_prob: [0.0, 0.0, 0.016, 0.983, 0.001, 0.0]\n",
      "âœ“ Has q_type_prob attribute: True\n"
     ]
    }
   ],
   "source": [
    "# Step 2: SquadExample ìƒì„± í™•ì¸\n",
    "print(\"\\n\" + \"â”€\"*80)\n",
    "print(\"ğŸ“¦ STEP 2: SquadExample Creation\")\n",
    "print(\"â”€\"*80)\n",
    "test_examples = read_squad_examples(\n",
    "    input_file='../../../data/squad/train-v1.1_classified_qtype_prob.jsonl',\n",
    "    is_training=True,\n",
    "    logger=logger\n",
    ")\n",
    "print(f\"âœ“ Total examples: {len(test_examples)}\")\n",
    "print(f\"âœ“ Example[0] type: {type(test_examples[0])}\")\n",
    "print(f\"âœ“ Example[0].q_type: {test_examples[0].q_type}\")\n",
    "print(f\"âœ“ Example[0].q_type_prob: {test_examples[0].q_type_prob}\")\n",
    "print(f\"âœ“ Has q_type_prob attribute: {hasattr(test_examples[0], 'q_type_prob')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c0b65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: InputFeatures ë³€í™˜ í™•ì¸\n",
    "print(\"\\n\" + \"â”€\"*80)\n",
    "print(\"ğŸ”§ STEP 3: InputFeatures Conversion\")\n",
    "print(\"â”€\"*80)\n",
    "test_features = convert_examples_to_features(\n",
    "    examples=test_examples[:5],  # 5ê°œë§Œ í…ŒìŠ¤íŠ¸\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=args.max_seq_length,\n",
    "    doc_stride=args.doc_stride,\n",
    "    max_query_length=args.max_query_length,\n",
    "    is_training=True,\n",
    "    logger=logger,\n",
    "    use_simple_feature=False\n",
    ")\n",
    "print(f\"âœ“ Total features: {len(test_features)}\")\n",
    "print(f\"âœ“ Feature[0] type: {type(test_features[0])}\")\n",
    "print(f\"âœ“ Feature[0].q_type: {test_features[0].q_type}\")\n",
    "print(f\"âœ“ Feature[0].q_type_prob: {test_features[0].q_type_prob}\")\n",
    "print(f\"âœ“ Has q_type_prob attribute: {hasattr(test_features[0], 'q_type_prob')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab78f8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ¯ STEP 4: TensorDataset Creation\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "âœ“ all_input_ids shape: torch.Size([5, 512])\n",
      "âœ“ all_q_types shape: torch.Size([5])\n",
      "âœ“ all_q_type_probs shape: torch.Size([5, 6])\n",
      "âœ“ Sample q_type: 3\n",
      "âœ“ Sample q_type_prob: [0.0, 0.0, 0.01600000075995922, 0.9829999804496765, 0.0010000000474974513, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Step 4: TensorDataset ìƒì„± í™•ì¸\n",
    "print(\"\\n\" + \"â”€\"*80)\n",
    "print(\"ğŸ¯ STEP 4: TensorDataset Creation\")\n",
    "print(\"â”€\"*80)\n",
    "\n",
    "# q_type_prob ì¶”ì¶œ\n",
    "all_q_type_probs = []\n",
    "for f in test_features:\n",
    "    if hasattr(f, 'q_type_prob') and f.q_type_prob is not None:\n",
    "        all_q_type_probs.append(f.q_type_prob)\n",
    "    else:\n",
    "        # Fallback: one-hot encoding\n",
    "        prob = [0.0] * 6\n",
    "        prob[f.q_type] = 1.0\n",
    "        all_q_type_probs.append(prob)\n",
    "\n",
    "all_input_ids = torch.tensor([f.input_ids for f in test_features], dtype=torch.long)\n",
    "all_q_types = torch.tensor([f.q_type for f in test_features], dtype=torch.long)\n",
    "all_q_type_probs = torch.tensor(all_q_type_probs, dtype=torch.float)\n",
    "\n",
    "print(f\"âœ“ all_input_ids shape: {all_input_ids.shape}\")\n",
    "print(f\"âœ“ all_q_types shape: {all_q_types.shape}\")\n",
    "print(f\"âœ“ all_q_type_probs shape: {all_q_type_probs.shape}\")\n",
    "print(f\"âœ“ Sample q_type: {all_q_types[0].item()}\")\n",
    "print(f\"âœ“ Sample q_type_prob: {all_q_type_probs[0].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa88e7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ” STEP 5: Top-3 Question Type Extraction\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "  Sample 0:\n",
      "    â€¢ Original q_type: 3\n",
      "    â€¢ Full q_type_prob: [0.0, 0.0, 0.01600000075995922, 0.9829999804496765, 0.0010000000474974513, 0.0]\n",
      "    â€¢ Top-3 indices: [3, 2, 4]\n",
      "    â€¢ Top-3 values: ['0.983', '0.016', '0.001']\n",
      "\n",
      "  Sample 1:\n",
      "    â€¢ Original q_type: 2\n",
      "    â€¢ Full q_type_prob: [0.0, 0.0010000000474974513, 0.9950000047683716, 0.004000000189989805, 0.0, 0.0]\n",
      "    â€¢ Top-3 indices: [2, 3, 1]\n",
      "    â€¢ Top-3 values: ['0.995', '0.004', '0.001']\n",
      "\n",
      "  Sample 2:\n",
      "    â€¢ Original q_type: 2\n",
      "    â€¢ Full q_type_prob: [0.0, 0.0010000000474974513, 0.9229999780654907, 0.01899999938905239, 0.05400000140070915, 0.0020000000949949026]\n",
      "    â€¢ Top-3 indices: [2, 4, 3]\n",
      "    â€¢ Top-3 values: ['0.923', '0.054', '0.019']\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Top-3 ì¶”ì¶œ í…ŒìŠ¤íŠ¸\n",
    "print(\"\\n\" + \"â”€\"*80)\n",
    "print(\"ğŸ” STEP 5: Top-3 Question Type Extraction\")\n",
    "print(\"â”€\"*80)\n",
    "\n",
    "for i in range(min(3, len(all_q_type_probs))):\n",
    "    q_type_prob = all_q_type_probs[i]\n",
    "    top3_indices = torch.topk(q_type_prob, k=3).indices.tolist()\n",
    "    top3_values = torch.topk(q_type_prob, k=3).values.tolist()\n",
    "    \n",
    "    print(f\"\\n  Sample {i}:\")\n",
    "    print(f\"    â€¢ Original q_type: {all_q_types[i].item()}\")\n",
    "    print(f\"    â€¢ Full q_type_prob: {q_type_prob.tolist()}\")\n",
    "    print(f\"    â€¢ Top-3 indices: {top3_indices}\")\n",
    "    print(f\"    â€¢ Top-3 values: {[f'{v:.3f}' for v in top3_values]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcf380a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ”— STEP 6: Source-Target Matching Simulation\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Mock Source Distribution:\n",
      "  â€¢ Type 0: 3 samples\n",
      "  â€¢ Type 1: 2 samples\n",
      "  â€¢ Type 2: 3 samples\n",
      "  â€¢ Type 3: 4 samples\n",
      "  â€¢ Type 4: 1 samples\n",
      "  â€¢ Type 5: 2 samples\n",
      "\n",
      "Target Sample:\n",
      "  â€¢ q_type_prob: [0.0, 0.0, 0.01600000075995922, 0.9829999804496765, 0.0010000000474974513, 0.0]\n",
      "  â€¢ Top-3 types: [3, 2, 4]\n",
      "\n",
      "Matched Source Samples (1 target â†’ 3 sources):\n",
      "  â€¢ Rank 1: Type 3 â†’ Source sample index 8\n",
      "  â€¢ Rank 2: Type 2 â†’ Source sample index 5\n",
      "  â€¢ Rank 3: Type 4 â†’ Source sample index 12\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Source-Target ë§¤ì¹­ ì‹œë®¬ë ˆì´ì…˜\n",
    "print(\"\\n\" + \"â”€\"*80)\n",
    "print(\"ğŸ”— STEP 6: Source-Target Matching Simulation\")\n",
    "print(\"â”€\"*80)\n",
    "\n",
    "# Mock source data-> valueëŠ” source featureì˜ ì¸ë±ìŠ¤ ì˜ë¯¸\n",
    "source_q_type_dict = {\n",
    "    0: [0, 1, 2],      # What ì§ˆë¬¸ 3ê°œ\n",
    "    1: [3, 4],         # When ì§ˆë¬¸ 2ê°œ\n",
    "    2: [5, 6, 7],      # Where ì§ˆë¬¸ 3ê°œ\n",
    "    3: [8, 9, 10, 11], # Who ì§ˆë¬¸ 4ê°œ\n",
    "    4: [12],           # Why ì§ˆë¬¸ 1ê°œ\n",
    "    5: [13, 14]        # How ì§ˆë¬¸ 2ê°œ\n",
    "}\n",
    "\n",
    "print(\"Mock Source Distribution:\")\n",
    "for q_type, indices in source_q_type_dict.items():\n",
    "    print(f\"  â€¢ Type {q_type}: {len(indices)} samples\")\n",
    "\n",
    "# íƒ€ê²Ÿ ìƒ˜í”Œ 1ê°œì— ëŒ€í•´ ë§¤ì¹­ ì‹œë®¬ë ˆì´ì…˜\n",
    "target_sample_prob = all_q_type_probs[0]\n",
    "top3_indices = torch.topk(target_sample_prob, k=3).indices.tolist()\n",
    "\n",
    "print(f\"\\nTarget Sample:\")\n",
    "print(f\"  â€¢ q_type_prob: {target_sample_prob.tolist()}\")\n",
    "print(f\"  â€¢ Top-3 types: {top3_indices}\")\n",
    "\n",
    "print(f\"\\nMatched Source Samples (1 target â†’ 3 sources):\")\n",
    "for rank, q_type in enumerate(top3_indices):\n",
    "    if len(source_q_type_dict[q_type]) > 0:\n",
    "        source_idx = source_q_type_dict[q_type][0]  # ì²« ë²ˆì§¸ ìƒ˜í”Œ ì„ íƒ\n",
    "        print(f\"  â€¢ Rank {rank+1}: Type {q_type} â†’ Source sample index {source_idx}\")\n",
    "    else:\n",
    "        print(f\"  â€¢ Rank {rank+1}: Type {q_type} â†’ âš ï¸ No source samples available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a579312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š STEP 7: Batch Size Comparison\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Before (1:1 matching):\n",
      "  â€¢ Target batch: 12\n",
      "  â€¢ Source batch: 12\n",
      "  â€¢ Total batch: 24\n",
      "\n",
      "After (1:3 matching with top-3 q_type_prob):\n",
      "  â€¢ Target batch: 12\n",
      "  â€¢ Source batch: 36 (ìµœëŒ€)\n",
      "  â€¢ Total batch: 48 (ìµœëŒ€)\n",
      "  â€¢ Memory increase: 100.0%\n",
      "\n",
      "================================================================================\n",
      "âœ… DATA PIPELINE TEST COMPLETED\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Step 7: ë°°ì¹˜ í¬ê¸° ë¹„êµ\n",
    "print(\"\\n\" + \"â”€\"*80)\n",
    "print(\"ğŸ“Š STEP 7: Batch Size Comparison\")\n",
    "print(\"â”€\"*80)\n",
    "\n",
    "target_batch_size = 12\n",
    "source_batch_size_old = target_batch_size  # Before: 1:1 ë§¤ì¹­\n",
    "source_batch_size_new = target_batch_size * 3  # After: 1:3 ë§¤ì¹­\n",
    "\n",
    "print(f\"Before (1:1 matching):\")\n",
    "print(f\"  â€¢ Target batch: {target_batch_size}\")\n",
    "print(f\"  â€¢ Source batch: {source_batch_size_old}\")\n",
    "print(f\"  â€¢ Total batch: {target_batch_size + source_batch_size_old}\")\n",
    "\n",
    "print(f\"\\nAfter (1:3 matching with top-3 q_type_prob):\")\n",
    "print(f\"  â€¢ Target batch: {target_batch_size}\")\n",
    "print(f\"  â€¢ Source batch: {source_batch_size_new} (ìµœëŒ€)\")\n",
    "print(f\"  â€¢ Total batch: {target_batch_size + source_batch_size_new} (ìµœëŒ€)\")\n",
    "print(f\"  â€¢ Memory increase: {((target_batch_size + source_batch_size_new) / (target_batch_size + source_batch_size_old) - 1) * 100:.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… DATA PIPELINE TEST COMPLETED\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "659c7e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ“ TRAINING BATCH SIMULATION - ì‹¤ì œ í•™ìŠµ ë°ì´í„° í™•ì¸\n",
      "================================================================================\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“ Loading Real Data (Source + Target)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "âœ“ Source features loaded: 20\n",
      "âœ“ Target features loaded: 10\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# ğŸ§ª í…ŒìŠ¤íŠ¸ ì½”ë“œ 2: ì‹¤ì œ í•™ìŠµ ë°°ì¹˜ ì‹œë®¬ë ˆì´ì…˜\n",
    "###############################################################################\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ“ TRAINING BATCH SIMULATION - ì‹¤ì œ í•™ìŠµ ë°ì´í„° í™•ì¸\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ì‹¤ì œ ë°ì´í„° ë¡œë“œ (ì†ŒëŸ‰)\n",
    "print(\"\\n\" + \"â”€\"*80)\n",
    "print(\"ğŸ“ Loading Real Data (Source + Target)\")\n",
    "print(\"â”€\"*80)\n",
    "train_squad_path = '../../../data/squad/train-v1.1_classified_qtype_prob.jsonl'\n",
    "train_cnn_path = '../../../data/cnn/cnn_train_classified_qtype_prob.jsonl'\n",
    "\n",
    "# Source features ë¡œë“œ\n",
    "source_features, _ = read_features_and_examples(\n",
    "    args, \n",
    "    args.source_train_file, \n",
    "    tokenizer, \n",
    "    logger,\n",
    "    use_simple_feature=False, \n",
    "    read_examples=True, \n",
    "    limit=20  # 20ê°œë§Œ ë¡œë“œ\n",
    ")\n",
    "\n",
    "# Target features ë¡œë“œ\n",
    "target_features, target_examples = read_features_and_examples(\n",
    "    args,\n",
    "    args.target_train_file,\n",
    "    tokenizer,\n",
    "    logger,\n",
    "    use_simple_feature=False,\n",
    "    read_examples=True,\n",
    "    limit=10  # 10ê°œë§Œ ë¡œë“œ\n",
    ")\n",
    "\n",
    "print(f\"âœ“ Source features loaded: {len(source_features)}\")\n",
    "print(f\"âœ“ Target features loaded: {len(target_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "050971a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š Source Q-Type Distribution\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  â€¢ Type 0: 0 samples\n",
      "  â€¢ Type 1: 0 samples\n",
      "  â€¢ Type 2: 7 samples\n",
      "  â€¢ Type 3: 5 samples\n",
      "  â€¢ Type 4: 1 samples\n",
      "  â€¢ Type 5: 7 samples\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ¯ Target Q-Type Probability Check\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "âœ“ Target samples with q_type_prob: 10\n",
      "\n",
      "First 3 target samples:\n",
      "  Sample 0: [0.001, 0.001, 0.171, 0.76, 0.064, 0.002]\n",
      "  Sample 1: [0.001, 0.001, 0.171, 0.76, 0.064, 0.002]\n",
      "  Sample 2: [0.001, 0.001, 0.171, 0.76, 0.064, 0.002]\n"
     ]
    }
   ],
   "source": [
    "# Source q_type ë¶„í¬ í™•ì¸\n",
    "print(\"\\n\" + \"â”€\"*80)\n",
    "print(\"ğŸ“Š Source Q-Type Distribution\")\n",
    "print(\"â”€\"*80)\n",
    "\n",
    "source_q_type_dict = {0: [], 1: [], 2: [], 3: [], 4: [], 5: []}\n",
    "for idx, f in enumerate(source_features):\n",
    "    source_q_type_dict[f.q_type].append(idx)\n",
    "\n",
    "for q_type, indices in source_q_type_dict.items():\n",
    "    print(f\"  â€¢ Type {q_type}: {len(indices)} samples\")\n",
    "    \n",
    "# Target q_type_prob í™•ì¸\n",
    "print(\"\\n\" + \"â”€\"*80)\n",
    "print(\"ğŸ¯ Target Q-Type Probability Check\")\n",
    "print(\"â”€\"*80)\n",
    "\n",
    "target_q_type_probs = []\n",
    "for f in target_features:\n",
    "    if hasattr(f, 'q_type_prob') and f.q_type_prob is not None:\n",
    "        target_q_type_probs.append(f.q_type_prob)\n",
    "    else:\n",
    "        prob = [0.0] * 6\n",
    "        prob[f.q_type] = 1.0\n",
    "        target_q_type_probs.append(prob)\n",
    "\n",
    "print(f\"âœ“ Target samples with q_type_prob: {len(target_q_type_probs)}\")\n",
    "print(f\"\\nFirst 3 target samples:\")\n",
    "for i in range(min(3, len(target_q_type_probs))):\n",
    "    print(f\"  Sample {i}: {target_q_type_probs[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d3d4fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ”„ Batch Creation Simulation\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Target Batch Size: 4\n",
      "Target Batch q_type_probs shape: torch.Size([4, 6])\n",
      "\n",
      "ğŸ”— Source Sampling (Top-3 Matching):\n",
      "\n",
      "  Target 0:\n",
      "    Top-3 types: [3, 2, 4]\n",
      "    Top-3 probs: ['0.760', '0.171', '0.064']\n",
      "    Matched sources:\n",
      "      â†’ Type 3: Source[0]\n",
      "      â†’ Type 2: Source[2]\n",
      "      â†’ Type 4: Source[10]\n",
      "\n",
      "  Target 1:\n",
      "    Top-3 types: [3, 2, 4]\n",
      "    Top-3 probs: ['0.760', '0.171', '0.064']\n",
      "    Matched sources:\n",
      "      â†’ Type 3: Source[0]\n",
      "      â†’ Type 2: Source[2]\n",
      "      â†’ Type 4: Source[10]\n",
      "\n",
      "  Target 2:\n",
      "    Top-3 types: [3, 2, 4]\n",
      "    Top-3 probs: ['0.760', '0.171', '0.064']\n",
      "    Matched sources:\n",
      "      â†’ Type 3: Source[0]\n",
      "      â†’ Type 2: Source[2]\n",
      "      â†’ Type 4: Source[10]\n",
      "\n",
      "  Target 3:\n",
      "    Top-3 types: [3, 2, 4]\n",
      "    Top-3 probs: ['0.760', '0.171', '0.064']\n",
      "    Matched sources:\n",
      "      â†’ Type 3: Source[0]\n",
      "      â†’ Type 2: Source[2]\n",
      "      â†’ Type 4: Source[10]\n",
      "\n",
      "âœ“ Total source samples matched: 12\n",
      "âœ“ Expected: 12 (ìµœëŒ€)\n",
      "âœ“ Actual: 12\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“¦ Final Batch Composition\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Target samples: 4\n",
      "Source samples: 12\n",
      "Total batch size: 16\n",
      "Memory ratio: 2.00x (compared to 1:1 matching)\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“ Tensor Shapes in Training Loop\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Target tensors:\n",
      "  â€¢ input_ids: torch.Size([4, 512])\n",
      "  â€¢ q_types: torch.Size([4])\n",
      "  â€¢ q_type_probs: torch.Size([4, 6])\n",
      "\n",
      "Source tensors:\n",
      "  â€¢ input_ids: torch.Size([12, 512])\n",
      "  â€¢ q_types: torch.Size([12])\n",
      "\n",
      "Concatenated tensors (input to model):\n",
      "  â€¢ input_ids: torch.Size([16, 512])\n",
      "  â€¢ q_types: torch.Size([16])\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š Q-Type Distribution in Batch\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Target batch distribution:\n",
      "  â€¢ Type 3: 4 samples\n",
      "\n",
      "Source batch distribution:\n",
      "  â€¢ Type 2: 4 samples\n",
      "  â€¢ Type 3: 4 samples\n",
      "  â€¢ Type 4: 4 samples\n",
      "\n",
      "Combined batch distribution:\n",
      "  â€¢ Type 2: 4 samples\n",
      "  â€¢ Type 3: 8 samples\n",
      "  â€¢ Type 4: 4 samples\n",
      "\n",
      "================================================================================\n",
      "âœ… TRAINING BATCH SIMULATION COMPLETED\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ë°°ì¹˜ ìƒì„± ì‹œë®¬ë ˆì´ì…˜\n",
    "print(\"\\n\" + \"â”€\"*80)\n",
    "print(\"ğŸ”„ Batch Creation Simulation\")\n",
    "print(\"â”€\"*80)\n",
    "\n",
    "# Target ë°°ì¹˜ ìƒì„± (4ê°œ ìƒ˜í”Œ)\n",
    "batch_size = 4\n",
    "target_batch_probs = torch.tensor(target_q_type_probs[:batch_size], dtype=torch.float)\n",
    "\n",
    "print(f\"Target Batch Size: {batch_size}\")\n",
    "print(f\"Target Batch q_type_probs shape: {target_batch_probs.shape}\")\n",
    "\n",
    "# Source ë°°ì¹˜ ìƒ˜í”Œë§ ì‹œë®¬ë ˆì´ì…˜\n",
    "print(\"\\nğŸ”— Source Sampling (Top-3 Matching):\")\n",
    "\n",
    "source_indices = []\n",
    "for i, q_type_prob in enumerate(target_batch_probs):\n",
    "    top3_indices = torch.topk(q_type_prob, k=3).indices.tolist()\n",
    "    top3_values = torch.topk(q_type_prob, k=3).values.tolist()\n",
    "    \n",
    "    print(f\"\\n  Target {i}:\")\n",
    "    print(f\"    Top-3 types: {top3_indices}\")\n",
    "    print(f\"    Top-3 probs: {[f'{v:.3f}' for v in top3_values]}\")\n",
    "    print(f\"    Matched sources:\")\n",
    "    \n",
    "    for rank, q_type in enumerate(top3_indices):\n",
    "        if len(source_q_type_dict[q_type]) > 0:\n",
    "            source_idx = source_q_type_dict[q_type][rank % len(source_q_type_dict[q_type])]\n",
    "            source_indices.append(source_idx)\n",
    "            print(f\"      â†’ Type {q_type}: Source[{source_idx}]\")\n",
    "        else:\n",
    "            print(f\"      â†’ Type {q_type}: âš ï¸ No source available (skip)\")\n",
    "\n",
    "print(f\"\\nâœ“ Total source samples matched: {len(source_indices)}\")\n",
    "print(f\"âœ“ Expected: {batch_size * 3} (ìµœëŒ€)\")\n",
    "print(f\"âœ“ Actual: {len(source_indices)}\")\n",
    "\n",
    "# ìµœì¢… ë°°ì¹˜ í¬ê¸°\n",
    "print(\"\\n\" + \"â”€\"*80)\n",
    "print(\"ğŸ“¦ Final Batch Composition\")\n",
    "print(\"â”€\"*80)\n",
    "\n",
    "print(f\"Target samples: {batch_size}\")\n",
    "print(f\"Source samples: {len(source_indices)}\")\n",
    "print(f\"Total batch size: {batch_size + len(source_indices)}\")\n",
    "print(f\"Memory ratio: {(batch_size + len(source_indices)) / (batch_size * 2):.2f}x (compared to 1:1 matching)\")\n",
    "\n",
    "# í…ì„œ í˜•íƒœ í™•ì¸\n",
    "print(\"\\n\" + \"â”€\"*80)\n",
    "print(\"ğŸ“ Tensor Shapes in Training Loop\")\n",
    "print(\"â”€\"*80)\n",
    "\n",
    "# Target í…ì„œ\n",
    "target_input_ids = torch.tensor([f.input_ids for f in target_features[:batch_size]], dtype=torch.long)\n",
    "target_q_types = torch.tensor([f.q_type for f in target_features[:batch_size]], dtype=torch.long)\n",
    "\n",
    "print(f\"Target tensors:\")\n",
    "print(f\"  â€¢ input_ids: {target_input_ids.shape}\")\n",
    "print(f\"  â€¢ q_types: {target_q_types.shape}\")\n",
    "print(f\"  â€¢ q_type_probs: {target_batch_probs.shape}\")\n",
    "\n",
    "# Source í…ì„œ (ì‹œë®¬ë ˆì´ì…˜)\n",
    "source_input_ids = torch.tensor([source_features[idx].input_ids for idx in source_indices], dtype=torch.long)\n",
    "source_q_types = torch.tensor([source_features[idx].q_type for idx in source_indices], dtype=torch.long)\n",
    "\n",
    "print(f\"\\nSource tensors:\")\n",
    "print(f\"  â€¢ input_ids: {source_input_ids.shape}\")\n",
    "print(f\"  â€¢ q_types: {source_q_types.shape}\")\n",
    "\n",
    "# Concatenated í…ì„œ\n",
    "concat_input_ids = torch.cat([target_input_ids, source_input_ids], dim=0)\n",
    "concat_q_types = torch.cat([target_q_types, source_q_types], dim=0)\n",
    "\n",
    "print(f\"\\nConcatenated tensors (input to model):\")\n",
    "print(f\"  â€¢ input_ids: {concat_input_ids.shape}\")\n",
    "print(f\"  â€¢ q_types: {concat_q_types.shape}\")\n",
    "\n",
    "# Q-type ë¶„í¬ í™•ì¸\n",
    "print(\"\\n\" + \"â”€\"*80)\n",
    "print(\"ğŸ“Š Q-Type Distribution in Batch\")\n",
    "print(\"â”€\"*80)\n",
    "\n",
    "from collections import Counter\n",
    "target_type_dist = Counter(target_q_types.tolist())\n",
    "source_type_dist = Counter(source_q_types.tolist())\n",
    "concat_type_dist = Counter(concat_q_types.tolist())\n",
    "\n",
    "print(\"Target batch distribution:\")\n",
    "for q_type in sorted(target_type_dist.keys()):\n",
    "    print(f\"  â€¢ Type {q_type}: {target_type_dist[q_type]} samples\")\n",
    "\n",
    "print(\"\\nSource batch distribution:\")\n",
    "for q_type in sorted(source_type_dist.keys()):\n",
    "    print(f\"  â€¢ Type {q_type}: {source_type_dist[q_type]} samples\")\n",
    "\n",
    "print(\"\\nCombined batch distribution:\")\n",
    "for q_type in sorted(concat_type_dist.keys()):\n",
    "    print(f\"  â€¢ Type {q_type}: {concat_type_dist[q_type]} samples\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… TRAINING BATCH SIMULATION COMPLETED\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "runtime_debug_v3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ”¥ ADDING RUNTIME LOGGING TO TRAINING LOOP\n",
      "================================================================================\n",
      "âœ… Runtime logging function defined.\n",
      "\n",
      "To use it, run:\n",
      "  globals()['comb_adversarial_training_stage'] = comb_adversarial_training_stage_with_logging\n",
      "  adaptation_stage(args, tokenizer, device, logger, debug=True)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def comb_adversarial_training_stage_with_logging(args, target_train_features, target_train_examples, source_train_features,\n",
    "            eval_features, eval_examples, removed_feature_index, new_generated_train_features, model, epoch,\n",
    "            device, best_acc, best_f1, logger):\n",
    "    \"\"\"\n",
    "    ë””ë²„ê¹… ì¶”ê°€ : ì‹¤ì œ í•™ìŠµ ë£¨í”„ì—ì„œ ë°°ì¹˜ í¬ê¸° ë¡œê¹…\n",
    "    \"\"\"\n",
    "    def sample_source_batch_top3(source_data, source_q_type_dict, sample_pointer, q_type_probs):\n",
    "        \"\"\"\n",
    "        q_type_probs ê¸°ë°˜ ìƒìœ„ 3ê°œ íƒ€ì…ì—ì„œ ì†ŒìŠ¤ ìƒ˜í”Œë§ (ë¡œê¹… ì¶”ê°€)\n",
    "        \"\"\"\n",
    "        output_idx = []\n",
    "        batch_top3_stats = []  # ê° ìƒ˜í”Œì˜ top-3 ì •ë³´ ì €ì¥\n",
    "\n",
    "        for batch_idx, q_type_prob in enumerate(q_type_probs):\n",
    "            top3_indices = torch.topk(q_type_prob, k=3).indices.tolist()\n",
    "            top3_values = torch.topk(q_type_prob, k=3).values.tolist()\n",
    "            \n",
    "            batch_top3_stats.append({\n",
    "                \"batch_idx\": batch_idx,\n",
    "                \"top3_types\": top3_indices,\n",
    "                \"top3_probs\": top3_values,\n",
    "                \"matched_sources\": []\n",
    "            })\n",
    "\n",
    "            for q_type in top3_indices:\n",
    "                if len(source_q_type_dict[q_type]) == 0:\n",
    "                    batch_top3_stats[-1][\"matched_sources\"].append(None)\n",
    "                    continue\n",
    "\n",
    "                next_q_idx = sample_pointer[q_type] % len(source_q_type_dict[q_type])\n",
    "                source_idx = source_q_type_dict[q_type][next_q_idx]\n",
    "                output_idx.append(source_idx)\n",
    "                batch_top3_stats[-1][\"matched_sources\"].append(source_idx)\n",
    "                sample_pointer[q_type] += 1\n",
    "\n",
    "        input_ids_source, input_masks_source, segment_ids_source, start_positions_source, end_positions_source, \\\n",
    "            q_types_source = [], [], [], [], [], []\n",
    "        for idx in output_idx:\n",
    "            input_ids_source.append(source_data[idx][0].unsqueeze(0))\n",
    "            input_masks_source.append(source_data[idx][1].unsqueeze(0))\n",
    "            segment_ids_source.append(source_data[idx][2].unsqueeze(0))\n",
    "            start_positions_source.append(source_data[idx][3].unsqueeze(0))\n",
    "            end_positions_source.append(source_data[idx][4].unsqueeze(0))\n",
    "            q_types_source.append(source_data[idx][5].unsqueeze(0))\n",
    "\n",
    "        return (torch.vstack(input_ids_source), torch.vstack(input_masks_source), torch.vstack(segment_ids_source), \\\n",
    "            torch.cat(start_positions_source, -1), torch.cat(end_positions_source, -1), torch.cat(q_types_source, -1),\n",
    "            batch_top3_stats)  # í†µê³„ ì •ë³´ë„ ë°˜í™˜\n",
    "\n",
    "    # Generate self-training samples\n",
    "    new_generated_train_features, removed_feature_index = generate_self_training_samples(args, target_train_examples,\n",
    "        target_train_features, device, model, removed_feature_index, new_generated_train_features, args.generate_prob_th,\n",
    "        logger)\n",
    "    if new_generated_train_features is None:\n",
    "        sys.exit()\n",
    "    \n",
    "    logger.info(\"\\n\")\n",
    "    logger.info(\"====================  Start Adversarial Training Stage  ====================\")\n",
    "    \n",
    "    # q_type_prob ì¶”ì¶œ\n",
    "    all_q_type_probs = []\n",
    "    fallback_count = 0\n",
    "    for f in new_generated_train_features:\n",
    "        if hasattr(f, \"q_type_prob\") and f.q_type_prob is not None:\n",
    "            all_q_type_probs.append(f.q_type_prob)\n",
    "        else:\n",
    "            prob = [0.0] * 6\n",
    "            prob[f.q_type] = 1.0\n",
    "            all_q_type_probs.append(prob)\n",
    "            fallback_count += 1\n",
    "    \n",
    "    # ğŸ”¥ ë¡œê¹…: Fallback ì‚¬ìš©ë¥ \n",
    "    print(f\"\\nğŸ”¥ RUNTIME LOG - q_type_prob Status:\")\n",
    "    print(f\"  Total target features: {len(new_generated_train_features)}\")\n",
    "    print(f\"  Fallback (one-hot) count: {fallback_count}\")\n",
    "    print(f\"  Proper q_type_prob count: {len(new_generated_train_features) - fallback_count}\")\n",
    "    print(f\"  Fallback rate: {fallback_count / len(new_generated_train_features) * 100:.1f}%\\n\")\n",
    "    \n",
    "    all_input_ids = torch.tensor([f.input_ids for f in new_generated_train_features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in new_generated_train_features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in new_generated_train_features], dtype=torch.long)\n",
    "    all_start_positions = torch.tensor([f.start_position for f in new_generated_train_features], dtype=torch.long)\n",
    "    all_end_positions = torch.tensor([f.end_position for f in new_generated_train_features], dtype=torch.long)\n",
    "    all_q_types = torch.tensor([f.q_type for f in new_generated_train_features], dtype=torch.long)\n",
    "    all_q_type_probs = torch.tensor(all_q_type_probs, dtype=torch.float)\n",
    "    \n",
    "    train_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids,\n",
    "        all_start_positions, all_end_positions, all_q_types, all_q_type_probs)\n",
    "    \n",
    "    # Source data ì¤€ë¹„\n",
    "    source_input_ids = torch.tensor([f.input_ids for f in source_train_features], dtype=torch.long)\n",
    "    source_input_mask = torch.tensor([f.input_mask for f in source_train_features], dtype=torch.long)\n",
    "    source_segment_ids = torch.tensor([f.segment_ids for f in source_train_features], dtype=torch.long)\n",
    "    source_start_positions = torch.tensor([f.start_position for f in source_train_features], dtype=torch.long)\n",
    "    source_end_positions = torch.tensor([f.end_position for f in source_train_features], dtype=torch.long)\n",
    "    source_q_types = []\n",
    "    source_q_type_dict = {0: [], 1: [], 2: [], 3: [], 4: [], 5: []}\n",
    "    for idx, f in enumerate(source_train_features):\n",
    "        source_q_types.append(f.q_type)\n",
    "        source_q_type_dict[f.q_type].append(idx)\n",
    "    source_q_types = torch.tensor(source_q_types, dtype=torch.long)\n",
    "    for key in source_q_type_dict.keys():\n",
    "        random.shuffle(source_q_type_dict[key])\n",
    "    sample_pointer = [0] * 6\n",
    "    source_data = TensorDataset(source_input_ids, source_input_mask, source_segment_ids, source_start_positions, \n",
    "        source_end_positions, source_q_types)\n",
    "\n",
    "    # ğŸ”¥ ë¡œê¹…: Source ë¶„í¬\n",
    "    print(f\"ğŸ”¥ RUNTIME LOG - Source Q-Type Distribution:\")\n",
    "    for q_type in sorted(source_q_type_dict.keys()):\n",
    "        print(f\"  Type {q_type}: {len(source_q_type_dict[q_type])} samples\")\n",
    "    print()\n",
    "\n",
    "    train_sampler = BERTRandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=args.train_batch_size)\n",
    "    \n",
    "    data_len = len(new_generated_train_features)\n",
    "    logger.info(\"  Num split examples = %d\", data_len)\n",
    "    logger.info(\"  Batch size = %d\", args.train_batch_size)\n",
    "    num_train_steps = math.ceil(data_len / args.train_batch_size / args.gradient_accumulation_steps)\n",
    "    if num_train_steps == 0 and data_len > 0:\n",
    "        num_train_steps = 1\n",
    "    t_total = num_train_steps\n",
    "    logger.info(\"  Num steps = %d\", num_train_steps)\n",
    "\n",
    "    optimizer_grouped_parameters = get_bert_model_parameters(model)\n",
    "    optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "            lr=args.adapt_learning_rate,\n",
    "            warmup=args.warmup_proportion,\n",
    "            t_total=t_total)\n",
    "    global_step = 0\n",
    "\n",
    "    # ğŸ”¥ ë°°ì¹˜ë³„ ë¡œê¹… (ì²« 3ê°œ ë°°ì¹˜ë§Œ)\n",
    "    print(f\"\\nğŸ”¥ RUNTIME LOG - Training Loop (First 3 Batches):\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\")):\n",
    "        model.train()\n",
    "        \n",
    "        # ğŸ”¥ ë¡œê¹…: ë°°ì¹˜ ì •ë³´ (ì²« 3ê°œë§Œ)\n",
    "        if step < 3:\n",
    "            print(f\"\\n--- Batch {step} ---\")\n",
    "            print(f\"Target batch size: {batch[0].shape[0]}\")\n",
    "            print(f\"Sample q_type_prob[0]: {batch[-1][0].tolist()}\")\n",
    "            top3 = torch.topk(batch[-1][0], k=3)\n",
    "            print(f\"Top-3 types: {top3.indices.tolist()}, probs: {[f'{v:.3f}' for v in top3.values.tolist()]}\")\n",
    "        \n",
    "        # ì†ŒìŠ¤ ë°°ì¹˜ ìƒ˜í”Œë§\n",
    "        result = sample_source_batch_top3(source_data, source_q_type_dict, sample_pointer, batch[-1])\n",
    "        batch_source = result[:6]  # í…ì„œë“¤ë§Œ\n",
    "        batch_stats = result[6]     # í†µê³„ ì •ë³´\n",
    "        \n",
    "        # ğŸ”¥ ë¡œê¹…: ì†ŒìŠ¤ ë°°ì¹˜ í¬ê¸° (ì²« 3ê°œë§Œ)\n",
    "        if step < 3:\n",
    "            print(f\"Source batch size: {batch_source[0].shape[0]}\")\n",
    "            print(f\"Source sampling ratio: {batch_source[0].shape[0] / batch[0].shape[0]:.2f}x\")\n",
    "            print(f\"First target sample matched to sources:\")\n",
    "            first_stats = batch_stats[0]\n",
    "            for i, (typ, prob, src) in enumerate(zip(first_stats[\"top3_types\"], \n",
    "                                                       first_stats[\"top3_probs\"],\n",
    "                                                       first_stats[\"matched_sources\"])):\n",
    "                if src is not None:\n",
    "                    print(f\"  Rank {i+1}: Type {typ} (prob={prob:.3f}) â†’ Source[{src}]\")\n",
    "                else:\n",
    "                    print(f\"  Rank {i+1}: Type {typ} (prob={prob:.3f}) â†’ âš ï¸  No source\")\n",
    "        \n",
    "        batch = tuple(t.to(device) for t in batch[:-1])\n",
    "        batch_source = tuple(t.to(device) for t in batch_source)\n",
    "        input_ids, input_masks, segment_ids, start_positions, end_positions, q_types = batch\n",
    "        input_ids_source, input_masks_source, segment_ids_source, start_positions_source, end_positions_source, q_types_source = batch_source\n",
    "        \n",
    "        # íƒ€ê²Ÿ + ì†ŒìŠ¤ concat\n",
    "        input_ids = torch.cat((input_ids, input_ids_source), 0)\n",
    "        input_masks = torch.cat((input_masks, input_masks_source), 0)\n",
    "        segment_ids = torch.cat((segment_ids, segment_ids_source), 0)\n",
    "        start_positions = torch.cat((start_positions, start_positions_source), 0)\n",
    "        end_positions = torch.cat((end_positions, end_positions_source), 0)\n",
    "        q_types = torch.cat((q_types, q_types_source), 0)\n",
    "        \n",
    "        # ğŸ”¥ ë¡œê¹…: ìµœì¢… ë°°ì¹˜ í¬ê¸° (ì²« 3ê°œë§Œ)\n",
    "        if step < 3:\n",
    "            print(f\"Combined batch size: {input_ids.shape[0]}\")\n",
    "            from collections import Counter\n",
    "            q_type_dist = Counter(q_types.cpu().tolist())\n",
    "            print(f\"Q-type distribution: {dict(sorted(q_type_dist.items()))}\")\n",
    "        \n",
    "        # QC4QA loss ê³„ì‚°\n",
    "        loss = model.forward_ours(input_ids, segment_ids, input_masks, start_positions,\n",
    "                end_positions, q_types, lambda_c=args.lambda_c)\n",
    "        if args.gradient_accumulation_steps > 1:\n",
    "            loss = loss / args.gradient_accumulation_steps\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        if (step + 1) % args.gradient_accumulation_steps == 0:\n",
    "            lr_this_step = args.adapt_learning_rate * warmup_linear(global_step / t_total, args.warmup_proportion)\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group[\"lr\"] = lr_this_step\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ğŸ”¥ TRAINING LOOP COMPLETED\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "        \n",
    "    final_acc, final_f1 = None, None\n",
    "    if epoch == args.num_train_epochs - 1:\n",
    "        final_acc, final_f1 = evaluation_stage(args, eval_examples, eval_features, device, model,\n",
    "            global_step=global_step, best_acc=None, best_f1=None, logger=logger)\n",
    "        best_acc, best_f1 = compare_performance(args, best_acc, best_f1, final_acc, final_f1, model, logger)\n",
    "    else:\n",
    "        best_acc, best_f1 = evaluation_stage(args, eval_examples, eval_features, device, model,\n",
    "            global_step=global_step, best_acc=best_acc, best_f1=best_f1, logger=logger)\n",
    "    return best_acc, best_f1, final_acc, final_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f0c3940",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2255560/1948527526.py:360: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_state_dict = torch.load(input_model_file)\n",
      "11/04/2025 15:10:04 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/gayeon39/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "11/04/2025 15:10:04 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /home/gayeon39/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpt_69n218\n",
      "11/04/2025 15:10:06 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_seq_length\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_BN\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "11/04/2025 15:10:08 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/gayeon39/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "11/04/2025 15:10:08 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /home/gayeon39/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpag6oswki\n",
      "11/04/2025 15:10:10 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_seq_length\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_BN\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "11/04/2025 15:10:12 - INFO - utils.ConfigLogger -   ***** Reading Target Unlabeled Training Samples *****\n",
      "11/04/2025 15:11:48 - INFO - utils.ConfigLogger -   ***** Reading Source Training Samples *****\n",
      "11/04/2025 15:11:56 - INFO - utils.ConfigLogger -   ***** Reading Evaluation Samples *****\n",
      "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]11/04/2025 15:12:00 - INFO - utils.ConfigLogger -   \n",
      "\n",
      "11/04/2025 15:12:00 - INFO - utils.ConfigLogger -    ###########  Start Training Epoch 1  ###########\n",
      "11/04/2025 15:12:00 - INFO - utils.ConfigLogger -   \n",
      "\n",
      "11/04/2025 15:12:00 - INFO - utils.ConfigLogger -   ***** Generating training data for this epoch *****\n",
      "11/04/2025 15:12:00 - INFO - utils.ConfigLogger -   ***** Running Evaluation Stage *****\n",
      "11/04/2025 15:12:00 - INFO - utils.ConfigLogger -     Num orig examples = 50\n",
      "11/04/2025 15:12:00 - INFO - utils.ConfigLogger -     Num split examples = 50\n",
      "11/04/2025 15:12:00 - INFO - utils.ConfigLogger -     Batch size = 12\n",
      "11/04/2025 15:12:00 - INFO - utils.ConfigLogger -   Start evaluating\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 20.15it/s]\n",
      "11/04/2025 15:12:01 - INFO - utils.ConfigLogger -   Writing predictions to: model/squad2target/predictions_2025-11-04 15:12:01.json\n",
      "11/04/2025 15:12:01 - INFO - utils.ConfigLogger -   Writing nbest to: model/squad2target/nbest_predictions_2025-11-04 15:12:01.json\n",
      "11/04/2025 15:12:01 - INFO - utils.ConfigLogger -   \n",
      "\n",
      "11/04/2025 15:12:01 - INFO - utils.ConfigLogger -   ====================  Start Adversarial Training Stage  ====================\n",
      "11/04/2025 15:12:01 - INFO - utils.ConfigLogger -     Num split examples = 2\n",
      "11/04/2025 15:12:01 - INFO - utils.ConfigLogger -     Batch size = 12\n",
      "11/04/2025 15:12:01 - INFO - utils.ConfigLogger -     Num steps = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”¥ RUNTIME LOG - q_type_prob Status:\n",
      "  Total target features: 2\n",
      "  Fallback (one-hot) count: 0\n",
      "  Proper q_type_prob count: 2\n",
      "  Fallback rate: 0.0%\n",
      "\n",
      "ğŸ”¥ RUNTIME LOG - Source Q-Type Distribution:\n",
      "  Type 0: 0 samples\n",
      "  Type 1: 0 samples\n",
      "  Type 2: 11 samples\n",
      "  Type 3: 18 samples\n",
      "  Type 4: 3 samples\n",
      "  Type 5: 18 samples\n",
      "\n",
      "\n",
      "ğŸ”¥ RUNTIME LOG - Training Loop (First 3 Batches):\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.67it/s]\n",
      "11/04/2025 15:12:01 - INFO - utils.ConfigLogger -   ***** Running Predictions *****\n",
      "11/04/2025 15:12:01 - INFO - utils.ConfigLogger -     Num orig examples = 50\n",
      "11/04/2025 15:12:01 - INFO - utils.ConfigLogger -     Num split examples = 50\n",
      "11/04/2025 15:12:01 - INFO - utils.ConfigLogger -     Batch size = 12\n",
      "11/04/2025 15:12:01 - INFO - utils.ConfigLogger -   Start evaluating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Batch 0 ---\n",
      "Target batch size: 2\n",
      "Sample q_type_prob[0]: [0.0010000000474974513, 0.010999999940395355, 0.3059999942779541, 0.6769999861717224, 0.003000000026077032, 0.0010000000474974513]\n",
      "Top-3 types: [3, 2, 1], probs: ['0.677', '0.306', '0.011']\n",
      "Source batch size: 5\n",
      "Source sampling ratio: 2.50x\n",
      "First target sample matched to sources:\n",
      "  Rank 1: Type 3 (prob=0.677) â†’ Source[46]\n",
      "  Rank 2: Type 2 (prob=0.306) â†’ Source[14]\n",
      "  Rank 3: Type 1 (prob=0.011) â†’ âš ï¸  No source\n",
      "Combined batch size: 7\n",
      "Q-type distribution: {2: 3, 3: 3, 5: 1}\n",
      "\n",
      "================================================================================\n",
      "ğŸ”¥ TRAINING LOOP COMPLETED\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 20.15it/s]\n",
      "11/04/2025 15:12:01 - INFO - utils.ConfigLogger -   Writing predictions to: model/squad2target/predictions_1.json\n",
      "11/04/2025 15:12:01 - INFO - utils.ConfigLogger -   Writing nbest to: model/squad2target/nbest_predictions_1.json\n",
      "/tmp/ipykernel_2255560/1948527526.py:27: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  logger.warn(message)\n",
      "11/04/2025 15:12:01 - WARNING - utils.ConfigLogger -   Unanswered question validation/fd0dc9fcbb41450c388f6d3f90153da19f53e050 will receive score 0.\n",
      "11/04/2025 15:12:01 - WARNING - utils.ConfigLogger -   Unanswered question validation/7ad6bf269adef016560ea4d857150771842e0d23 will receive score 0.\n",
      "11/04/2025 15:12:01 - WARNING - utils.ConfigLogger -   Unanswered question validation/de308d2ec5722143d8156c3fe2192a2884ca86f9 will receive score 0.\n",
      "11/04/2025 15:12:01 - WARNING - utils.ConfigLogger -   Unanswered question validation/c1875aa38c8ac079d128a4ddf92259479955abcc will receive score 0.\n",
      "11/04/2025 15:12:01 - WARNING - utils.ConfigLogger -   Unanswered question validation/1993fab60212e6627aea8ae78a33d9a81ab0e27c will receive score 0.\n",
      "11/04/2025 15:12:01 - WARNING - utils.ConfigLogger -   Unanswered question validation/6253f6fb35a222d648643465c6b9399dcdbe13a1 will receive score 0.\n",
      "11/04/2025 15:12:01 - WARNING - utils.ConfigLogger -   Unanswered question validation/1714ebeffea86e2788bfb7653ada360f61af2ff7 will receive score 0.\n",
      "11/04/2025 15:12:01 - WARNING - utils.ConfigLogger -   Unanswered question validation/656544054260257c0fa082e68c795a2152a49fc8 will receive score 0.\n",
      "11/04/2025 15:12:01 - WARNING - utils.ConfigLogger -   Unanswered question validation/d4c01b8a4fb735a1734d9c8fadddb1028b751b34 will receive score 0.\n",
      "11/04/2025 15:12:01 - WARNING - utils.ConfigLogger -   Unanswered question validation/6c22ba2fa5c59946e284a888fcc7c74fcac38e65 will receive score 0.\n",
      "11/04/2025 15:12:01 - WARNING - utils.ConfigLogger -   Unanswered question validation/bf9c95d342a51ffe32440116c9d5b1b7dfa96531 will receive score 0.\n",
      "11/04/2025 15:12:01 - WARNING - utils.ConfigLogger -   Unanswered question validation/d787ad7de05d3f63168579a29ded97b35bffd1b6 will receive score 0.\n",
      "11/04/2025 15:12:01 - WARNING - utils.ConfigLogger -   Unanswered question validation/c9d2e46b29b21b8b598b4b80803c1af651e7f1d2 will receive score 0.\n",
      "11/04/2025 15:12:01 - WARNING - utils.ConfigLogger -   Unanswered question validation/0957a9a140132d7f2ba596b62628fb98e5470a80 will receive score 0.\n",
      "11/04/2025 15:12:01 - WARNING - utils.ConfigLogger -   Unanswered question validation/033daf6ae73daf122e5982c6422b284d69b42764 will receive score 0.\n",
      "11/04/2025 15:12:01 - WARNING - utils.ConfigLogger -   Unanswered question validation/b3eff20f10ae157008ccf8962ed340feee33d31b will receive score 0.\n",
      "11/04/2025 15:12:01 - WARNING - utils.ConfigLogger -   Unanswered question validation/b1096769370114b16f44468ecb9aa2f9addaec3c will receive score 0.\n",
      "11/04/2025 15:12:01 - WARNING - utils.ConfigLogger -   Unanswered question validation/cbd9f3fae1ca0c7eabf3d38b3311c9998995d13e will receive score 0.\n",
      "11/04/2025 15:12:01 - WARNING - utils.ConfigLogger -   Unanswered question validation/01f460fa9d4289827ece2af1344485728e414981 will receive score 0.\n",
      "11/04/2025 15:12:01 - WARNING - utils.ConfigLogger -   Unanswered question validation/78c8d1e634e80e210626dc12671d13b62d10bc99 will receive score 0.\n",
      "11/04/2025 15:12:01 - WARNING - utils.ConfigLogger -   Unanswered question validation/5ec7c78400e01b1dcf2bd7d2cf9d6610ff59af12 will receive score 0.\n",
      "11/04/2025 15:12:01 - INFO - utils.ConfigLogger -   Current EM is 13.79310, F1 is 24.43514\n",
      "11/04/2025 15:12:01 - INFO - utils.ConfigLogger -   Current model BEATS previous best model, previous best is EM = 0.00000, F1 = 0.00000\n",
      "11/04/2025 15:12:01 - INFO - utils.ConfigLogger -   Current best model has been saved!\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -   \n",
      "\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -    ###########  End Training Epoch 1  ###########\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -   \n",
      "\n",
      "Epoch:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:01<00:01,  1.61s/it]11/04/2025 15:12:02 - INFO - utils.ConfigLogger -   \n",
      "\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -    ###########  Start Training Epoch 2  ###########\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -   \n",
      "\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -   ***** Generating training data for this epoch *****\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -   ***** Running Evaluation Stage *****\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -     Num orig examples = 50\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -     Num split examples = 50\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -     Batch size = 12\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -   Start evaluating\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 20.27it/s]\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -   Writing predictions to: model/squad2target/predictions_2025-11-04 15:12:02.json\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -   Writing nbest to: model/squad2target/nbest_predictions_2025-11-04 15:12:02.json\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -   \n",
      "\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -   ====================  Start Adversarial Training Stage  ====================\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -     Num split examples = 2\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -     Batch size = 12\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -     Num steps = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”¥ RUNTIME LOG - q_type_prob Status:\n",
      "  Total target features: 2\n",
      "  Fallback (one-hot) count: 0\n",
      "  Proper q_type_prob count: 2\n",
      "  Fallback rate: 0.0%\n",
      "\n",
      "ğŸ”¥ RUNTIME LOG - Source Q-Type Distribution:\n",
      "  Type 0: 0 samples\n",
      "  Type 1: 0 samples\n",
      "  Type 2: 11 samples\n",
      "  Type 3: 18 samples\n",
      "  Type 4: 3 samples\n",
      "  Type 5: 18 samples\n",
      "\n",
      "\n",
      "ğŸ”¥ RUNTIME LOG - Training Loop (First 3 Batches):\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.35it/s]\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -   ***** Running Predictions *****\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -     Num orig examples = 50\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -     Num split examples = 50\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -     Batch size = 12\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -   Start evaluating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Batch 0 ---\n",
      "Target batch size: 2\n",
      "Sample q_type_prob[0]: [0.0010000000474974513, 0.010999999940395355, 0.3059999942779541, 0.6769999861717224, 0.003000000026077032, 0.0010000000474974513]\n",
      "Top-3 types: [3, 2, 1], probs: ['0.677', '0.306', '0.011']\n",
      "Source batch size: 5\n",
      "Source sampling ratio: 2.50x\n",
      "First target sample matched to sources:\n",
      "  Rank 1: Type 3 (prob=0.677) â†’ Source[35]\n",
      "  Rank 2: Type 2 (prob=0.306) â†’ Source[2]\n",
      "  Rank 3: Type 1 (prob=0.011) â†’ âš ï¸  No source\n",
      "Combined batch size: 7\n",
      "Q-type distribution: {2: 3, 3: 3, 5: 1}\n",
      "\n",
      "================================================================================\n",
      "ğŸ”¥ TRAINING LOOP COMPLETED\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 20.11it/s]\n",
      "11/04/2025 15:12:03 - INFO - utils.ConfigLogger -   Writing predictions to: model/squad2target/predictions_1.json\n",
      "11/04/2025 15:12:03 - INFO - utils.ConfigLogger -   Writing nbest to: model/squad2target/nbest_predictions_1.json\n",
      "11/04/2025 15:12:03 - WARNING - utils.ConfigLogger -   Unanswered question validation/fd0dc9fcbb41450c388f6d3f90153da19f53e050 will receive score 0.\n",
      "11/04/2025 15:12:03 - WARNING - utils.ConfigLogger -   Unanswered question validation/7ad6bf269adef016560ea4d857150771842e0d23 will receive score 0.\n",
      "11/04/2025 15:12:03 - WARNING - utils.ConfigLogger -   Unanswered question validation/de308d2ec5722143d8156c3fe2192a2884ca86f9 will receive score 0.\n",
      "11/04/2025 15:12:03 - WARNING - utils.ConfigLogger -   Unanswered question validation/c1875aa38c8ac079d128a4ddf92259479955abcc will receive score 0.\n",
      "11/04/2025 15:12:03 - WARNING - utils.ConfigLogger -   Unanswered question validation/1993fab60212e6627aea8ae78a33d9a81ab0e27c will receive score 0.\n",
      "11/04/2025 15:12:03 - WARNING - utils.ConfigLogger -   Unanswered question validation/6253f6fb35a222d648643465c6b9399dcdbe13a1 will receive score 0.\n",
      "11/04/2025 15:12:03 - WARNING - utils.ConfigLogger -   Unanswered question validation/1714ebeffea86e2788bfb7653ada360f61af2ff7 will receive score 0.\n",
      "11/04/2025 15:12:03 - WARNING - utils.ConfigLogger -   Unanswered question validation/656544054260257c0fa082e68c795a2152a49fc8 will receive score 0.\n",
      "11/04/2025 15:12:03 - WARNING - utils.ConfigLogger -   Unanswered question validation/d4c01b8a4fb735a1734d9c8fadddb1028b751b34 will receive score 0.\n",
      "11/04/2025 15:12:03 - WARNING - utils.ConfigLogger -   Unanswered question validation/6c22ba2fa5c59946e284a888fcc7c74fcac38e65 will receive score 0.\n",
      "11/04/2025 15:12:03 - WARNING - utils.ConfigLogger -   Unanswered question validation/bf9c95d342a51ffe32440116c9d5b1b7dfa96531 will receive score 0.\n",
      "11/04/2025 15:12:03 - WARNING - utils.ConfigLogger -   Unanswered question validation/d787ad7de05d3f63168579a29ded97b35bffd1b6 will receive score 0.\n",
      "11/04/2025 15:12:03 - WARNING - utils.ConfigLogger -   Unanswered question validation/c9d2e46b29b21b8b598b4b80803c1af651e7f1d2 will receive score 0.\n",
      "11/04/2025 15:12:03 - WARNING - utils.ConfigLogger -   Unanswered question validation/0957a9a140132d7f2ba596b62628fb98e5470a80 will receive score 0.\n",
      "11/04/2025 15:12:03 - WARNING - utils.ConfigLogger -   Unanswered question validation/033daf6ae73daf122e5982c6422b284d69b42764 will receive score 0.\n",
      "11/04/2025 15:12:03 - WARNING - utils.ConfigLogger -   Unanswered question validation/b3eff20f10ae157008ccf8962ed340feee33d31b will receive score 0.\n",
      "11/04/2025 15:12:03 - WARNING - utils.ConfigLogger -   Unanswered question validation/b1096769370114b16f44468ecb9aa2f9addaec3c will receive score 0.\n",
      "11/04/2025 15:12:03 - WARNING - utils.ConfigLogger -   Unanswered question validation/cbd9f3fae1ca0c7eabf3d38b3311c9998995d13e will receive score 0.\n",
      "11/04/2025 15:12:03 - WARNING - utils.ConfigLogger -   Unanswered question validation/01f460fa9d4289827ece2af1344485728e414981 will receive score 0.\n",
      "11/04/2025 15:12:03 - WARNING - utils.ConfigLogger -   Unanswered question validation/78c8d1e634e80e210626dc12671d13b62d10bc99 will receive score 0.\n",
      "11/04/2025 15:12:03 - WARNING - utils.ConfigLogger -   Unanswered question validation/5ec7c78400e01b1dcf2bd7d2cf9d6610ff59af12 will receive score 0.\n",
      "11/04/2025 15:12:03 - INFO - utils.ConfigLogger -   Current EM is 13.79310, F1 is 24.43514\n",
      "11/04/2025 15:12:03 - INFO - utils.ConfigLogger -   Current model CANNOT beat previous best model, previous best is EM = 13.79310, F1 = 24.43514\n",
      "11/04/2025 15:12:03 - INFO - utils.ConfigLogger -   \n",
      "\n",
      "11/04/2025 15:12:03 - INFO - utils.ConfigLogger -    ###########  End Training Epoch 2  ###########\n",
      "11/04/2025 15:12:03 - INFO - utils.ConfigLogger -   \n",
      "\n",
      "Epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.22s/it]\n",
      "11/04/2025 15:12:04 - INFO - utils.ConfigLogger -   The final model has been save\n",
      "11/04/2025 15:12:04 - INFO - utils.ConfigLogger -   *** The Training Stage is Ended ***\n",
      "11/04/2025 15:12:04 - INFO - utils.ConfigLogger -   \n",
      "\n",
      "Best EM is 13.79310. Best F1 is 24.43514\n",
      "11/04/2025 15:12:04 - INFO - utils.ConfigLogger -   \n",
      "\n",
      "Final EM is 13.79310. Best F1 is 24.43514\n"
     ]
    }
   ],
   "source": [
    "# ë¡œê¹… í•¨ìˆ˜ë¡œ ë®ì–´ì“°ê¸°\n",
    "globals()['comb_adversarial_training_stage'] = comb_adversarial_training_stage_with_logging\n",
    "model = prepare_model(args, device)\n",
    "adaptation_stage(args, tokenizer, device, logger, debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "da",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
