{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c05814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch:  True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "from abc import ABCMeta\n",
    "import argparse\n",
    "import datetime \n",
    "import collections\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import sys\n",
    "import io\n",
    "from tqdm import tqdm, trange\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, WeightedRandomSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "from pytorch_pretrained_bert.modeling import BertForQuestionAnswering\n",
    "from pytorch_pretrained_bert.modeling import BertForQuestionAnsweringQC4QA\n",
    "\n",
    "from pytorch_pretrained_bert.optimization import BertAdam\n",
    "from utils.ConfigLogger import config_logger\n",
    "from utils.evaluate import f1_score, exact_match_score, metric_max_over_ground_truths\n",
    "from utils.BERTRandomSampler import BERTRandomSampler\n",
    "\n",
    "PYTORCH_PRETRAINED_BERT_CACHE = Path(os.getenv('PYTORCH_PRETRAINED_BERT_CACHE',\n",
    "                                               Path.home() / '.pytorch_pretrained_bert'))\n",
    "\n",
    "from da_data_utils import * # Question Type용 Data_utils 파일(원본은 data_utils.py)\n",
    "from qada_utils import *\n",
    "############################\n",
    "import importlib, types, argparse\n",
    "from utils.ConfigLogger import config_logger\n",
    "print('torch: ',torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8bd1e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_squad_path = '../../../data/squad/train-v1.1_classified_qtype_prob.jsonl'\n",
    "dev_squad_path = '../../../data/squad/dev-v1.1.json'\n",
    "train_cnn_path = '../../../data/cnn/cnn_train_classified_qtype_prob.jsonl'\n",
    "dev_cnn_path = '../../../data/cnn/cnn_dev.json'\n",
    "\n",
    "\n",
    "def open_jsonl(path):\n",
    "    data = []\n",
    "    with io.open(path, 'r', encoding='utf-8') as f:\n",
    "        for example in f:\n",
    "            data.append(json.loads(example))\n",
    "    data = data[:10] # debug size\n",
    "    return data\n",
    "\n",
    "def open_json(path):\n",
    "    with io.open(path, 'r', encoding='utf-8') as f:\n",
    "        input_data = json.load(f)[\"data\"]\n",
    "    input_data = input_data[:10]  # debug size\n",
    "    return input_data\n",
    "\n",
    "train_squad_data = open_jsonl(train_squad_path)\n",
    "dev_squad_data = open_json(dev_squad_path)\n",
    "train_cnn_data = open_jsonl(train_cnn_path)\n",
    "dev_cnn_data = open_json(dev_cnn_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85da19a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answers': [{'answer_start': 515, 'text': 'Saint Bernadette Soubirous'}],\n",
       " 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
       " 'id': '5733be284776f41900661182',\n",
       " 'q_type': 3,\n",
       " 'q_type_prob': [0.0, 0.0, 0.016, 0.983, 0.001, 0.0]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_squad_data[0]['paragraphs'][0]['qas'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbd86efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answers': [{'answer_start': 2070, 'text': 'Globe'}],\n",
       " 'question': 'on the Democratic side , the Register backs Clinton , while the @placeholder picks Obama',\n",
       " 'id': 'training/6dc32db9379e43971ad93007e76c5347e213f21a',\n",
       " 'q_type': 3,\n",
       " 'q_type_prob': [0.001, 0.001, 0.171, 0.76, 0.064, 0.002]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cnn_data[0]['paragraphs'][0]['qas'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b491535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_stage(args, device, tokenizer, logger, debug=False):\n",
    "    # Load a trained model that you have fine-tuned\n",
    "    output_model_file = os.path.join(args.output_dir, args.output_model_file)\n",
    "    model_state_dict = torch.load(output_model_file)\n",
    "    model = BertForQuestionAnswering.from_pretrained(args.bert_model, state_dict=model_state_dict, args=args)\n",
    "    model.to(device)\n",
    "    # Read prediction samples\n",
    "    read_limit = None\n",
    "    if debug:\n",
    "        read_limit = 100 # 샘플 100개만 사용\n",
    "    logger.info(\"***** Reading Prediction Samples *****\")\n",
    "    eval_features, eval_examples = read_features_and_examples(args, args.predict_file, tokenizer, logger,\n",
    "            use_simple_feature=False, read_examples=True, limit=read_limit)\n",
    "    acc, f1 = evaluation_stage(args, eval_examples, eval_features, device, model, logger)\n",
    "    logger.info('***** Prediction Performance *****')\n",
    "    logger.info('EM is %.5f, F1 is %.5f', acc, f1)\n",
    "\n",
    "\n",
    "def evaluate_acc_and_f1(predictions, raw_data, logger, threshold=-1, all_probs=None):\n",
    "    f1 = exact_match = total = 0\n",
    "    eval_threshold = True\n",
    "    if threshold is None or all_probs is None:\n",
    "        eval_threshold = False\n",
    "    for sample in raw_data:\n",
    "        if (sample.qas_id not in predictions) or (eval_threshold and sample.qas_id not in all_probs):\n",
    "            message = 'Unanswered question ' + sample.qas_id + ' will receive score 0.'\n",
    "            logger.warn(message)\n",
    "            continue\n",
    "        if not eval_threshold or (eval_threshold and all_probs[sample.qas_id] >= threshold):\n",
    "            ground_truths = sample.orig_answers\n",
    "            prediction = predictions[sample.qas_id]\n",
    "            exact_match += metric_max_over_ground_truths(\n",
    "                exact_match_score, prediction, ground_truths)\n",
    "            f1 += metric_max_over_ground_truths(\n",
    "                f1_score, prediction, ground_truths)\n",
    "            total += 1\n",
    "\n",
    "    exact_match = 100.0 * exact_match / total\n",
    "    f1 = 100.0 * f1 / total\n",
    "\n",
    "    return exact_match, f1\n",
    "\n",
    "\n",
    "def keep_high_prob_samples(all_probs, all_features, prob_threshold, removed_feature_index, all_indices,\n",
    "        keep_generated=False):\n",
    "    '''\n",
    "    셀프 트레이닝용: 높은 확률의 예측을 pseudo-label로 변환\n",
    "    '''\n",
    "    new_train_features = []\n",
    "    for i, feature in enumerate(all_features):\n",
    "        if keep_generated:\n",
    "            if feature.example_index not in removed_feature_index and all_probs[feature.example_index] > prob_threshold:\n",
    "                feature.start_position, feature.end_position = all_indices[i][0] = all_indices[i][1]\n",
    "                new_train_features.append(feature)\n",
    "                removed_feature_index.add(feature.example_index)\n",
    "        else:\n",
    "            if all_probs[feature.example_index] > prob_threshold:\n",
    "                feature.start_position, feature.end_position = all_indices[i][0], all_indices[i][1]\n",
    "                new_train_features.append(feature)\n",
    "    return new_train_features, removed_feature_index\n",
    "\n",
    "\n",
    "def compare_performance(args, best_acc, best_f1, acc, f1, model, logger):\n",
    "    if not (best_f1 is None or best_acc is None):\n",
    "        if best_acc < acc:\n",
    "            logger.info('Current model BEATS previous best model, previous best is EM = %.5F, F1 = %.5f',\n",
    "                best_acc, best_f1)\n",
    "            best_acc, best_f1 = acc, f1\n",
    "            logger.info('Current best model has been saved!')\n",
    "            model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
    "            torch.save(model_to_save.state_dict(), os.path.join(args.output_dir, args.output_model_file))\n",
    "        else:\n",
    "            logger.info('Current model CANNOT beat previous best model, previous best is EM = %.5F, F1 = %.5f',\n",
    "                best_acc, best_f1)\n",
    "    else:\n",
    "        best_acc, best_f1 = acc, f1\n",
    "    return best_acc, best_f1\n",
    "\n",
    "\n",
    "def evaluation_stage(args, eval_examples, eval_features, device, model, logger, generate_prob_th=0.6,\n",
    "        removed_feature_index=None, global_step=None, best_acc=None, best_f1=None, generate_label=False):\n",
    "    if not global_step:\n",
    "        logger.info(\"***** Running Evaluation Stage *****\")\n",
    "    else:\n",
    "        logger.info(\"***** Running Predictions *****\")\n",
    "    logger.info(\"  Num orig examples = %d\", len(eval_examples))\n",
    "    logger.info(\"  Num split examples = %d\", len(eval_features))\n",
    "    logger.info(\"  Batch size = %d\", args.predict_batch_size)\n",
    "\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\n",
    "    all_example_index = torch.arange(all_input_ids.size(0), dtype=torch.long)\n",
    "    eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_example_index)\n",
    "    # Run prediction for full data\n",
    "    eval_sampler = SequentialSampler(eval_data)\n",
    "    eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=args.predict_batch_size)\n",
    "\n",
    "    model.eval()\n",
    "    all_results = []\n",
    "    logger.info(\"Start evaluating\")\n",
    "    for input_ids, input_mask, segment_ids, example_indices in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "        input_ids = input_ids.to(device)\n",
    "        input_mask = input_mask.to(device)\n",
    "        segment_ids = segment_ids.to(device)\n",
    "        with torch.no_grad():\n",
    "             batch_start_logits, batch_end_logits, _ = model(input_ids, segment_ids, input_mask)\n",
    "        for i, example_index in enumerate(example_indices):\n",
    "            start_logits = batch_start_logits[i].detach().cpu().tolist()\n",
    "            end_logits = batch_end_logits[i].detach().cpu().tolist()\n",
    "            eval_feature = eval_features[example_index.item()]\n",
    "            unique_id = int(eval_feature.unique_id)\n",
    "            all_results.append(RawResult(unique_id=unique_id,\n",
    "                start_logits=start_logits,\n",
    "                end_logits=end_logits))\n",
    "\n",
    "    if global_step:\n",
    "        prediction_file_name = 'predictions_' + str(global_step) + f'_{datetime.datetime.now().strftime(\"%Y%m%d_%H:%M:%S\")}.json'\n",
    "        nbest_file_name = 'nbest_predictions_' + str(global_step) + f'_{datetime.datetime.now().strftime(\"%Y%m%d_%H:%M:%S\")}.json'\n",
    "        output_prediction_file = os.path.join(args.output_dir, prediction_file_name)\n",
    "        output_nbest_file = os.path.join(args.output_dir, nbest_file_name)\n",
    "    else:\n",
    "        output_prediction_file = os.path.join(args.output_dir, f'predictions_{datetime.datetime.now().strftime(\"%Y%m%d_%H:%M:%S\")}.json')\n",
    "        output_nbest_file = os.path.join(args.output_dir, f'nbest_predictions_{datetime.datetime.now().strftime(\"%Y%m%d_%H:%M:%S\")}.json')\n",
    "    all_predictions, all_probs, all_indices = write_predictions(args, eval_examples, eval_features, all_results,\n",
    "        args.n_best_size, args.max_answer_length,\n",
    "        args.do_lower_case, output_prediction_file,\n",
    "        output_nbest_file, args.verbose_logging, logger, args.output_prediction)\n",
    "    if generate_label:\n",
    "        return keep_high_prob_samples(all_probs, eval_features, generate_prob_th, removed_feature_index, all_indices,\n",
    "                keep_generated=args.keep_previous_generated)\n",
    "    else:\n",
    "        acc, f1 = evaluate_acc_and_f1(all_predictions, eval_examples, logger)\n",
    "        logger.info('Current EM is %.5f, F1 is %.5f', acc, f1)\n",
    "        if not (best_f1 is None or best_acc is None):\n",
    "            best_acc, best_f1 = compare_performance(args, best_acc, best_f1, acc, f1, model, logger)\n",
    "            return best_acc, best_f1\n",
    "        else:\n",
    "            return acc, f1\n",
    "\n",
    "\n",
    "def generate_self_training_samples(args, train_examples, train_features, device, model, removed_feature_index,\n",
    "        new_generated_train_features, generate_prob_th, logger):\n",
    "    '''\n",
    "    타겟 도메인 데이터에서 pseudo-label 생성\n",
    "    '''\n",
    "    logger.info('***** Generating training data for this epoch *****')\n",
    "    if args.keep_previous_generated:\n",
    "        train_features_removed_previous = []\n",
    "        for index in range(len(train_features)):\n",
    "            if index not in removed_feature_index:\n",
    "                train_features_removed_previous.append(train_features[index])\n",
    "    else:\n",
    "        train_features_removed_previous = train_features\n",
    "    cur_train_features, removed_feature_index = \\\n",
    "        evaluation_stage(args, train_examples, train_features_removed_previous, device, model, logger,\n",
    "            removed_feature_index=removed_feature_index, generate_label=True, generate_prob_th=generate_prob_th)\n",
    "    if len(cur_train_features) == 0:\n",
    "        logger.info(\"  No new training samples were generated, training procedure ends\")\n",
    "        return None, None\n",
    "    if args.keep_previous_generated:\n",
    "        new_generated_train_features.extend(cur_train_features)\n",
    "    else:\n",
    "        new_generated_train_features = cur_train_features\n",
    "    return new_generated_train_features, removed_feature_index\n",
    "\n",
    "\n",
    "def get_bert_model_parameters(model):\n",
    "    '''\n",
    "    역할:BERT optimizer 파라미터 그룹 생성 (weight decay 적용/미적용 분리)\n",
    "    반환: optimizer_grouped_parameters\n",
    "    '''\n",
    "    # Prepare optimizer\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "\n",
    "    # hack to remove pooler, which is not used\n",
    "    # thus it produce None grad that break apex\n",
    "    param_optimizer = [n for n in param_optimizer if 'pooler' not in n[0]]\n",
    "\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "    return optimizer_grouped_parameters\n",
    "\n",
    "\n",
    "def comb_adversarial_training_stage(args, target_train_features, target_train_examples, source_train_features,\n",
    "            eval_features, eval_examples, removed_feature_index, new_generated_train_features, model, epoch,\n",
    "            device, best_acc, best_f1, logger):\n",
    "    '''\n",
    "    1. Self-training: 타겟 데이터에서 pseudo-label 생성\n",
    "    2. Question Type Probability 기반 Source-Target 매칭:\n",
    "        타겟 배치의 각 샘플에서 q_type_prob 상위 3개를 추출하여\n",
    "        각 타입에 해당하는 소스 샘플을 샘플링 (타겟 1개 → 소스 3개)\n",
    "    3. Combined Training: 타겟(pseudo) + 소스(labeled) 데이터를 concat하여 학습\n",
    "    '''\n",
    "\n",
    "    def sample_source_batch_top3(source_data, source_q_type_dict, sample_pointer, q_type_probs):\n",
    "        \"\"\"\n",
    "        q_type_probs 기반 상위 3개 타입에서 소스 샘플링\n",
    "        Args:\n",
    "            q_type_probs: [batch_size, 6] 텐서\n",
    "        Returns:\n",
    "            타겟 배치의 최대 3배 크기 소스 배치\n",
    "        \"\"\"\n",
    "        output_idx = []\n",
    "\n",
    "        for q_type_prob in q_type_probs:  # 각 타겟 샘플\n",
    "            # 상위 3개 q_type 인덱스 추출\n",
    "            top3_indices = torch.topk(q_type_prob, k=3).indices.tolist()\n",
    "\n",
    "            for q_type in top3_indices:\n",
    "                # 해당 타입에 소스 샘플이 없으면 스킵\n",
    "                if len(source_q_type_dict[q_type]) == 0:\n",
    "                    continue\n",
    "\n",
    "                next_q_idx = sample_pointer[q_type] % len(source_q_type_dict[q_type])\n",
    "                output_idx.append(source_q_type_dict[q_type][next_q_idx])\n",
    "                sample_pointer[q_type] += 1\n",
    "\n",
    "        input_ids_source, input_masks_source, segment_ids_source, start_positions_source, end_positions_source, \\\n",
    "            q_types_source = [], [], [], [], [], []\n",
    "        for idx in output_idx:\n",
    "            input_ids_source.append(source_data[idx][0].unsqueeze(0))\n",
    "            input_masks_source.append(source_data[idx][1].unsqueeze(0))\n",
    "            segment_ids_source.append(source_data[idx][2].unsqueeze(0))\n",
    "            start_positions_source.append(source_data[idx][3].unsqueeze(0))\n",
    "            end_positions_source.append(source_data[idx][4].unsqueeze(0))\n",
    "            q_types_source.append(source_data[idx][5].unsqueeze(0))\n",
    "\n",
    "        return torch.vstack(input_ids_source), torch.vstack(input_masks_source), torch.vstack(segment_ids_source), \\\n",
    "            torch.cat(start_positions_source, -1), torch.cat(end_positions_source, -1), torch.cat(q_types_source, -1)\n",
    "\n",
    "    # Generate self-training samples\n",
    "    # 1. Pseudo-label 생성\n",
    "    new_generated_train_features, removed_feature_index = generate_self_training_samples(args, target_train_examples,\n",
    "        target_train_features, device, model, removed_feature_index, new_generated_train_features, args.generate_prob_th,\n",
    "        logger)\n",
    "    if new_generated_train_features is None:\n",
    "        sys.exit()\n",
    "    \n",
    "    logger.info('\\n')\n",
    "    logger.info('====================  Start Adversarial Training Stage  ====================')\n",
    "    \n",
    "    # q_type_prob 추출 (데이터에서 가져오기)\n",
    "    all_q_type_probs = []\n",
    "    for f in new_generated_train_features:\n",
    "        # InputFeatures에 q_type_prob가 있는지 확인\n",
    "        if hasattr(f, 'q_type_prob') and f.q_type_prob is not None:\n",
    "            all_q_type_probs.append(f.q_type_prob)\n",
    "        else:\n",
    "            # q_type_prob가 없으면 one-hot 인코딩 사용\n",
    "            prob = [0.0] * 6\n",
    "            prob[f.q_type] = 1.0\n",
    "            all_q_type_probs.append(prob)\n",
    "    \n",
    "    all_input_ids = torch.tensor([f.input_ids for f in new_generated_train_features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in new_generated_train_features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in new_generated_train_features], dtype=torch.long)\n",
    "    all_start_positions = torch.tensor([f.start_position for f in new_generated_train_features], dtype=torch.long)\n",
    "    all_end_positions = torch.tensor([f.end_position for f in new_generated_train_features], dtype=torch.long)\n",
    "    all_q_types = torch.tensor([f.q_type for f in new_generated_train_features], dtype=torch.long)\n",
    "    all_q_type_probs = torch.tensor(all_q_type_probs, dtype=torch.float)\n",
    "    \n",
    "    train_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids,\n",
    "        all_start_positions, all_end_positions, all_q_types, all_q_type_probs)\n",
    "    \n",
    "    source_input_ids = torch.tensor([f.input_ids for f in source_train_features], dtype=torch.long)\n",
    "    source_input_mask = torch.tensor([f.input_mask for f in source_train_features], dtype=torch.long)\n",
    "    source_segment_ids = torch.tensor([f.segment_ids for f in source_train_features], dtype=torch.long)\n",
    "    source_start_positions = torch.tensor([f.start_position for f in source_train_features], dtype=torch.long)\n",
    "    source_end_positions = torch.tensor([f.end_position for f in source_train_features], dtype=torch.long)\n",
    "    source_q_types = []\n",
    "    source_q_type_dict = {\n",
    "        0: [],\n",
    "        1: [],\n",
    "        2: [],\n",
    "        3: [],\n",
    "        4: [],\n",
    "        5: []\n",
    "    }\n",
    "    for idx, f in enumerate(source_train_features):\n",
    "        source_q_types.append(f.q_type)\n",
    "        source_q_type_dict[f.q_type].append(idx)\n",
    "    source_q_types = torch.tensor(source_q_types, dtype=torch.long)\n",
    "    for key in source_q_type_dict.keys():\n",
    "        random.shuffle(source_q_type_dict[key])\n",
    "    sample_pointer = [0] * 6\n",
    "    source_data = TensorDataset(source_input_ids, source_input_mask, source_segment_ids, source_start_positions, \n",
    "        source_end_positions, source_q_types)\n",
    "\n",
    "    train_sampler = BERTRandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=args.train_batch_size)\n",
    "    \n",
    "    data_len = len(new_generated_train_features)\n",
    "    logger.info(\"  Num split examples = %d\", data_len)\n",
    "    logger.info(\"  Batch size = %d\", args.train_batch_size)\n",
    "    num_train_steps = math.ceil(data_len / args.train_batch_size / args.gradient_accumulation_steps)\n",
    "    if num_train_steps == 0 and data_len > 0:\n",
    "        num_train_steps = 1\n",
    "    t_total = num_train_steps\n",
    "    logger.info(\"  Num steps = %d\", num_train_steps)\n",
    "\n",
    "    loss_sum = 0\n",
    "    optimizer_grouped_parameters = get_bert_model_parameters(model)\n",
    "    optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "            lr=args.adapt_learning_rate,\n",
    "            warmup=args.warmup_proportion,\n",
    "            t_total=t_total)\n",
    "    global_step = 0\n",
    "\n",
    "    # 타겟 배치 순회(pseudo-labeling->소스 매칭->결합 학습)\n",
    "    for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\")):\n",
    "        model.train()\n",
    "        # 소스 배치 샘플링 (question type probability 기반 상위 3개)\n",
    "        batch_source = sample_source_batch_top3(source_data, source_q_type_dict, sample_pointer, batch[-1])\n",
    "        batch = tuple(t.to(device) for t in batch[:-1])  # q_type_probs는 제외\n",
    "        batch_source = tuple(t.to(device) for t in batch_source)\n",
    "        input_ids, input_masks, segment_ids, start_positions, end_positions, q_types = batch\n",
    "        input_ids_source, input_masks_source, segment_ids_source, start_positions_source, end_positions_source, q_types_source = batch_source\n",
    "        # 타겟 + 소스 concat\n",
    "        input_ids = torch.cat((input_ids, input_ids_source), 0)\n",
    "        input_masks = torch.cat((input_masks, input_masks_source), 0)\n",
    "        segment_ids = torch.cat((segment_ids, segment_ids_source), 0)\n",
    "        start_positions = torch.cat((start_positions, start_positions_source), 0)\n",
    "        end_positions = torch.cat((end_positions, end_positions_source), 0)\n",
    "        q_types = torch.cat((q_types, q_types_source), 0)\n",
    "        # QC4QA loss 계산 및 역전파\n",
    "        loss = model.forward_ours(input_ids, segment_ids, input_masks, start_positions,\n",
    "                end_positions, q_types, lambda_c=args.lambda_c)\n",
    "        if args.gradient_accumulation_steps > 1:\n",
    "            loss = loss / args.gradient_accumulation_steps\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        if (step + 1) % args.gradient_accumulation_steps == 0:\n",
    "            # modify learning rate with special warm up BERT uses\n",
    "            lr_this_step = args.adapt_learning_rate * warmup_linear(global_step / t_total, args.warmup_proportion)\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr_this_step\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "        \n",
    "    final_acc, final_f1 = None, None\n",
    "    if epoch == args.num_train_epochs - 1:\n",
    "        final_acc, final_f1 = evaluation_stage(args, eval_examples, eval_features, device, model,\n",
    "            global_step=global_step, best_acc=None, best_f1=None, logger=logger)\n",
    "        best_acc, best_f1 = compare_performance(args, best_acc, best_f1, final_acc, final_f1, model, logger)\n",
    "    else:\n",
    "        best_acc, best_f1 = evaluation_stage(args, eval_examples, eval_features, device, model,\n",
    "            global_step=global_step, best_acc=best_acc, best_f1=best_f1, logger=logger)\n",
    "    return best_acc, best_f1, final_acc, final_f1\n",
    "\n",
    "\n",
    "def prepare_model(args, device):\n",
    "    # Source 도메인에서 fine-tuned 모델 로드(run_source.py는 사전학습 모델 로드)\n",
    "    input_model_file = os.path.join(args.input_dir, args.input_model_file)\n",
    "    model_state_dict = torch.load(input_model_file)\n",
    "    model = BertForQuestionAnsweringQC4QA.from_pretrained(args.bert_model, state_dict=model_state_dict, args=args)\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "\n",
    "def adaptation_stage(args, tokenizer, device, logger, debug=True):\n",
    "    '''\n",
    "    역할: 도메인 적응 메인 루프\n",
    "    '''\n",
    "    ### 데이터 수 조절 ### \n",
    "    sample_limit = 100\n",
    "    \n",
    "    model = prepare_model(args, device)\n",
    "    best_acc, best_f1 = 0, 0\n",
    "    \n",
    "    read_limit = None\n",
    "    if debug:\n",
    "        read_limit = 50\n",
    "\n",
    "    ## Read target training examples\n",
    "    logger.info(\"***** Reading Target Unlabeled Training Samples *****\")\n",
    "    train_features, train_examples = read_features_and_examples(args, args.target_train_file, tokenizer, logger,\n",
    "        use_simple_feature=False, read_examples=True, limit=read_limit)\n",
    "\n",
    "    ## Read source training examples\n",
    "    logger.info(\"***** Reading Source Training Samples *****\")\n",
    "    source_train_features, _ = read_features_and_examples(args, args.source_train_file, tokenizer, logger,\n",
    "        use_simple_feature=False, read_examples=True, limit=read_limit)\n",
    "\n",
    "    # Read evaluation samples\n",
    "    logger.info(\"***** Reading Evaluation Samples *****\")\n",
    "    eval_features, eval_examples = read_features_and_examples(args, args.target_predict_file, tokenizer, logger,\n",
    "        use_simple_feature=False, read_examples=True, limit=read_limit)\n",
    "\n",
    "    removed_feature_index = set()\n",
    "    new_generated_train_features = []\n",
    "    final_acc, final_f1 = 0.0, 0.0\n",
    "    for epoch in trange(int(args.num_train_epochs), desc=\"Epoch\"):\n",
    "        logger.info('\\n')\n",
    "        logger.info(' ###########  Start Training Epoch %d  ###########', epoch + 1)\n",
    "        logger.info('\\n')\n",
    "        best_acc, best_f1, final_acc, final_f1 = comb_adversarial_training_stage(args, train_features, train_examples,\n",
    "                source_train_features, eval_features, eval_examples, removed_feature_index, new_generated_train_features,\n",
    "                model, epoch, device, best_acc, best_f1, logger)\n",
    "        logger.info('\\n')\n",
    "        logger.info(' ###########  End Training Epoch %d  ###########', epoch + 1)\n",
    "        logger.info('\\n')\n",
    "\n",
    "    # Save the final trained model\n",
    "    model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
    "    output_model_file = os.path.join(args.output_dir, args.output_model_file + '.final')\n",
    "    torch.save(model_to_save.state_dict(), output_model_file)\n",
    "    logger.info('The final model has been save')\n",
    "    logger.info('*** The Training Stage is Ended ***')\n",
    "    logger.info('\\n\\nBest EM is %.5f. Best F1 is %.5f', best_acc, best_f1)\n",
    "    logger.info('\\n\\nFinal EM is %.5f. Best F1 is %.5f', final_acc, final_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a508a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "args = argparse.Namespace(\n",
    "    debug = True, # sample_limit 사이즈로 디버깅\n",
    "    bert_model='bert-base-uncased',\n",
    "    do_adaptation=True,\n",
    "    do_predict=False,\n",
    "    do_lower_case=True,\n",
    "    source_train_file=\"../../../data/squad/train-v1.1_classified_qtype_prob.jsonl\",\n",
    "    target_train_file=\"../../../data/cnn/cnn_train_classified_qtype_prob.jsonl\",\n",
    "    target_predict_file=\"../../../data/cnn/cnn_dev.json\",\n",
    "    input_dir=\"model/fine_tuning\",\n",
    "    input_model_file=\"ft_squad_1_20250916.bin\",\n",
    "    output_dir=\"model/adapt\",\n",
    "    output_model_file=\"squad2cnn_1_20251105.bin\",\n",
    "    logger_path=\"logs/adapt/squad2cnn_1_20251105\",\n",
    "    max_seq_length=512,\n",
    "    seed=42,\n",
    "    gradient_accumulation_steps=1,\n",
    "    train_batch_size=12,\n",
    "    predict_batch_size=12,\n",
    "    num_workers=4,\n",
    "    evaluation_interval=2000,\n",
    "    loss_logging_interval=500,\n",
    "    train_learning_rate=3e-5,\n",
    "    num_train_epochs=2,\n",
    "    warmup_proportion=0.1,\n",
    "    n_best_size=20,\n",
    "    max_answer_length=30,\n",
    "    verbose_logging=False,\n",
    "    use_simple_feature=False,\n",
    "    generate_prob_th=0.6,\n",
    "    keep_previous_generated=False,\n",
    "    use_BN=True,\n",
    "    output_prediction=True,\n",
    "    source_sampling_ratio=3,\n",
    "    doc_stride=128,\n",
    "    max_query_length=64,\n",
    "    adapt_learning_rate=1e-5,\n",
    "    lambda_c=0.1,\n",
    "    sample_limit= 100  ### 디버깅용 데이터셋 크기\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9468b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/05/2025 12:25:53 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/gayeon44/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = cuda\n"
     ]
    }
   ],
   "source": [
    "# 3) 로거/디바이스/토크나이저 준비\n",
    "logger = config_logger(args.logger_path)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = BertTokenizer.from_pretrained(args.bert_model, do_lower_case=args.do_lower_case)\n",
    "\n",
    "print(f\"device = {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45e6e9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/05/2025 12:26:01 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/gayeon44/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "11/05/2025 12:26:01 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /home/gayeon44/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpn60klqn6\n",
      "11/05/2025 12:26:03 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_seq_length\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_BN\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "11/05/2025 12:26:05 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/gayeon44/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "11/05/2025 12:26:05 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /home/gayeon44/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmprjpqet5y\n",
      "11/05/2025 12:26:06 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_seq_length\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_BN\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "11/05/2025 12:26:07 - INFO - utils.ConfigLogger -   ***** Reading Target Unlabeled Training Samples *****\n",
      "11/05/2025 12:27:08 - INFO - utils.ConfigLogger -   ***** Reading Source Training Samples *****\n",
      "11/05/2025 12:27:15 - INFO - utils.ConfigLogger -   ***** Reading Evaluation Samples *****\n",
      "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]11/05/2025 12:27:17 - INFO - utils.ConfigLogger -   \n",
      "\n",
      "11/05/2025 12:27:17 - INFO - utils.ConfigLogger -    ###########  Start Training Epoch 1  ###########\n",
      "11/05/2025 12:27:17 - INFO - utils.ConfigLogger -   \n",
      "\n",
      "11/05/2025 12:27:17 - INFO - utils.ConfigLogger -   ***** Generating training data for this epoch *****\n",
      "11/05/2025 12:27:17 - INFO - utils.ConfigLogger -   ***** Running Evaluation Stage *****\n",
      "11/05/2025 12:27:17 - INFO - utils.ConfigLogger -     Num orig examples = 50\n",
      "11/05/2025 12:27:17 - INFO - utils.ConfigLogger -     Num split examples = 50\n",
      "11/05/2025 12:27:17 - INFO - utils.ConfigLogger -     Batch size = 12\n",
      "11/05/2025 12:27:17 - INFO - utils.ConfigLogger -   Start evaluating\n",
      "Evaluating: 100%|██████████| 5/5 [00:00<00:00, 15.55it/s]\n",
      "11/05/2025 12:27:17 - INFO - utils.ConfigLogger -   Writing predictions to: model/squad2target/predictions_20251105_12:27:17.json\n",
      "11/05/2025 12:27:17 - INFO - utils.ConfigLogger -   Writing nbest to: model/squad2target/nbest_predictions_20251105_12:27:17.json\n",
      "11/05/2025 12:27:17 - INFO - utils.ConfigLogger -   \n",
      "\n",
      "11/05/2025 12:27:17 - INFO - utils.ConfigLogger -   ====================  Start Adversarial Training Stage  ====================\n",
      "11/05/2025 12:27:17 - INFO - utils.ConfigLogger -     Num split examples = 2\n",
      "11/05/2025 12:27:17 - INFO - utils.ConfigLogger -     Batch size = 12\n",
      "11/05/2025 12:27:17 - INFO - utils.ConfigLogger -     Num steps = 1\n",
      "/home/gayeon44/gayeon/[DA]/preliminary/QC4QA/src/pytorch_pretrained_bert/optimization.py:132: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at /pytorch/torch/csrc/utils/python_arg_parser.cpp:1805.)\n",
      "  next_m.mul_(beta1).add_(1 - beta1, grad)\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00,  3.55it/s]\n",
      "11/05/2025 12:27:18 - INFO - utils.ConfigLogger -   ***** Running Predictions *****\n",
      "11/05/2025 12:27:18 - INFO - utils.ConfigLogger -     Num orig examples = 50\n",
      "11/05/2025 12:27:18 - INFO - utils.ConfigLogger -     Num split examples = 50\n",
      "11/05/2025 12:27:18 - INFO - utils.ConfigLogger -     Batch size = 12\n",
      "11/05/2025 12:27:18 - INFO - utils.ConfigLogger -   Start evaluating\n",
      "Evaluating: 100%|██████████| 5/5 [00:00<00:00, 30.07it/s]\n",
      "11/05/2025 12:27:19 - INFO - utils.ConfigLogger -   Writing predictions to: model/squad2target/predictions_1_20251105_12:27:19.json\n",
      "11/05/2025 12:27:19 - INFO - utils.ConfigLogger -   Writing nbest to: model/squad2target/nbest_predictions_1_20251105_12:27:19.json\n",
      "/tmp/ipykernel_9481/3773295735.py:27: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  logger.warn(message)\n",
      "11/05/2025 12:27:19 - WARNING - utils.ConfigLogger -   Unanswered question validation/fd0dc9fcbb41450c388f6d3f90153da19f53e050 will receive score 0.\n",
      "11/05/2025 12:27:19 - WARNING - utils.ConfigLogger -   Unanswered question validation/7ad6bf269adef016560ea4d857150771842e0d23 will receive score 0.\n",
      "11/05/2025 12:27:19 - WARNING - utils.ConfigLogger -   Unanswered question validation/de308d2ec5722143d8156c3fe2192a2884ca86f9 will receive score 0.\n",
      "11/05/2025 12:27:19 - WARNING - utils.ConfigLogger -   Unanswered question validation/c1875aa38c8ac079d128a4ddf92259479955abcc will receive score 0.\n",
      "11/05/2025 12:27:19 - WARNING - utils.ConfigLogger -   Unanswered question validation/1993fab60212e6627aea8ae78a33d9a81ab0e27c will receive score 0.\n",
      "11/05/2025 12:27:19 - WARNING - utils.ConfigLogger -   Unanswered question validation/6253f6fb35a222d648643465c6b9399dcdbe13a1 will receive score 0.\n",
      "11/05/2025 12:27:19 - WARNING - utils.ConfigLogger -   Unanswered question validation/1714ebeffea86e2788bfb7653ada360f61af2ff7 will receive score 0.\n",
      "11/05/2025 12:27:19 - WARNING - utils.ConfigLogger -   Unanswered question validation/656544054260257c0fa082e68c795a2152a49fc8 will receive score 0.\n",
      "11/05/2025 12:27:19 - WARNING - utils.ConfigLogger -   Unanswered question validation/d4c01b8a4fb735a1734d9c8fadddb1028b751b34 will receive score 0.\n",
      "11/05/2025 12:27:19 - WARNING - utils.ConfigLogger -   Unanswered question validation/6c22ba2fa5c59946e284a888fcc7c74fcac38e65 will receive score 0.\n",
      "11/05/2025 12:27:19 - WARNING - utils.ConfigLogger -   Unanswered question validation/bf9c95d342a51ffe32440116c9d5b1b7dfa96531 will receive score 0.\n",
      "11/05/2025 12:27:19 - WARNING - utils.ConfigLogger -   Unanswered question validation/d787ad7de05d3f63168579a29ded97b35bffd1b6 will receive score 0.\n",
      "11/05/2025 12:27:19 - WARNING - utils.ConfigLogger -   Unanswered question validation/c9d2e46b29b21b8b598b4b80803c1af651e7f1d2 will receive score 0.\n",
      "11/05/2025 12:27:19 - WARNING - utils.ConfigLogger -   Unanswered question validation/0957a9a140132d7f2ba596b62628fb98e5470a80 will receive score 0.\n",
      "11/05/2025 12:27:19 - WARNING - utils.ConfigLogger -   Unanswered question validation/033daf6ae73daf122e5982c6422b284d69b42764 will receive score 0.\n",
      "11/05/2025 12:27:19 - WARNING - utils.ConfigLogger -   Unanswered question validation/b3eff20f10ae157008ccf8962ed340feee33d31b will receive score 0.\n",
      "11/05/2025 12:27:19 - WARNING - utils.ConfigLogger -   Unanswered question validation/b1096769370114b16f44468ecb9aa2f9addaec3c will receive score 0.\n",
      "11/05/2025 12:27:19 - WARNING - utils.ConfigLogger -   Unanswered question validation/cbd9f3fae1ca0c7eabf3d38b3311c9998995d13e will receive score 0.\n",
      "11/05/2025 12:27:19 - WARNING - utils.ConfigLogger -   Unanswered question validation/01f460fa9d4289827ece2af1344485728e414981 will receive score 0.\n",
      "11/05/2025 12:27:19 - WARNING - utils.ConfigLogger -   Unanswered question validation/78c8d1e634e80e210626dc12671d13b62d10bc99 will receive score 0.\n",
      "11/05/2025 12:27:19 - WARNING - utils.ConfigLogger -   Unanswered question validation/5ec7c78400e01b1dcf2bd7d2cf9d6610ff59af12 will receive score 0.\n",
      "11/05/2025 12:27:19 - INFO - utils.ConfigLogger -   Current EM is 13.79310, F1 is 24.43514\n",
      "11/05/2025 12:27:19 - INFO - utils.ConfigLogger -   Current model BEATS previous best model, previous best is EM = 0.00000, F1 = 0.00000\n",
      "11/05/2025 12:27:19 - INFO - utils.ConfigLogger -   Current best model has been saved!\n",
      "11/05/2025 12:27:19 - INFO - utils.ConfigLogger -   \n",
      "\n",
      "11/05/2025 12:27:19 - INFO - utils.ConfigLogger -    ###########  End Training Epoch 1  ###########\n",
      "11/05/2025 12:27:19 - INFO - utils.ConfigLogger -   \n",
      "\n",
      "Epoch:  50%|█████     | 1/2 [00:01<00:01,  1.86s/it]11/05/2025 12:27:19 - INFO - utils.ConfigLogger -   \n",
      "\n",
      "11/05/2025 12:27:19 - INFO - utils.ConfigLogger -    ###########  Start Training Epoch 2  ###########\n",
      "11/05/2025 12:27:19 - INFO - utils.ConfigLogger -   \n",
      "\n",
      "11/05/2025 12:27:19 - INFO - utils.ConfigLogger -   ***** Generating training data for this epoch *****\n",
      "11/05/2025 12:27:19 - INFO - utils.ConfigLogger -   ***** Running Evaluation Stage *****\n",
      "11/05/2025 12:27:19 - INFO - utils.ConfigLogger -     Num orig examples = 50\n",
      "11/05/2025 12:27:19 - INFO - utils.ConfigLogger -     Num split examples = 50\n",
      "11/05/2025 12:27:19 - INFO - utils.ConfigLogger -     Batch size = 12\n",
      "11/05/2025 12:27:19 - INFO - utils.ConfigLogger -   Start evaluating\n",
      "Evaluating: 100%|██████████| 5/5 [00:00<00:00, 29.85it/s]\n",
      "11/05/2025 12:27:19 - INFO - utils.ConfigLogger -   Writing predictions to: model/squad2target/predictions_20251105_12:27:19.json\n",
      "11/05/2025 12:27:19 - INFO - utils.ConfigLogger -   Writing nbest to: model/squad2target/nbest_predictions_20251105_12:27:19.json\n",
      "11/05/2025 12:27:19 - INFO - utils.ConfigLogger -   \n",
      "\n",
      "11/05/2025 12:27:19 - INFO - utils.ConfigLogger -   ====================  Start Adversarial Training Stage  ====================\n",
      "11/05/2025 12:27:19 - INFO - utils.ConfigLogger -     Num split examples = 2\n",
      "11/05/2025 12:27:19 - INFO - utils.ConfigLogger -     Batch size = 12\n",
      "11/05/2025 12:27:19 - INFO - utils.ConfigLogger -     Num steps = 1\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 10.83it/s]\n",
      "11/05/2025 12:27:19 - INFO - utils.ConfigLogger -   ***** Running Predictions *****\n",
      "11/05/2025 12:27:19 - INFO - utils.ConfigLogger -     Num orig examples = 50\n",
      "11/05/2025 12:27:19 - INFO - utils.ConfigLogger -     Num split examples = 50\n",
      "11/05/2025 12:27:19 - INFO - utils.ConfigLogger -     Batch size = 12\n",
      "11/05/2025 12:27:19 - INFO - utils.ConfigLogger -   Start evaluating\n",
      "Evaluating: 100%|██████████| 5/5 [00:00<00:00, 30.02it/s]\n",
      "11/05/2025 12:27:19 - INFO - utils.ConfigLogger -   Writing predictions to: model/squad2target/predictions_1_20251105_12:27:19.json\n",
      "11/05/2025 12:27:19 - INFO - utils.ConfigLogger -   Writing nbest to: model/squad2target/nbest_predictions_1_20251105_12:27:19.json\n",
      "11/05/2025 12:27:19 - WARNING - utils.ConfigLogger -   Unanswered question validation/fd0dc9fcbb41450c388f6d3f90153da19f53e050 will receive score 0.\n",
      "11/05/2025 12:27:19 - WARNING - utils.ConfigLogger -   Unanswered question validation/7ad6bf269adef016560ea4d857150771842e0d23 will receive score 0.\n",
      "11/05/2025 12:27:19 - WARNING - utils.ConfigLogger -   Unanswered question validation/de308d2ec5722143d8156c3fe2192a2884ca86f9 will receive score 0.\n",
      "11/05/2025 12:27:19 - WARNING - utils.ConfigLogger -   Unanswered question validation/c1875aa38c8ac079d128a4ddf92259479955abcc will receive score 0.\n",
      "11/05/2025 12:27:19 - WARNING - utils.ConfigLogger -   Unanswered question validation/1993fab60212e6627aea8ae78a33d9a81ab0e27c will receive score 0.\n",
      "11/05/2025 12:27:19 - WARNING - utils.ConfigLogger -   Unanswered question validation/6253f6fb35a222d648643465c6b9399dcdbe13a1 will receive score 0.\n",
      "11/05/2025 12:27:19 - WARNING - utils.ConfigLogger -   Unanswered question validation/1714ebeffea86e2788bfb7653ada360f61af2ff7 will receive score 0.\n",
      "11/05/2025 12:27:19 - WARNING - utils.ConfigLogger -   Unanswered question validation/656544054260257c0fa082e68c795a2152a49fc8 will receive score 0.\n",
      "11/05/2025 12:27:19 - WARNING - utils.ConfigLogger -   Unanswered question validation/d4c01b8a4fb735a1734d9c8fadddb1028b751b34 will receive score 0.\n",
      "11/05/2025 12:27:19 - WARNING - utils.ConfigLogger -   Unanswered question validation/6c22ba2fa5c59946e284a888fcc7c74fcac38e65 will receive score 0.\n",
      "11/05/2025 12:27:19 - WARNING - utils.ConfigLogger -   Unanswered question validation/bf9c95d342a51ffe32440116c9d5b1b7dfa96531 will receive score 0.\n",
      "11/05/2025 12:27:19 - WARNING - utils.ConfigLogger -   Unanswered question validation/d787ad7de05d3f63168579a29ded97b35bffd1b6 will receive score 0.\n",
      "11/05/2025 12:27:19 - WARNING - utils.ConfigLogger -   Unanswered question validation/c9d2e46b29b21b8b598b4b80803c1af651e7f1d2 will receive score 0.\n",
      "11/05/2025 12:27:19 - WARNING - utils.ConfigLogger -   Unanswered question validation/0957a9a140132d7f2ba596b62628fb98e5470a80 will receive score 0.\n",
      "11/05/2025 12:27:19 - WARNING - utils.ConfigLogger -   Unanswered question validation/033daf6ae73daf122e5982c6422b284d69b42764 will receive score 0.\n",
      "11/05/2025 12:27:19 - WARNING - utils.ConfigLogger -   Unanswered question validation/b3eff20f10ae157008ccf8962ed340feee33d31b will receive score 0.\n",
      "11/05/2025 12:27:19 - WARNING - utils.ConfigLogger -   Unanswered question validation/b1096769370114b16f44468ecb9aa2f9addaec3c will receive score 0.\n",
      "11/05/2025 12:27:19 - WARNING - utils.ConfigLogger -   Unanswered question validation/cbd9f3fae1ca0c7eabf3d38b3311c9998995d13e will receive score 0.\n",
      "11/05/2025 12:27:19 - WARNING - utils.ConfigLogger -   Unanswered question validation/01f460fa9d4289827ece2af1344485728e414981 will receive score 0.\n",
      "11/05/2025 12:27:19 - WARNING - utils.ConfigLogger -   Unanswered question validation/78c8d1e634e80e210626dc12671d13b62d10bc99 will receive score 0.\n",
      "11/05/2025 12:27:19 - WARNING - utils.ConfigLogger -   Unanswered question validation/5ec7c78400e01b1dcf2bd7d2cf9d6610ff59af12 will receive score 0.\n",
      "11/05/2025 12:27:19 - INFO - utils.ConfigLogger -   Current EM is 13.79310, F1 is 24.43514\n",
      "11/05/2025 12:27:19 - INFO - utils.ConfigLogger -   Current model CANNOT beat previous best model, previous best is EM = 13.79310, F1 = 24.43514\n",
      "11/05/2025 12:27:19 - INFO - utils.ConfigLogger -   \n",
      "\n",
      "11/05/2025 12:27:19 - INFO - utils.ConfigLogger -    ###########  End Training Epoch 2  ###########\n",
      "11/05/2025 12:27:19 - INFO - utils.ConfigLogger -   \n",
      "\n",
      "Epoch: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]\n",
      "11/05/2025 12:27:20 - INFO - utils.ConfigLogger -   The final model has been save\n",
      "11/05/2025 12:27:20 - INFO - utils.ConfigLogger -   *** The Training Stage is Ended ***\n",
      "11/05/2025 12:27:20 - INFO - utils.ConfigLogger -   \n",
      "\n",
      "Best EM is 13.79310. Best F1 is 24.43514\n",
      "11/05/2025 12:27:20 - INFO - utils.ConfigLogger -   \n",
      "\n",
      "Final EM is 13.79310. Best F1 is 24.43514\n"
     ]
    }
   ],
   "source": [
    "# 4) 입력 모델 로드 및 적응 단계 실행\n",
    "model = prepare_model(args, device)\n",
    "adaptation_stage(args, tokenizer, device, logger, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81480207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "🔍 DATA PIPELINE TEST - 데이터 흐름 확인\n",
      "================================================================================\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "📄 STEP 1: Raw JSON Data\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "✓ Question: To whom did the Virgin Mary allegedly appear in 1858 in Lour...\n",
      "✓ q_type: 3\n",
      "✓ q_type_prob: [0.0, 0.0, 0.016, 0.983, 0.001, 0.0]\n",
      "✓ Top-3 types: [(3, 0.983), (2, 0.016), (4, 0.001)]\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# 🧪 테스트 코드: 데이터 파이프라인 검증\n",
    "###############################################################################\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"🔍 DATA PIPELINE TEST - 데이터 흐름 확인\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Step 1: Raw JSON 데이터 확인\n",
    "print(\"\\n\" + \"─\"*80)\n",
    "print(\"📄 STEP 1: Raw JSON Data\")\n",
    "print(\"─\"*80)\n",
    "sample_qa = train_squad_data[0]['paragraphs'][0]['qas'][0]\n",
    "print(f\"✓ Question: {sample_qa['question'][:60]}...\")\n",
    "print(f\"✓ q_type: {sample_qa['q_type']}\")\n",
    "print(f\"✓ q_type_prob: {sample_qa['q_type_prob']}\")\n",
    "print(f\"✓ Top-3 types: {sorted(enumerate(sample_qa['q_type_prob']), key=lambda x: x[1], reverse=True)[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d14cfebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "📦 STEP 2: SquadExample Creation\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "✓ Total examples: 87599\n",
      "✓ Example[0] type: <class 'da_data_utils.SquadExample'>\n",
      "✓ Example[0].q_type: 3\n",
      "✓ Example[0].q_type_prob: [0.0, 0.0, 0.016, 0.983, 0.001, 0.0]\n",
      "✓ Has q_type_prob attribute: True\n"
     ]
    }
   ],
   "source": [
    "# Step 2: SquadExample 생성 확인\n",
    "print(\"\\n\" + \"─\"*80)\n",
    "print(\"📦 STEP 2: SquadExample Creation\")\n",
    "print(\"─\"*80)\n",
    "test_examples = read_squad_examples(\n",
    "    input_file='../../../data/squad/train-v1.1_classified_qtype_prob.jsonl',\n",
    "    is_training=True,\n",
    "    logger=logger\n",
    ")\n",
    "print(f\"✓ Total examples: {len(test_examples)}\")\n",
    "print(f\"✓ Example[0] type: {type(test_examples[0])}\")\n",
    "print(f\"✓ Example[0].q_type: {test_examples[0].q_type}\")\n",
    "print(f\"✓ Example[0].q_type_prob: {test_examples[0].q_type_prob}\")\n",
    "print(f\"✓ Has q_type_prob attribute: {hasattr(test_examples[0], 'q_type_prob')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5c0b65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "🔧 STEP 3: InputFeatures Conversion\n",
      "────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   *** Example ***\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   unique_id: 1000000000\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   example_index: 0\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   doc_span_index: 0\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   tokens: [CLS] to whom did the virgin mary allegedly appear in 1858 in lou ##rdes france ? [SEP] architectural ##ly , the school has a catholic character . atop the main building ' s gold dome is a golden statue of the virgin mary . immediately in front of the main building and facing it , is a copper statue of christ with arms up ##rai ##sed with the legend \" ve ##ni ##te ad me om ##nes \" . next to the main building is the basilica of the sacred heart . immediately behind the basilica is the gr ##otto , a marian place of prayer and reflection . it is a replica of the gr ##otto at lou ##rdes , france where the virgin mary reputed ##ly appeared to saint bern ##ade ##tte so ##ub ##iro ##us in 1858 . at the end of the main drive ( and in a direct line that connects through 3 statues and the gold dome ) , is a simple , modern stone statue of mary . [SEP]\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   token_to_orig_map: 17:0 18:0 19:0 20:1 21:2 22:3 23:4 24:5 25:6 26:6 27:7 28:8 29:9 30:10 31:10 32:10 33:11 34:12 35:13 36:14 37:15 38:16 39:17 40:18 41:19 42:20 43:20 44:21 45:22 46:23 47:24 48:25 49:26 50:27 51:28 52:29 53:30 54:30 55:31 56:32 57:33 58:34 59:35 60:36 61:37 62:38 63:39 64:39 65:39 66:40 67:41 68:42 69:43 70:43 71:43 72:43 73:44 74:45 75:46 76:46 77:46 78:46 79:47 80:48 81:49 82:50 83:51 84:52 85:53 86:54 87:55 88:56 89:57 90:58 91:58 92:59 93:60 94:61 95:62 96:63 97:64 98:65 99:65 100:65 101:66 102:67 103:68 104:69 105:70 106:71 107:72 108:72 109:73 110:74 111:75 112:76 113:77 114:78 115:79 116:79 117:80 118:81 119:81 120:81 121:82 122:83 123:84 124:85 125:86 126:87 127:87 128:88 129:89 130:90 131:91 132:91 133:91 134:92 135:92 136:92 137:92 138:93 139:94 140:94 141:95 142:96 143:97 144:98 145:99 146:100 147:101 148:102 149:102 150:103 151:104 152:105 153:106 154:107 155:108 156:109 157:110 158:111 159:112 160:113 161:114 162:115 163:115 164:115 165:116 166:117 167:118 168:118 169:119 170:120 171:121 172:122 173:123 174:123\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   token_is_max_context: 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   input_ids: 101 2000 3183 2106 1996 6261 2984 9382 3711 1999 8517 1999 10223 26371 2605 1029 102 6549 2135 1010 1996 2082 2038 1037 3234 2839 1012 10234 1996 2364 2311 1005 1055 2751 8514 2003 1037 3585 6231 1997 1996 6261 2984 1012 3202 1999 2392 1997 1996 2364 2311 1998 5307 2009 1010 2003 1037 6967 6231 1997 4828 2007 2608 2039 14995 6924 2007 1996 5722 1000 2310 3490 2618 4748 2033 18168 5267 1000 1012 2279 2000 1996 2364 2311 2003 1996 13546 1997 1996 6730 2540 1012 3202 2369 1996 13546 2003 1996 24665 23052 1010 1037 14042 2173 1997 7083 1998 9185 1012 2009 2003 1037 15059 1997 1996 24665 23052 2012 10223 26371 1010 2605 2073 1996 6261 2984 22353 2135 2596 2000 3002 16595 9648 4674 2061 12083 9711 2271 1999 8517 1012 2012 1996 2203 1997 1996 2364 3298 1006 1998 1999 1037 3622 2240 2008 8539 2083 1017 11342 1998 1996 2751 8514 1007 1010 2003 1037 3722 1010 2715 2962 6231 1997 2984 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   start_position: 130\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   end_position: 137\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   answer: saint bern ##ade ##tte so ##ub ##iro ##us\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   *** Example ***\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   unique_id: 1000000001\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   example_index: 1\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   doc_span_index: 0\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   tokens: [CLS] what is in front of the notre dame main building ? [SEP] architectural ##ly , the school has a catholic character . atop the main building ' s gold dome is a golden statue of the virgin mary . immediately in front of the main building and facing it , is a copper statue of christ with arms up ##rai ##sed with the legend \" ve ##ni ##te ad me om ##nes \" . next to the main building is the basilica of the sacred heart . immediately behind the basilica is the gr ##otto , a marian place of prayer and reflection . it is a replica of the gr ##otto at lou ##rdes , france where the virgin mary reputed ##ly appeared to saint bern ##ade ##tte so ##ub ##iro ##us in 1858 . at the end of the main drive ( and in a direct line that connects through 3 statues and the gold dome ) , is a simple , modern stone statue of mary . [SEP]\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   token_to_orig_map: 13:0 14:0 15:0 16:1 17:2 18:3 19:4 20:5 21:6 22:6 23:7 24:8 25:9 26:10 27:10 28:10 29:11 30:12 31:13 32:14 33:15 34:16 35:17 36:18 37:19 38:20 39:20 40:21 41:22 42:23 43:24 44:25 45:26 46:27 47:28 48:29 49:30 50:30 51:31 52:32 53:33 54:34 55:35 56:36 57:37 58:38 59:39 60:39 61:39 62:40 63:41 64:42 65:43 66:43 67:43 68:43 69:44 70:45 71:46 72:46 73:46 74:46 75:47 76:48 77:49 78:50 79:51 80:52 81:53 82:54 83:55 84:56 85:57 86:58 87:58 88:59 89:60 90:61 91:62 92:63 93:64 94:65 95:65 96:65 97:66 98:67 99:68 100:69 101:70 102:71 103:72 104:72 105:73 106:74 107:75 108:76 109:77 110:78 111:79 112:79 113:80 114:81 115:81 116:81 117:82 118:83 119:84 120:85 121:86 122:87 123:87 124:88 125:89 126:90 127:91 128:91 129:91 130:92 131:92 132:92 133:92 134:93 135:94 136:94 137:95 138:96 139:97 140:98 141:99 142:100 143:101 144:102 145:102 146:103 147:104 148:105 149:106 150:107 151:108 152:109 153:110 154:111 155:112 156:113 157:114 158:115 159:115 160:115 161:116 162:117 163:118 164:118 165:119 166:120 167:121 168:122 169:123 170:123\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   token_is_max_context: 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   input_ids: 101 2054 2003 1999 2392 1997 1996 10289 8214 2364 2311 1029 102 6549 2135 1010 1996 2082 2038 1037 3234 2839 1012 10234 1996 2364 2311 1005 1055 2751 8514 2003 1037 3585 6231 1997 1996 6261 2984 1012 3202 1999 2392 1997 1996 2364 2311 1998 5307 2009 1010 2003 1037 6967 6231 1997 4828 2007 2608 2039 14995 6924 2007 1996 5722 1000 2310 3490 2618 4748 2033 18168 5267 1000 1012 2279 2000 1996 2364 2311 2003 1996 13546 1997 1996 6730 2540 1012 3202 2369 1996 13546 2003 1996 24665 23052 1010 1037 14042 2173 1997 7083 1998 9185 1012 2009 2003 1037 15059 1997 1996 24665 23052 2012 10223 26371 1010 2605 2073 1996 6261 2984 22353 2135 2596 2000 3002 16595 9648 4674 2061 12083 9711 2271 1999 8517 1012 2012 1996 2203 1997 1996 2364 3298 1006 1998 1999 1037 3622 2240 2008 8539 2083 1017 11342 1998 1996 2751 8514 1007 1010 2003 1037 3722 1010 2715 2962 6231 1997 2984 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   start_position: 52\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   end_position: 56\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   answer: a copper statue of christ\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   *** Example ***\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   unique_id: 1000000002\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   example_index: 2\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   doc_span_index: 0\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   tokens: [CLS] the basilica of the sacred heart at notre dame is beside to which structure ? [SEP] architectural ##ly , the school has a catholic character . atop the main building ' s gold dome is a golden statue of the virgin mary . immediately in front of the main building and facing it , is a copper statue of christ with arms up ##rai ##sed with the legend \" ve ##ni ##te ad me om ##nes \" . next to the main building is the basilica of the sacred heart . immediately behind the basilica is the gr ##otto , a marian place of prayer and reflection . it is a replica of the gr ##otto at lou ##rdes , france where the virgin mary reputed ##ly appeared to saint bern ##ade ##tte so ##ub ##iro ##us in 1858 . at the end of the main drive ( and in a direct line that connects through 3 statues and the gold dome ) , is a simple , modern stone statue of mary . [SEP]\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   token_to_orig_map: 17:0 18:0 19:0 20:1 21:2 22:3 23:4 24:5 25:6 26:6 27:7 28:8 29:9 30:10 31:10 32:10 33:11 34:12 35:13 36:14 37:15 38:16 39:17 40:18 41:19 42:20 43:20 44:21 45:22 46:23 47:24 48:25 49:26 50:27 51:28 52:29 53:30 54:30 55:31 56:32 57:33 58:34 59:35 60:36 61:37 62:38 63:39 64:39 65:39 66:40 67:41 68:42 69:43 70:43 71:43 72:43 73:44 74:45 75:46 76:46 77:46 78:46 79:47 80:48 81:49 82:50 83:51 84:52 85:53 86:54 87:55 88:56 89:57 90:58 91:58 92:59 93:60 94:61 95:62 96:63 97:64 98:65 99:65 100:65 101:66 102:67 103:68 104:69 105:70 106:71 107:72 108:72 109:73 110:74 111:75 112:76 113:77 114:78 115:79 116:79 117:80 118:81 119:81 120:81 121:82 122:83 123:84 124:85 125:86 126:87 127:87 128:88 129:89 130:90 131:91 132:91 133:91 134:92 135:92 136:92 137:92 138:93 139:94 140:94 141:95 142:96 143:97 144:98 145:99 146:100 147:101 148:102 149:102 150:103 151:104 152:105 153:106 154:107 155:108 156:109 157:110 158:111 159:112 160:113 161:114 162:115 163:115 164:115 165:116 166:117 167:118 168:118 169:119 170:120 171:121 172:122 173:123 174:123\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   token_is_max_context: 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   input_ids: 101 1996 13546 1997 1996 6730 2540 2012 10289 8214 2003 3875 2000 2029 3252 1029 102 6549 2135 1010 1996 2082 2038 1037 3234 2839 1012 10234 1996 2364 2311 1005 1055 2751 8514 2003 1037 3585 6231 1997 1996 6261 2984 1012 3202 1999 2392 1997 1996 2364 2311 1998 5307 2009 1010 2003 1037 6967 6231 1997 4828 2007 2608 2039 14995 6924 2007 1996 5722 1000 2310 3490 2618 4748 2033 18168 5267 1000 1012 2279 2000 1996 2364 2311 2003 1996 13546 1997 1996 6730 2540 1012 3202 2369 1996 13546 2003 1996 24665 23052 1010 1037 14042 2173 1997 7083 1998 9185 1012 2009 2003 1037 15059 1997 1996 24665 23052 2012 10223 26371 1010 2605 2073 1996 6261 2984 22353 2135 2596 2000 3002 16595 9648 4674 2061 12083 9711 2271 1999 8517 1012 2012 1996 2203 1997 1996 2364 3298 1006 1998 1999 1037 3622 2240 2008 8539 2083 1017 11342 1998 1996 2751 8514 1007 1010 2003 1037 3722 1010 2715 2962 6231 1997 2984 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   start_position: 81\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   end_position: 83\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   answer: the main building\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   *** Example ***\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   unique_id: 1000000003\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   example_index: 3\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   doc_span_index: 0\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   tokens: [CLS] what is the gr ##otto at notre dame ? [SEP] architectural ##ly , the school has a catholic character . atop the main building ' s gold dome is a golden statue of the virgin mary . immediately in front of the main building and facing it , is a copper statue of christ with arms up ##rai ##sed with the legend \" ve ##ni ##te ad me om ##nes \" . next to the main building is the basilica of the sacred heart . immediately behind the basilica is the gr ##otto , a marian place of prayer and reflection . it is a replica of the gr ##otto at lou ##rdes , france where the virgin mary reputed ##ly appeared to saint bern ##ade ##tte so ##ub ##iro ##us in 1858 . at the end of the main drive ( and in a direct line that connects through 3 statues and the gold dome ) , is a simple , modern stone statue of mary . [SEP]\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   token_to_orig_map: 11:0 12:0 13:0 14:1 15:2 16:3 17:4 18:5 19:6 20:6 21:7 22:8 23:9 24:10 25:10 26:10 27:11 28:12 29:13 30:14 31:15 32:16 33:17 34:18 35:19 36:20 37:20 38:21 39:22 40:23 41:24 42:25 43:26 44:27 45:28 46:29 47:30 48:30 49:31 50:32 51:33 52:34 53:35 54:36 55:37 56:38 57:39 58:39 59:39 60:40 61:41 62:42 63:43 64:43 65:43 66:43 67:44 68:45 69:46 70:46 71:46 72:46 73:47 74:48 75:49 76:50 77:51 78:52 79:53 80:54 81:55 82:56 83:57 84:58 85:58 86:59 87:60 88:61 89:62 90:63 91:64 92:65 93:65 94:65 95:66 96:67 97:68 98:69 99:70 100:71 101:72 102:72 103:73 104:74 105:75 106:76 107:77 108:78 109:79 110:79 111:80 112:81 113:81 114:81 115:82 116:83 117:84 118:85 119:86 120:87 121:87 122:88 123:89 124:90 125:91 126:91 127:91 128:92 129:92 130:92 131:92 132:93 133:94 134:94 135:95 136:96 137:97 138:98 139:99 140:100 141:101 142:102 143:102 144:103 145:104 146:105 147:106 148:107 149:108 150:109 151:110 152:111 153:112 154:113 155:114 156:115 157:115 158:115 159:116 160:117 161:118 162:118 163:119 164:120 165:121 166:122 167:123 168:123\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   token_is_max_context: 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   input_ids: 101 2054 2003 1996 24665 23052 2012 10289 8214 1029 102 6549 2135 1010 1996 2082 2038 1037 3234 2839 1012 10234 1996 2364 2311 1005 1055 2751 8514 2003 1037 3585 6231 1997 1996 6261 2984 1012 3202 1999 2392 1997 1996 2364 2311 1998 5307 2009 1010 2003 1037 6967 6231 1997 4828 2007 2608 2039 14995 6924 2007 1996 5722 1000 2310 3490 2618 4748 2033 18168 5267 1000 1012 2279 2000 1996 2364 2311 2003 1996 13546 1997 1996 6730 2540 1012 3202 2369 1996 13546 2003 1996 24665 23052 1010 1037 14042 2173 1997 7083 1998 9185 1012 2009 2003 1037 15059 1997 1996 24665 23052 2012 10223 26371 1010 2605 2073 1996 6261 2984 22353 2135 2596 2000 3002 16595 9648 4674 2061 12083 9711 2271 1999 8517 1012 2012 1996 2203 1997 1996 2364 3298 1006 1998 1999 1037 3622 2240 2008 8539 2083 1017 11342 1998 1996 2751 8514 1007 1010 2003 1037 3722 1010 2715 2962 6231 1997 2984 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   start_position: 95\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   end_position: 101\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   answer: a marian place of prayer and reflection\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   *** Example ***\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   unique_id: 1000000004\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   example_index: 4\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   doc_span_index: 0\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   tokens: [CLS] what sits on top of the main building at notre dame ? [SEP] architectural ##ly , the school has a catholic character . atop the main building ' s gold dome is a golden statue of the virgin mary . immediately in front of the main building and facing it , is a copper statue of christ with arms up ##rai ##sed with the legend \" ve ##ni ##te ad me om ##nes \" . next to the main building is the basilica of the sacred heart . immediately behind the basilica is the gr ##otto , a marian place of prayer and reflection . it is a replica of the gr ##otto at lou ##rdes , france where the virgin mary reputed ##ly appeared to saint bern ##ade ##tte so ##ub ##iro ##us in 1858 . at the end of the main drive ( and in a direct line that connects through 3 statues and the gold dome ) , is a simple , modern stone statue of mary . [SEP]\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   token_to_orig_map: 14:0 15:0 16:0 17:1 18:2 19:3 20:4 21:5 22:6 23:6 24:7 25:8 26:9 27:10 28:10 29:10 30:11 31:12 32:13 33:14 34:15 35:16 36:17 37:18 38:19 39:20 40:20 41:21 42:22 43:23 44:24 45:25 46:26 47:27 48:28 49:29 50:30 51:30 52:31 53:32 54:33 55:34 56:35 57:36 58:37 59:38 60:39 61:39 62:39 63:40 64:41 65:42 66:43 67:43 68:43 69:43 70:44 71:45 72:46 73:46 74:46 75:46 76:47 77:48 78:49 79:50 80:51 81:52 82:53 83:54 84:55 85:56 86:57 87:58 88:58 89:59 90:60 91:61 92:62 93:63 94:64 95:65 96:65 97:65 98:66 99:67 100:68 101:69 102:70 103:71 104:72 105:72 106:73 107:74 108:75 109:76 110:77 111:78 112:79 113:79 114:80 115:81 116:81 117:81 118:82 119:83 120:84 121:85 122:86 123:87 124:87 125:88 126:89 127:90 128:91 129:91 130:91 131:92 132:92 133:92 134:92 135:93 136:94 137:94 138:95 139:96 140:97 141:98 142:99 143:100 144:101 145:102 146:102 147:103 148:104 149:105 150:106 151:107 152:108 153:109 154:110 155:111 156:112 157:113 158:114 159:115 160:115 161:115 162:116 163:117 164:118 165:118 166:119 167:120 168:121 169:122 170:123 171:123\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   token_is_max_context: 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   input_ids: 101 2054 7719 2006 2327 1997 1996 2364 2311 2012 10289 8214 1029 102 6549 2135 1010 1996 2082 2038 1037 3234 2839 1012 10234 1996 2364 2311 1005 1055 2751 8514 2003 1037 3585 6231 1997 1996 6261 2984 1012 3202 1999 2392 1997 1996 2364 2311 1998 5307 2009 1010 2003 1037 6967 6231 1997 4828 2007 2608 2039 14995 6924 2007 1996 5722 1000 2310 3490 2618 4748 2033 18168 5267 1000 1012 2279 2000 1996 2364 2311 2003 1996 13546 1997 1996 6730 2540 1012 3202 2369 1996 13546 2003 1996 24665 23052 1010 1037 14042 2173 1997 7083 1998 9185 1012 2009 2003 1037 15059 1997 1996 24665 23052 2012 10223 26371 1010 2605 2073 1996 6261 2984 22353 2135 2596 2000 3002 16595 9648 4674 2061 12083 9711 2271 1999 8517 1012 2012 1996 2203 1997 1996 2364 3298 1006 1998 1999 1037 3622 2240 2008 8539 2083 1017 11342 1998 1996 2751 8514 1007 1010 2003 1037 3722 1010 2715 2962 6231 1997 2984 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   start_position: 33\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   end_position: 39\n",
      "11/05/2025 12:31:09 - INFO - utils.ConfigLogger -   answer: a golden statue of the virgin mary\n",
      "100%|██████████| 5/5 [00:00<00:00, 262.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Total features: 5\n",
      "✓ Feature[0] type: <class 'da_data_utils.InputFeatures'>\n",
      "✓ Feature[0].q_type: 3\n",
      "✓ Feature[0].q_type_prob: [0.0, 0.0, 0.016, 0.983, 0.001, 0.0]\n",
      "✓ Has q_type_prob attribute: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3: InputFeatures 변환 확인\n",
    "print(\"\\n\" + \"─\"*80)\n",
    "print(\"🔧 STEP 3: InputFeatures Conversion\")\n",
    "print(\"─\"*80)\n",
    "test_features = convert_examples_to_features(\n",
    "    examples=test_examples[:5],  # 5개만 테스트\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=args.max_seq_length,\n",
    "    doc_stride=args.doc_stride,\n",
    "    max_query_length=args.max_query_length,\n",
    "    is_training=True,\n",
    "    logger=logger,\n",
    "    use_simple_feature=False\n",
    ")\n",
    "print(f\"✓ Total features: {len(test_features)}\")\n",
    "print(f\"✓ Feature[0] type: {type(test_features[0])}\")\n",
    "print(f\"✓ Feature[0].q_type: {test_features[0].q_type}\")\n",
    "print(f\"✓ Feature[0].q_type_prob: {test_features[0].q_type_prob}\")\n",
    "print(f\"✓ Has q_type_prob attribute: {hasattr(test_features[0], 'q_type_prob')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab78f8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "🎯 STEP 4: TensorDataset Creation\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "✓ all_input_ids shape: torch.Size([5, 512])\n",
      "✓ all_q_types shape: torch.Size([5])\n",
      "✓ all_q_type_probs shape: torch.Size([5, 6])\n",
      "✓ Sample q_type: 3\n",
      "✓ Sample q_type_prob: [0.0, 0.0, 0.01600000075995922, 0.9829999804496765, 0.0010000000474974513, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Step 4: TensorDataset 생성 확인\n",
    "print(\"\\n\" + \"─\"*80)\n",
    "print(\"🎯 STEP 4: TensorDataset Creation\")\n",
    "print(\"─\"*80)\n",
    "\n",
    "# q_type_prob 추출\n",
    "all_q_type_probs = []\n",
    "for f in test_features:\n",
    "    if hasattr(f, 'q_type_prob') and f.q_type_prob is not None:\n",
    "        all_q_type_probs.append(f.q_type_prob)\n",
    "    else:\n",
    "        # Fallback: one-hot encoding\n",
    "        prob = [0.0] * 6\n",
    "        prob[f.q_type] = 1.0\n",
    "        all_q_type_probs.append(prob)\n",
    "\n",
    "all_input_ids = torch.tensor([f.input_ids for f in test_features], dtype=torch.long)\n",
    "all_q_types = torch.tensor([f.q_type for f in test_features], dtype=torch.long)\n",
    "all_q_type_probs = torch.tensor(all_q_type_probs, dtype=torch.float)\n",
    "\n",
    "print(f\"✓ all_input_ids shape: {all_input_ids.shape}\")\n",
    "print(f\"✓ all_q_types shape: {all_q_types.shape}\")\n",
    "print(f\"✓ all_q_type_probs shape: {all_q_type_probs.shape}\")\n",
    "print(f\"✓ Sample q_type: {all_q_types[0].item()}\")\n",
    "print(f\"✓ Sample q_type_prob: {all_q_type_probs[0].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa88e7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "🔝 STEP 5: Top-3 Question Type Extraction\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "  Sample 0:\n",
      "    • Original q_type: 3\n",
      "    • Full q_type_prob: [0.0, 0.0, 0.01600000075995922, 0.9829999804496765, 0.0010000000474974513, 0.0]\n",
      "    • Top-3 indices: [3, 2, 4]\n",
      "    • Top-3 values: ['0.983', '0.016', '0.001']\n",
      "\n",
      "  Sample 1:\n",
      "    • Original q_type: 2\n",
      "    • Full q_type_prob: [0.0, 0.0010000000474974513, 0.9950000047683716, 0.004000000189989805, 0.0, 0.0]\n",
      "    • Top-3 indices: [2, 3, 1]\n",
      "    • Top-3 values: ['0.995', '0.004', '0.001']\n",
      "\n",
      "  Sample 2:\n",
      "    • Original q_type: 2\n",
      "    • Full q_type_prob: [0.0, 0.0010000000474974513, 0.9229999780654907, 0.01899999938905239, 0.05400000140070915, 0.0020000000949949026]\n",
      "    • Top-3 indices: [2, 4, 3]\n",
      "    • Top-3 values: ['0.923', '0.054', '0.019']\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Top-3 추출 테스트\n",
    "print(\"\\n\" + \"─\"*80)\n",
    "print(\"🔝 STEP 5: Top-3 Question Type Extraction\")\n",
    "print(\"─\"*80)\n",
    "\n",
    "for i in range(min(3, len(all_q_type_probs))):\n",
    "    q_type_prob = all_q_type_probs[i]\n",
    "    top3_indices = torch.topk(q_type_prob, k=3).indices.tolist()\n",
    "    top3_values = torch.topk(q_type_prob, k=3).values.tolist()\n",
    "    \n",
    "    print(f\"\\n  Sample {i}:\")\n",
    "    print(f\"    • Original q_type: {all_q_types[i].item()}\")\n",
    "    print(f\"    • Full q_type_prob: {q_type_prob.tolist()}\")\n",
    "    print(f\"    • Top-3 indices: {top3_indices}\")\n",
    "    print(f\"    • Top-3 values: {[f'{v:.3f}' for v in top3_values]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcf380a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "🔗 STEP 6: Source-Target Matching Simulation\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Mock Source Distribution:\n",
      "  • Type 0: 3 samples\n",
      "  • Type 1: 2 samples\n",
      "  • Type 2: 3 samples\n",
      "  • Type 3: 4 samples\n",
      "  • Type 4: 1 samples\n",
      "  • Type 5: 2 samples\n",
      "\n",
      "Target Sample:\n",
      "  • q_type_prob: [0.0, 0.0, 0.01600000075995922, 0.9829999804496765, 0.0010000000474974513, 0.0]\n",
      "  • Top-3 types: [3, 2, 4]\n",
      "\n",
      "Matched Source Samples (1 target → 3 sources):\n",
      "  • Rank 1: Type 3 → Source sample index 8\n",
      "  • Rank 2: Type 2 → Source sample index 5\n",
      "  • Rank 3: Type 4 → Source sample index 12\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Source-Target 매칭 시뮬레이션\n",
    "print(\"\\n\" + \"─\"*80)\n",
    "print(\"🔗 STEP 6: Source-Target Matching Simulation\")\n",
    "print(\"─\"*80)\n",
    "\n",
    "# Mock source data-> value는 source feature의 인덱스 의미\n",
    "source_q_type_dict = {\n",
    "    0: [0, 1, 2],      # What 질문 3개\n",
    "    1: [3, 4],         # When 질문 2개\n",
    "    2: [5, 6, 7],      # Where 질문 3개\n",
    "    3: [8, 9, 10, 11], # Who 질문 4개\n",
    "    4: [12],           # Why 질문 1개\n",
    "    5: [13, 14]        # How 질문 2개\n",
    "}\n",
    "\n",
    "print(\"Mock Source Distribution:\")\n",
    "for q_type, indices in source_q_type_dict.items():\n",
    "    print(f\"  • Type {q_type}: {len(indices)} samples\")\n",
    "\n",
    "# 타겟 샘플 1개에 대해 매칭 시뮬레이션\n",
    "target_sample_prob = all_q_type_probs[0]\n",
    "top3_indices = torch.topk(target_sample_prob, k=3).indices.tolist()\n",
    "\n",
    "print(f\"\\nTarget Sample:\")\n",
    "print(f\"  • q_type_prob: {target_sample_prob.tolist()}\")\n",
    "print(f\"  • Top-3 types: {top3_indices}\")\n",
    "\n",
    "print(f\"\\nMatched Source Samples (1 target → 3 sources):\")\n",
    "for rank, q_type in enumerate(top3_indices):\n",
    "    if len(source_q_type_dict[q_type]) > 0:\n",
    "        source_idx = source_q_type_dict[q_type][0]  # 첫 번째 샘플 선택\n",
    "        print(f\"  • Rank {rank+1}: Type {q_type} → Source sample index {source_idx}\")\n",
    "    else:\n",
    "        print(f\"  • Rank {rank+1}: Type {q_type} → ⚠️ No source samples available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a579312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "📊 STEP 7: Batch Size Comparison\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Before (1:1 matching):\n",
      "  • Target batch: 12\n",
      "  • Source batch: 12\n",
      "  • Total batch: 24\n",
      "\n",
      "After (1:3 matching with top-3 q_type_prob):\n",
      "  • Target batch: 12\n",
      "  • Source batch: 36 (최대)\n",
      "  • Total batch: 48 (최대)\n",
      "  • Memory increase: 100.0%\n",
      "\n",
      "================================================================================\n",
      "✅ DATA PIPELINE TEST COMPLETED\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Step 7: 배치 크기 비교\n",
    "print(\"\\n\" + \"─\"*80)\n",
    "print(\"📊 STEP 7: Batch Size Comparison\")\n",
    "print(\"─\"*80)\n",
    "\n",
    "target_batch_size = 12\n",
    "source_batch_size_old = target_batch_size  # Before: 1:1 매칭\n",
    "source_batch_size_new = target_batch_size * 3  # After: 1:3 매칭\n",
    "\n",
    "print(f\"Before (1:1 matching):\")\n",
    "print(f\"  • Target batch: {target_batch_size}\")\n",
    "print(f\"  • Source batch: {source_batch_size_old}\")\n",
    "print(f\"  • Total batch: {target_batch_size + source_batch_size_old}\")\n",
    "\n",
    "print(f\"\\nAfter (1:3 matching with top-3 q_type_prob):\")\n",
    "print(f\"  • Target batch: {target_batch_size}\")\n",
    "print(f\"  • Source batch: {source_batch_size_new} (최대)\")\n",
    "print(f\"  • Total batch: {target_batch_size + source_batch_size_new} (최대)\")\n",
    "print(f\"  • Memory increase: {((target_batch_size + source_batch_size_new) / (target_batch_size + source_batch_size_old) - 1) * 100:.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✅ DATA PIPELINE TEST COMPLETED\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "659c7e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "🎓 TRAINING BATCH SIMULATION - 실제 학습 데이터 확인\n",
      "================================================================================\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "📁 Loading Real Data (Source + Target)\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "✓ Source features loaded: 20\n",
      "✓ Target features loaded: 10\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# 🧪 테스트 코드 2: 실제 학습 배치 시뮬레이션\n",
    "###############################################################################\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🎓 TRAINING BATCH SIMULATION - 실제 학습 데이터 확인\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 실제 데이터 로드 (소량)\n",
    "print(\"\\n\" + \"─\"*80)\n",
    "print(\"📁 Loading Real Data (Source + Target)\")\n",
    "print(\"─\"*80)\n",
    "train_squad_path = '../../../data/squad/train-v1.1_classified_qtype_prob.jsonl'\n",
    "train_cnn_path = '../../../data/cnn/cnn_train_classified_qtype_prob.jsonl'\n",
    "\n",
    "# Source features 로드\n",
    "source_features, _ = read_features_and_examples(\n",
    "    args, \n",
    "    args.source_train_file, \n",
    "    tokenizer, \n",
    "    logger,\n",
    "    use_simple_feature=False, \n",
    "    read_examples=True, \n",
    "    limit=20  # 20개만 로드\n",
    ")\n",
    "\n",
    "# Target features 로드\n",
    "target_features, target_examples = read_features_and_examples(\n",
    "    args,\n",
    "    args.target_train_file,\n",
    "    tokenizer,\n",
    "    logger,\n",
    "    use_simple_feature=False,\n",
    "    read_examples=True,\n",
    "    limit=10  # 10개만 로드\n",
    ")\n",
    "\n",
    "print(f\"✓ Source features loaded: {len(source_features)}\")\n",
    "print(f\"✓ Target features loaded: {len(target_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "050971a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "📊 Source Q-Type Distribution\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "  • Type 0: 0 samples\n",
      "  • Type 1: 0 samples\n",
      "  • Type 2: 7 samples\n",
      "  • Type 3: 5 samples\n",
      "  • Type 4: 1 samples\n",
      "  • Type 5: 7 samples\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "🎯 Target Q-Type Probability Check\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "✓ Target samples with q_type_prob: 10\n",
      "\n",
      "First 3 target samples:\n",
      "  Sample 0: [0.001, 0.001, 0.171, 0.76, 0.064, 0.002]\n",
      "  Sample 1: [0.001, 0.001, 0.171, 0.76, 0.064, 0.002]\n",
      "  Sample 2: [0.001, 0.001, 0.171, 0.76, 0.064, 0.002]\n"
     ]
    }
   ],
   "source": [
    "# Source q_type 분포 확인\n",
    "print(\"\\n\" + \"─\"*80)\n",
    "print(\"📊 Source Q-Type Distribution\")\n",
    "print(\"─\"*80)\n",
    "\n",
    "source_q_type_dict = {0: [], 1: [], 2: [], 3: [], 4: [], 5: []}\n",
    "for idx, f in enumerate(source_features):\n",
    "    source_q_type_dict[f.q_type].append(idx)\n",
    "\n",
    "for q_type, indices in source_q_type_dict.items():\n",
    "    print(f\"  • Type {q_type}: {len(indices)} samples\")\n",
    "    \n",
    "# Target q_type_prob 확인\n",
    "print(\"\\n\" + \"─\"*80)\n",
    "print(\"🎯 Target Q-Type Probability Check\")\n",
    "print(\"─\"*80)\n",
    "\n",
    "target_q_type_probs = []\n",
    "for f in target_features:\n",
    "    if hasattr(f, 'q_type_prob') and f.q_type_prob is not None:\n",
    "        target_q_type_probs.append(f.q_type_prob)\n",
    "    else:\n",
    "        prob = [0.0] * 6\n",
    "        prob[f.q_type] = 1.0\n",
    "        target_q_type_probs.append(prob)\n",
    "\n",
    "print(f\"✓ Target samples with q_type_prob: {len(target_q_type_probs)}\")\n",
    "print(f\"\\nFirst 3 target samples:\")\n",
    "for i in range(min(3, len(target_q_type_probs))):\n",
    "    print(f\"  Sample {i}: {target_q_type_probs[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d3d4fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "🔄 Batch Creation Simulation\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Target Batch Size: 4\n",
      "Target Batch q_type_probs shape: torch.Size([4, 6])\n",
      "\n",
      "🔗 Source Sampling (Top-3 Matching):\n",
      "\n",
      "  Target 0:\n",
      "    Top-3 types: [3, 2, 4]\n",
      "    Top-3 probs: ['0.760', '0.171', '0.064']\n",
      "    Matched sources:\n",
      "      → Type 3: Source[0]\n",
      "      → Type 2: Source[2]\n",
      "      → Type 4: Source[10]\n",
      "\n",
      "  Target 1:\n",
      "    Top-3 types: [3, 2, 4]\n",
      "    Top-3 probs: ['0.760', '0.171', '0.064']\n",
      "    Matched sources:\n",
      "      → Type 3: Source[0]\n",
      "      → Type 2: Source[2]\n",
      "      → Type 4: Source[10]\n",
      "\n",
      "  Target 2:\n",
      "    Top-3 types: [3, 2, 4]\n",
      "    Top-3 probs: ['0.760', '0.171', '0.064']\n",
      "    Matched sources:\n",
      "      → Type 3: Source[0]\n",
      "      → Type 2: Source[2]\n",
      "      → Type 4: Source[10]\n",
      "\n",
      "  Target 3:\n",
      "    Top-3 types: [3, 2, 4]\n",
      "    Top-3 probs: ['0.760', '0.171', '0.064']\n",
      "    Matched sources:\n",
      "      → Type 3: Source[0]\n",
      "      → Type 2: Source[2]\n",
      "      → Type 4: Source[10]\n",
      "\n",
      "✓ Total source samples matched: 12\n",
      "✓ Expected: 12 (최대)\n",
      "✓ Actual: 12\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "📦 Final Batch Composition\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Target samples: 4\n",
      "Source samples: 12\n",
      "Total batch size: 16\n",
      "Memory ratio: 2.00x (compared to 1:1 matching)\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "📐 Tensor Shapes in Training Loop\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Target tensors:\n",
      "  • input_ids: torch.Size([4, 512])\n",
      "  • q_types: torch.Size([4])\n",
      "  • q_type_probs: torch.Size([4, 6])\n",
      "\n",
      "Source tensors:\n",
      "  • input_ids: torch.Size([12, 512])\n",
      "  • q_types: torch.Size([12])\n",
      "\n",
      "Concatenated tensors (input to model):\n",
      "  • input_ids: torch.Size([16, 512])\n",
      "  • q_types: torch.Size([16])\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "📊 Q-Type Distribution in Batch\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Target batch distribution:\n",
      "  • Type 3: 4 samples\n",
      "\n",
      "Source batch distribution:\n",
      "  • Type 2: 4 samples\n",
      "  • Type 3: 4 samples\n",
      "  • Type 4: 4 samples\n",
      "\n",
      "Combined batch distribution:\n",
      "  • Type 2: 4 samples\n",
      "  • Type 3: 8 samples\n",
      "  • Type 4: 4 samples\n",
      "\n",
      "================================================================================\n",
      "✅ TRAINING BATCH SIMULATION COMPLETED\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 배치 생성 시뮬레이션\n",
    "print(\"\\n\" + \"─\"*80)\n",
    "print(\"🔄 Batch Creation Simulation\")\n",
    "print(\"─\"*80)\n",
    "\n",
    "# Target 배치 생성 (4개 샘플)\n",
    "batch_size = 4\n",
    "target_batch_probs = torch.tensor(target_q_type_probs[:batch_size], dtype=torch.float)\n",
    "\n",
    "print(f\"Target Batch Size: {batch_size}\")\n",
    "print(f\"Target Batch q_type_probs shape: {target_batch_probs.shape}\")\n",
    "\n",
    "# Source 배치 샘플링 시뮬레이션\n",
    "print(\"\\n🔗 Source Sampling (Top-3 Matching):\")\n",
    "\n",
    "source_indices = []\n",
    "for i, q_type_prob in enumerate(target_batch_probs):\n",
    "    top3_indices = torch.topk(q_type_prob, k=3).indices.tolist()\n",
    "    top3_values = torch.topk(q_type_prob, k=3).values.tolist()\n",
    "    \n",
    "    print(f\"\\n  Target {i}:\")\n",
    "    print(f\"    Top-3 types: {top3_indices}\")\n",
    "    print(f\"    Top-3 probs: {[f'{v:.3f}' for v in top3_values]}\")\n",
    "    print(f\"    Matched sources:\")\n",
    "    \n",
    "    for rank, q_type in enumerate(top3_indices):\n",
    "        if len(source_q_type_dict[q_type]) > 0:\n",
    "            source_idx = source_q_type_dict[q_type][rank % len(source_q_type_dict[q_type])]\n",
    "            source_indices.append(source_idx)\n",
    "            print(f\"      → Type {q_type}: Source[{source_idx}]\")\n",
    "        else:\n",
    "            print(f\"      → Type {q_type}: ⚠️ No source available (skip)\")\n",
    "\n",
    "print(f\"\\n✓ Total source samples matched: {len(source_indices)}\")\n",
    "print(f\"✓ Expected: {batch_size * 3} (최대)\")\n",
    "print(f\"✓ Actual: {len(source_indices)}\")\n",
    "\n",
    "# 최종 배치 크기\n",
    "print(\"\\n\" + \"─\"*80)\n",
    "print(\"📦 Final Batch Composition\")\n",
    "print(\"─\"*80)\n",
    "\n",
    "print(f\"Target samples: {batch_size}\")\n",
    "print(f\"Source samples: {len(source_indices)}\")\n",
    "print(f\"Total batch size: {batch_size + len(source_indices)}\")\n",
    "print(f\"Memory ratio: {(batch_size + len(source_indices)) / (batch_size * 2):.2f}x (compared to 1:1 matching)\")\n",
    "\n",
    "# 텐서 형태 확인\n",
    "print(\"\\n\" + \"─\"*80)\n",
    "print(\"📐 Tensor Shapes in Training Loop\")\n",
    "print(\"─\"*80)\n",
    "\n",
    "# Target 텐서\n",
    "target_input_ids = torch.tensor([f.input_ids for f in target_features[:batch_size]], dtype=torch.long)\n",
    "target_q_types = torch.tensor([f.q_type for f in target_features[:batch_size]], dtype=torch.long)\n",
    "\n",
    "print(f\"Target tensors:\")\n",
    "print(f\"  • input_ids: {target_input_ids.shape}\")\n",
    "print(f\"  • q_types: {target_q_types.shape}\")\n",
    "print(f\"  • q_type_probs: {target_batch_probs.shape}\")\n",
    "\n",
    "# Source 텐서 (시뮬레이션)\n",
    "source_input_ids = torch.tensor([source_features[idx].input_ids for idx in source_indices], dtype=torch.long)\n",
    "source_q_types = torch.tensor([source_features[idx].q_type for idx in source_indices], dtype=torch.long)\n",
    "\n",
    "print(f\"\\nSource tensors:\")\n",
    "print(f\"  • input_ids: {source_input_ids.shape}\")\n",
    "print(f\"  • q_types: {source_q_types.shape}\")\n",
    "\n",
    "# Concatenated 텐서\n",
    "concat_input_ids = torch.cat([target_input_ids, source_input_ids], dim=0)\n",
    "concat_q_types = torch.cat([target_q_types, source_q_types], dim=0)\n",
    "\n",
    "print(f\"\\nConcatenated tensors (input to model):\")\n",
    "print(f\"  • input_ids: {concat_input_ids.shape}\")\n",
    "print(f\"  • q_types: {concat_q_types.shape}\")\n",
    "\n",
    "# Q-type 분포 확인\n",
    "print(\"\\n\" + \"─\"*80)\n",
    "print(\"📊 Q-Type Distribution in Batch\")\n",
    "print(\"─\"*80)\n",
    "\n",
    "from collections import Counter\n",
    "target_type_dist = Counter(target_q_types.tolist())\n",
    "source_type_dist = Counter(source_q_types.tolist())\n",
    "concat_type_dist = Counter(concat_q_types.tolist())\n",
    "\n",
    "print(\"Target batch distribution:\")\n",
    "for q_type in sorted(target_type_dist.keys()):\n",
    "    print(f\"  • Type {q_type}: {target_type_dist[q_type]} samples\")\n",
    "\n",
    "print(\"\\nSource batch distribution:\")\n",
    "for q_type in sorted(source_type_dist.keys()):\n",
    "    print(f\"  • Type {q_type}: {source_type_dist[q_type]} samples\")\n",
    "\n",
    "print(\"\\nCombined batch distribution:\")\n",
    "for q_type in sorted(concat_type_dist.keys()):\n",
    "    print(f\"  • Type {q_type}: {concat_type_dist[q_type]} samples\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✅ TRAINING BATCH SIMULATION COMPLETED\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "runtime_debug_v3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "🔥 ADDING RUNTIME LOGGING TO TRAINING LOOP\n",
      "================================================================================\n",
      "✅ Runtime logging function defined.\n",
      "\n",
      "To use it, run:\n",
      "  globals()['comb_adversarial_training_stage'] = comb_adversarial_training_stage_with_logging\n",
      "  adaptation_stage(args, tokenizer, device, logger, debug=True)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def comb_adversarial_training_stage_with_logging(args, target_train_features, target_train_examples, source_train_features,\n",
    "            eval_features, eval_examples, removed_feature_index, new_generated_train_features, model, epoch,\n",
    "            device, best_acc, best_f1, logger):\n",
    "    \"\"\"\n",
    "    디버깅 추가 : 실제 학습 루프에서 배치 크기 로깅\n",
    "    \"\"\"\n",
    "    def sample_source_batch_top3(source_data, source_q_type_dict, sample_pointer, q_type_probs):\n",
    "        \"\"\"\n",
    "        q_type_probs 기반 상위 3개 타입에서 소스 샘플링 (로깅 추가)\n",
    "        \"\"\"\n",
    "        output_idx = []\n",
    "        batch_top3_stats = []  # 각 샘플의 top-3 정보 저장\n",
    "\n",
    "        for batch_idx, q_type_prob in enumerate(q_type_probs):\n",
    "            top3_indices = torch.topk(q_type_prob, k=3).indices.tolist()\n",
    "            top3_values = torch.topk(q_type_prob, k=3).values.tolist()\n",
    "            \n",
    "            batch_top3_stats.append({\n",
    "                \"batch_idx\": batch_idx,\n",
    "                \"top3_types\": top3_indices,\n",
    "                \"top3_probs\": top3_values,\n",
    "                \"matched_sources\": []\n",
    "            })\n",
    "\n",
    "            for q_type in top3_indices:\n",
    "                if len(source_q_type_dict[q_type]) == 0:\n",
    "                    batch_top3_stats[-1][\"matched_sources\"].append(None)\n",
    "                    continue\n",
    "\n",
    "                next_q_idx = sample_pointer[q_type] % len(source_q_type_dict[q_type])\n",
    "                source_idx = source_q_type_dict[q_type][next_q_idx]\n",
    "                output_idx.append(source_idx)\n",
    "                batch_top3_stats[-1][\"matched_sources\"].append(source_idx)\n",
    "                sample_pointer[q_type] += 1\n",
    "\n",
    "        input_ids_source, input_masks_source, segment_ids_source, start_positions_source, end_positions_source, \\\n",
    "            q_types_source = [], [], [], [], [], []\n",
    "        for idx in output_idx:\n",
    "            input_ids_source.append(source_data[idx][0].unsqueeze(0))\n",
    "            input_masks_source.append(source_data[idx][1].unsqueeze(0))\n",
    "            segment_ids_source.append(source_data[idx][2].unsqueeze(0))\n",
    "            start_positions_source.append(source_data[idx][3].unsqueeze(0))\n",
    "            end_positions_source.append(source_data[idx][4].unsqueeze(0))\n",
    "            q_types_source.append(source_data[idx][5].unsqueeze(0))\n",
    "\n",
    "        return (torch.vstack(input_ids_source), torch.vstack(input_masks_source), torch.vstack(segment_ids_source), \\\n",
    "            torch.cat(start_positions_source, -1), torch.cat(end_positions_source, -1), torch.cat(q_types_source, -1),\n",
    "            batch_top3_stats)  # 통계 정보도 반환\n",
    "\n",
    "    # Generate self-training samples\n",
    "    new_generated_train_features, removed_feature_index = generate_self_training_samples(args, target_train_examples,\n",
    "        target_train_features, device, model, removed_feature_index, new_generated_train_features, args.generate_prob_th,\n",
    "        logger)\n",
    "    if new_generated_train_features is None:\n",
    "        sys.exit()\n",
    "    \n",
    "    logger.info(\"\\n\")\n",
    "    logger.info(\"====================  Start Adversarial Training Stage  ====================\")\n",
    "    \n",
    "    # q_type_prob 추출\n",
    "    all_q_type_probs = []\n",
    "    fallback_count = 0\n",
    "    for f in new_generated_train_features:\n",
    "        if hasattr(f, \"q_type_prob\") and f.q_type_prob is not None:\n",
    "            all_q_type_probs.append(f.q_type_prob)\n",
    "        else:\n",
    "            prob = [0.0] * 6\n",
    "            prob[f.q_type] = 1.0\n",
    "            all_q_type_probs.append(prob)\n",
    "            fallback_count += 1\n",
    "    \n",
    "    # 🔥 로깅: Fallback 사용률\n",
    "    print(f\"\\n🔥 RUNTIME LOG - q_type_prob Status:\")\n",
    "    print(f\"  Total target features: {len(new_generated_train_features)}\")\n",
    "    print(f\"  Fallback (one-hot) count: {fallback_count}\")\n",
    "    print(f\"  Proper q_type_prob count: {len(new_generated_train_features) - fallback_count}\")\n",
    "    print(f\"  Fallback rate: {fallback_count / len(new_generated_train_features) * 100:.1f}%\\n\")\n",
    "    \n",
    "    all_input_ids = torch.tensor([f.input_ids for f in new_generated_train_features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in new_generated_train_features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in new_generated_train_features], dtype=torch.long)\n",
    "    all_start_positions = torch.tensor([f.start_position for f in new_generated_train_features], dtype=torch.long)\n",
    "    all_end_positions = torch.tensor([f.end_position for f in new_generated_train_features], dtype=torch.long)\n",
    "    all_q_types = torch.tensor([f.q_type for f in new_generated_train_features], dtype=torch.long)\n",
    "    all_q_type_probs = torch.tensor(all_q_type_probs, dtype=torch.float)\n",
    "    \n",
    "    train_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids,\n",
    "        all_start_positions, all_end_positions, all_q_types, all_q_type_probs)\n",
    "    \n",
    "    # Source data 준비\n",
    "    source_input_ids = torch.tensor([f.input_ids for f in source_train_features], dtype=torch.long)\n",
    "    source_input_mask = torch.tensor([f.input_mask for f in source_train_features], dtype=torch.long)\n",
    "    source_segment_ids = torch.tensor([f.segment_ids for f in source_train_features], dtype=torch.long)\n",
    "    source_start_positions = torch.tensor([f.start_position for f in source_train_features], dtype=torch.long)\n",
    "    source_end_positions = torch.tensor([f.end_position for f in source_train_features], dtype=torch.long)\n",
    "    source_q_types = []\n",
    "    source_q_type_dict = {0: [], 1: [], 2: [], 3: [], 4: [], 5: []}\n",
    "    for idx, f in enumerate(source_train_features):\n",
    "        source_q_types.append(f.q_type)\n",
    "        source_q_type_dict[f.q_type].append(idx)\n",
    "    source_q_types = torch.tensor(source_q_types, dtype=torch.long)\n",
    "    for key in source_q_type_dict.keys():\n",
    "        random.shuffle(source_q_type_dict[key])\n",
    "    sample_pointer = [0] * 6\n",
    "    source_data = TensorDataset(source_input_ids, source_input_mask, source_segment_ids, source_start_positions, \n",
    "        source_end_positions, source_q_types)\n",
    "\n",
    "    # 🔥 로깅: Source 분포\n",
    "    print(f\"🔥 RUNTIME LOG - Source Q-Type Distribution:\")\n",
    "    for q_type in sorted(source_q_type_dict.keys()):\n",
    "        print(f\"  Type {q_type}: {len(source_q_type_dict[q_type])} samples\")\n",
    "    print()\n",
    "\n",
    "    train_sampler = BERTRandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=args.train_batch_size)\n",
    "    \n",
    "    data_len = len(new_generated_train_features)\n",
    "    logger.info(\"  Num split examples = %d\", data_len)\n",
    "    logger.info(\"  Batch size = %d\", args.train_batch_size)\n",
    "    num_train_steps = math.ceil(data_len / args.train_batch_size / args.gradient_accumulation_steps)\n",
    "    if num_train_steps == 0 and data_len > 0:\n",
    "        num_train_steps = 1\n",
    "    t_total = num_train_steps\n",
    "    logger.info(\"  Num steps = %d\", num_train_steps)\n",
    "\n",
    "    optimizer_grouped_parameters = get_bert_model_parameters(model)\n",
    "    optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "            lr=args.adapt_learning_rate,\n",
    "            warmup=args.warmup_proportion,\n",
    "            t_total=t_total)\n",
    "    global_step = 0\n",
    "\n",
    "    # 🔥 배치별 로깅 (첫 3개 배치만)\n",
    "    print(f\"\\n🔥 RUNTIME LOG - Training Loop (First 3 Batches):\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\")):\n",
    "        model.train()\n",
    "        \n",
    "        # 🔥 로깅: 배치 정보 (첫 3개만)\n",
    "        if step < 3:\n",
    "            print(f\"\\n--- Batch {step} ---\")\n",
    "            print(f\"Target batch size: {batch[0].shape[0]}\")\n",
    "            print(f\"Sample q_type_prob[0]: {batch[-1][0].tolist()}\")\n",
    "            top3 = torch.topk(batch[-1][0], k=3)\n",
    "            print(f\"Top-3 types: {top3.indices.tolist()}, probs: {[f'{v:.3f}' for v in top3.values.tolist()]}\")\n",
    "        \n",
    "        # 소스 배치 샘플링\n",
    "        result = sample_source_batch_top3(source_data, source_q_type_dict, sample_pointer, batch[-1])\n",
    "        batch_source = result[:6]  # 텐서들만\n",
    "        batch_stats = result[6]     # 통계 정보\n",
    "        \n",
    "        # 🔥 로깅: 소스 배치 크기 (첫 3개만)\n",
    "        if step < 3:\n",
    "            print(f\"Source batch size: {batch_source[0].shape[0]}\")\n",
    "            print(f\"Source sampling ratio: {batch_source[0].shape[0] / batch[0].shape[0]:.2f}x\")\n",
    "            print(f\"First target sample matched to sources:\")\n",
    "            first_stats = batch_stats[0]\n",
    "            for i, (typ, prob, src) in enumerate(zip(first_stats[\"top3_types\"], \n",
    "                                                       first_stats[\"top3_probs\"],\n",
    "                                                       first_stats[\"matched_sources\"])):\n",
    "                if src is not None:\n",
    "                    print(f\"  Rank {i+1}: Type {typ} (prob={prob:.3f}) → Source[{src}]\")\n",
    "                else:\n",
    "                    print(f\"  Rank {i+1}: Type {typ} (prob={prob:.3f}) → ⚠️  No source\")\n",
    "        \n",
    "        batch = tuple(t.to(device) for t in batch[:-1])\n",
    "        batch_source = tuple(t.to(device) for t in batch_source)\n",
    "        input_ids, input_masks, segment_ids, start_positions, end_positions, q_types = batch\n",
    "        input_ids_source, input_masks_source, segment_ids_source, start_positions_source, end_positions_source, q_types_source = batch_source\n",
    "        \n",
    "        # 타겟 + 소스 concat\n",
    "        input_ids = torch.cat((input_ids, input_ids_source), 0)\n",
    "        input_masks = torch.cat((input_masks, input_masks_source), 0)\n",
    "        segment_ids = torch.cat((segment_ids, segment_ids_source), 0)\n",
    "        start_positions = torch.cat((start_positions, start_positions_source), 0)\n",
    "        end_positions = torch.cat((end_positions, end_positions_source), 0)\n",
    "        q_types = torch.cat((q_types, q_types_source), 0)\n",
    "        \n",
    "        # 🔥 로깅: 최종 배치 크기 (첫 3개만)\n",
    "        if step < 3:\n",
    "            print(f\"Combined batch size: {input_ids.shape[0]}\")\n",
    "            from collections import Counter\n",
    "            q_type_dist = Counter(q_types.cpu().tolist())\n",
    "            print(f\"Q-type distribution: {dict(sorted(q_type_dist.items()))}\")\n",
    "        \n",
    "        # QC4QA loss 계산\n",
    "        loss = model.forward_ours(input_ids, segment_ids, input_masks, start_positions,\n",
    "                end_positions, q_types, lambda_c=args.lambda_c)\n",
    "        if args.gradient_accumulation_steps > 1:\n",
    "            loss = loss / args.gradient_accumulation_steps\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        if (step + 1) % args.gradient_accumulation_steps == 0:\n",
    "            lr_this_step = args.adapt_learning_rate * warmup_linear(global_step / t_total, args.warmup_proportion)\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group[\"lr\"] = lr_this_step\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"🔥 TRAINING LOOP COMPLETED\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "        \n",
    "    final_acc, final_f1 = None, None\n",
    "    if epoch == args.num_train_epochs - 1:\n",
    "        final_acc, final_f1 = evaluation_stage(args, eval_examples, eval_features, device, model,\n",
    "            global_step=global_step, best_acc=None, best_f1=None, logger=logger)\n",
    "        best_acc, best_f1 = compare_performance(args, best_acc, best_f1, final_acc, final_f1, model, logger)\n",
    "    else:\n",
    "        best_acc, best_f1 = evaluation_stage(args, eval_examples, eval_features, device, model,\n",
    "            global_step=global_step, best_acc=best_acc, best_f1=best_f1, logger=logger)\n",
    "    return best_acc, best_f1, final_acc, final_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f0c3940",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2255560/1948527526.py:360: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_state_dict = torch.load(input_model_file)\n",
      "11/04/2025 15:10:04 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/gayeon39/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "11/04/2025 15:10:04 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /home/gayeon39/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpt_69n218\n",
      "11/04/2025 15:10:06 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_seq_length\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_BN\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "11/04/2025 15:10:08 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/gayeon39/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "11/04/2025 15:10:08 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /home/gayeon39/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpag6oswki\n",
      "11/04/2025 15:10:10 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_seq_length\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_BN\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "11/04/2025 15:10:12 - INFO - utils.ConfigLogger -   ***** Reading Target Unlabeled Training Samples *****\n",
      "11/04/2025 15:11:48 - INFO - utils.ConfigLogger -   ***** Reading Source Training Samples *****\n",
      "11/04/2025 15:11:56 - INFO - utils.ConfigLogger -   ***** Reading Evaluation Samples *****\n",
      "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]11/04/2025 15:12:00 - INFO - utils.ConfigLogger -   \n",
      "\n",
      "11/04/2025 15:12:00 - INFO - utils.ConfigLogger -    ###########  Start Training Epoch 1  ###########\n",
      "11/04/2025 15:12:00 - INFO - utils.ConfigLogger -   \n",
      "\n",
      "11/04/2025 15:12:00 - INFO - utils.ConfigLogger -   ***** Generating training data for this epoch *****\n",
      "11/04/2025 15:12:00 - INFO - utils.ConfigLogger -   ***** Running Evaluation Stage *****\n",
      "11/04/2025 15:12:00 - INFO - utils.ConfigLogger -     Num orig examples = 50\n",
      "11/04/2025 15:12:00 - INFO - utils.ConfigLogger -     Num split examples = 50\n",
      "11/04/2025 15:12:00 - INFO - utils.ConfigLogger -     Batch size = 12\n",
      "11/04/2025 15:12:00 - INFO - utils.ConfigLogger -   Start evaluating\n",
      "Evaluating: 100%|██████████| 5/5 [00:00<00:00, 20.15it/s]\n",
      "11/04/2025 15:12:01 - INFO - utils.ConfigLogger -   Writing predictions to: model/squad2target/predictions_2025-11-04 15:12:01.json\n",
      "11/04/2025 15:12:01 - INFO - utils.ConfigLogger -   Writing nbest to: model/squad2target/nbest_predictions_2025-11-04 15:12:01.json\n",
      "11/04/2025 15:12:01 - INFO - utils.ConfigLogger -   \n",
      "\n",
      "11/04/2025 15:12:01 - INFO - utils.ConfigLogger -   ====================  Start Adversarial Training Stage  ====================\n",
      "11/04/2025 15:12:01 - INFO - utils.ConfigLogger -     Num split examples = 2\n",
      "11/04/2025 15:12:01 - INFO - utils.ConfigLogger -     Batch size = 12\n",
      "11/04/2025 15:12:01 - INFO - utils.ConfigLogger -     Num steps = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔥 RUNTIME LOG - q_type_prob Status:\n",
      "  Total target features: 2\n",
      "  Fallback (one-hot) count: 0\n",
      "  Proper q_type_prob count: 2\n",
      "  Fallback rate: 0.0%\n",
      "\n",
      "🔥 RUNTIME LOG - Source Q-Type Distribution:\n",
      "  Type 0: 0 samples\n",
      "  Type 1: 0 samples\n",
      "  Type 2: 11 samples\n",
      "  Type 3: 18 samples\n",
      "  Type 4: 3 samples\n",
      "  Type 5: 18 samples\n",
      "\n",
      "\n",
      "🔥 RUNTIME LOG - Training Loop (First 3 Batches):\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1/1 [00:00<00:00,  6.67it/s]\n",
      "11/04/2025 15:12:01 - INFO - utils.ConfigLogger -   ***** Running Predictions *****\n",
      "11/04/2025 15:12:01 - INFO - utils.ConfigLogger -     Num orig examples = 50\n",
      "11/04/2025 15:12:01 - INFO - utils.ConfigLogger -     Num split examples = 50\n",
      "11/04/2025 15:12:01 - INFO - utils.ConfigLogger -     Batch size = 12\n",
      "11/04/2025 15:12:01 - INFO - utils.ConfigLogger -   Start evaluating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Batch 0 ---\n",
      "Target batch size: 2\n",
      "Sample q_type_prob[0]: [0.0010000000474974513, 0.010999999940395355, 0.3059999942779541, 0.6769999861717224, 0.003000000026077032, 0.0010000000474974513]\n",
      "Top-3 types: [3, 2, 1], probs: ['0.677', '0.306', '0.011']\n",
      "Source batch size: 5\n",
      "Source sampling ratio: 2.50x\n",
      "First target sample matched to sources:\n",
      "  Rank 1: Type 3 (prob=0.677) → Source[46]\n",
      "  Rank 2: Type 2 (prob=0.306) → Source[14]\n",
      "  Rank 3: Type 1 (prob=0.011) → ⚠️  No source\n",
      "Combined batch size: 7\n",
      "Q-type distribution: {2: 3, 3: 3, 5: 1}\n",
      "\n",
      "================================================================================\n",
      "🔥 TRAINING LOOP COMPLETED\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5/5 [00:00<00:00, 20.15it/s]\n",
      "11/04/2025 15:12:01 - INFO - utils.ConfigLogger -   Writing predictions to: model/squad2target/predictions_1.json\n",
      "11/04/2025 15:12:01 - INFO - utils.ConfigLogger -   Writing nbest to: model/squad2target/nbest_predictions_1.json\n",
      "/tmp/ipykernel_2255560/1948527526.py:27: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  logger.warn(message)\n",
      "11/04/2025 15:12:01 - WARNING - utils.ConfigLogger -   Unanswered question validation/fd0dc9fcbb41450c388f6d3f90153da19f53e050 will receive score 0.\n",
      "11/04/2025 15:12:01 - WARNING - utils.ConfigLogger -   Unanswered question validation/7ad6bf269adef016560ea4d857150771842e0d23 will receive score 0.\n",
      "11/04/2025 15:12:01 - WARNING - utils.ConfigLogger -   Unanswered question validation/de308d2ec5722143d8156c3fe2192a2884ca86f9 will receive score 0.\n",
      "11/04/2025 15:12:01 - WARNING - utils.ConfigLogger -   Unanswered question validation/c1875aa38c8ac079d128a4ddf92259479955abcc will receive score 0.\n",
      "11/04/2025 15:12:01 - WARNING - utils.ConfigLogger -   Unanswered question validation/1993fab60212e6627aea8ae78a33d9a81ab0e27c will receive score 0.\n",
      "11/04/2025 15:12:01 - WARNING - utils.ConfigLogger -   Unanswered question validation/6253f6fb35a222d648643465c6b9399dcdbe13a1 will receive score 0.\n",
      "11/04/2025 15:12:01 - WARNING - utils.ConfigLogger -   Unanswered question validation/1714ebeffea86e2788bfb7653ada360f61af2ff7 will receive score 0.\n",
      "11/04/2025 15:12:01 - WARNING - utils.ConfigLogger -   Unanswered question validation/656544054260257c0fa082e68c795a2152a49fc8 will receive score 0.\n",
      "11/04/2025 15:12:01 - WARNING - utils.ConfigLogger -   Unanswered question validation/d4c01b8a4fb735a1734d9c8fadddb1028b751b34 will receive score 0.\n",
      "11/04/2025 15:12:01 - WARNING - utils.ConfigLogger -   Unanswered question validation/6c22ba2fa5c59946e284a888fcc7c74fcac38e65 will receive score 0.\n",
      "11/04/2025 15:12:01 - WARNING - utils.ConfigLogger -   Unanswered question validation/bf9c95d342a51ffe32440116c9d5b1b7dfa96531 will receive score 0.\n",
      "11/04/2025 15:12:01 - WARNING - utils.ConfigLogger -   Unanswered question validation/d787ad7de05d3f63168579a29ded97b35bffd1b6 will receive score 0.\n",
      "11/04/2025 15:12:01 - WARNING - utils.ConfigLogger -   Unanswered question validation/c9d2e46b29b21b8b598b4b80803c1af651e7f1d2 will receive score 0.\n",
      "11/04/2025 15:12:01 - WARNING - utils.ConfigLogger -   Unanswered question validation/0957a9a140132d7f2ba596b62628fb98e5470a80 will receive score 0.\n",
      "11/04/2025 15:12:01 - WARNING - utils.ConfigLogger -   Unanswered question validation/033daf6ae73daf122e5982c6422b284d69b42764 will receive score 0.\n",
      "11/04/2025 15:12:01 - WARNING - utils.ConfigLogger -   Unanswered question validation/b3eff20f10ae157008ccf8962ed340feee33d31b will receive score 0.\n",
      "11/04/2025 15:12:01 - WARNING - utils.ConfigLogger -   Unanswered question validation/b1096769370114b16f44468ecb9aa2f9addaec3c will receive score 0.\n",
      "11/04/2025 15:12:01 - WARNING - utils.ConfigLogger -   Unanswered question validation/cbd9f3fae1ca0c7eabf3d38b3311c9998995d13e will receive score 0.\n",
      "11/04/2025 15:12:01 - WARNING - utils.ConfigLogger -   Unanswered question validation/01f460fa9d4289827ece2af1344485728e414981 will receive score 0.\n",
      "11/04/2025 15:12:01 - WARNING - utils.ConfigLogger -   Unanswered question validation/78c8d1e634e80e210626dc12671d13b62d10bc99 will receive score 0.\n",
      "11/04/2025 15:12:01 - WARNING - utils.ConfigLogger -   Unanswered question validation/5ec7c78400e01b1dcf2bd7d2cf9d6610ff59af12 will receive score 0.\n",
      "11/04/2025 15:12:01 - INFO - utils.ConfigLogger -   Current EM is 13.79310, F1 is 24.43514\n",
      "11/04/2025 15:12:01 - INFO - utils.ConfigLogger -   Current model BEATS previous best model, previous best is EM = 0.00000, F1 = 0.00000\n",
      "11/04/2025 15:12:01 - INFO - utils.ConfigLogger -   Current best model has been saved!\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -   \n",
      "\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -    ###########  End Training Epoch 1  ###########\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -   \n",
      "\n",
      "Epoch:  50%|█████     | 1/2 [00:01<00:01,  1.61s/it]11/04/2025 15:12:02 - INFO - utils.ConfigLogger -   \n",
      "\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -    ###########  Start Training Epoch 2  ###########\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -   \n",
      "\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -   ***** Generating training data for this epoch *****\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -   ***** Running Evaluation Stage *****\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -     Num orig examples = 50\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -     Num split examples = 50\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -     Batch size = 12\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -   Start evaluating\n",
      "Evaluating: 100%|██████████| 5/5 [00:00<00:00, 20.27it/s]\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -   Writing predictions to: model/squad2target/predictions_2025-11-04 15:12:02.json\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -   Writing nbest to: model/squad2target/nbest_predictions_2025-11-04 15:12:02.json\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -   \n",
      "\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -   ====================  Start Adversarial Training Stage  ====================\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -     Num split examples = 2\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -     Batch size = 12\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -     Num steps = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔥 RUNTIME LOG - q_type_prob Status:\n",
      "  Total target features: 2\n",
      "  Fallback (one-hot) count: 0\n",
      "  Proper q_type_prob count: 2\n",
      "  Fallback rate: 0.0%\n",
      "\n",
      "🔥 RUNTIME LOG - Source Q-Type Distribution:\n",
      "  Type 0: 0 samples\n",
      "  Type 1: 0 samples\n",
      "  Type 2: 11 samples\n",
      "  Type 3: 18 samples\n",
      "  Type 4: 3 samples\n",
      "  Type 5: 18 samples\n",
      "\n",
      "\n",
      "🔥 RUNTIME LOG - Training Loop (First 3 Batches):\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1/1 [00:00<00:00,  6.35it/s]\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -   ***** Running Predictions *****\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -     Num orig examples = 50\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -     Num split examples = 50\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -     Batch size = 12\n",
      "11/04/2025 15:12:02 - INFO - utils.ConfigLogger -   Start evaluating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Batch 0 ---\n",
      "Target batch size: 2\n",
      "Sample q_type_prob[0]: [0.0010000000474974513, 0.010999999940395355, 0.3059999942779541, 0.6769999861717224, 0.003000000026077032, 0.0010000000474974513]\n",
      "Top-3 types: [3, 2, 1], probs: ['0.677', '0.306', '0.011']\n",
      "Source batch size: 5\n",
      "Source sampling ratio: 2.50x\n",
      "First target sample matched to sources:\n",
      "  Rank 1: Type 3 (prob=0.677) → Source[35]\n",
      "  Rank 2: Type 2 (prob=0.306) → Source[2]\n",
      "  Rank 3: Type 1 (prob=0.011) → ⚠️  No source\n",
      "Combined batch size: 7\n",
      "Q-type distribution: {2: 3, 3: 3, 5: 1}\n",
      "\n",
      "================================================================================\n",
      "🔥 TRAINING LOOP COMPLETED\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5/5 [00:00<00:00, 20.11it/s]\n",
      "11/04/2025 15:12:03 - INFO - utils.ConfigLogger -   Writing predictions to: model/squad2target/predictions_1.json\n",
      "11/04/2025 15:12:03 - INFO - utils.ConfigLogger -   Writing nbest to: model/squad2target/nbest_predictions_1.json\n",
      "11/04/2025 15:12:03 - WARNING - utils.ConfigLogger -   Unanswered question validation/fd0dc9fcbb41450c388f6d3f90153da19f53e050 will receive score 0.\n",
      "11/04/2025 15:12:03 - WARNING - utils.ConfigLogger -   Unanswered question validation/7ad6bf269adef016560ea4d857150771842e0d23 will receive score 0.\n",
      "11/04/2025 15:12:03 - WARNING - utils.ConfigLogger -   Unanswered question validation/de308d2ec5722143d8156c3fe2192a2884ca86f9 will receive score 0.\n",
      "11/04/2025 15:12:03 - WARNING - utils.ConfigLogger -   Unanswered question validation/c1875aa38c8ac079d128a4ddf92259479955abcc will receive score 0.\n",
      "11/04/2025 15:12:03 - WARNING - utils.ConfigLogger -   Unanswered question validation/1993fab60212e6627aea8ae78a33d9a81ab0e27c will receive score 0.\n",
      "11/04/2025 15:12:03 - WARNING - utils.ConfigLogger -   Unanswered question validation/6253f6fb35a222d648643465c6b9399dcdbe13a1 will receive score 0.\n",
      "11/04/2025 15:12:03 - WARNING - utils.ConfigLogger -   Unanswered question validation/1714ebeffea86e2788bfb7653ada360f61af2ff7 will receive score 0.\n",
      "11/04/2025 15:12:03 - WARNING - utils.ConfigLogger -   Unanswered question validation/656544054260257c0fa082e68c795a2152a49fc8 will receive score 0.\n",
      "11/04/2025 15:12:03 - WARNING - utils.ConfigLogger -   Unanswered question validation/d4c01b8a4fb735a1734d9c8fadddb1028b751b34 will receive score 0.\n",
      "11/04/2025 15:12:03 - WARNING - utils.ConfigLogger -   Unanswered question validation/6c22ba2fa5c59946e284a888fcc7c74fcac38e65 will receive score 0.\n",
      "11/04/2025 15:12:03 - WARNING - utils.ConfigLogger -   Unanswered question validation/bf9c95d342a51ffe32440116c9d5b1b7dfa96531 will receive score 0.\n",
      "11/04/2025 15:12:03 - WARNING - utils.ConfigLogger -   Unanswered question validation/d787ad7de05d3f63168579a29ded97b35bffd1b6 will receive score 0.\n",
      "11/04/2025 15:12:03 - WARNING - utils.ConfigLogger -   Unanswered question validation/c9d2e46b29b21b8b598b4b80803c1af651e7f1d2 will receive score 0.\n",
      "11/04/2025 15:12:03 - WARNING - utils.ConfigLogger -   Unanswered question validation/0957a9a140132d7f2ba596b62628fb98e5470a80 will receive score 0.\n",
      "11/04/2025 15:12:03 - WARNING - utils.ConfigLogger -   Unanswered question validation/033daf6ae73daf122e5982c6422b284d69b42764 will receive score 0.\n",
      "11/04/2025 15:12:03 - WARNING - utils.ConfigLogger -   Unanswered question validation/b3eff20f10ae157008ccf8962ed340feee33d31b will receive score 0.\n",
      "11/04/2025 15:12:03 - WARNING - utils.ConfigLogger -   Unanswered question validation/b1096769370114b16f44468ecb9aa2f9addaec3c will receive score 0.\n",
      "11/04/2025 15:12:03 - WARNING - utils.ConfigLogger -   Unanswered question validation/cbd9f3fae1ca0c7eabf3d38b3311c9998995d13e will receive score 0.\n",
      "11/04/2025 15:12:03 - WARNING - utils.ConfigLogger -   Unanswered question validation/01f460fa9d4289827ece2af1344485728e414981 will receive score 0.\n",
      "11/04/2025 15:12:03 - WARNING - utils.ConfigLogger -   Unanswered question validation/78c8d1e634e80e210626dc12671d13b62d10bc99 will receive score 0.\n",
      "11/04/2025 15:12:03 - WARNING - utils.ConfigLogger -   Unanswered question validation/5ec7c78400e01b1dcf2bd7d2cf9d6610ff59af12 will receive score 0.\n",
      "11/04/2025 15:12:03 - INFO - utils.ConfigLogger -   Current EM is 13.79310, F1 is 24.43514\n",
      "11/04/2025 15:12:03 - INFO - utils.ConfigLogger -   Current model CANNOT beat previous best model, previous best is EM = 13.79310, F1 = 24.43514\n",
      "11/04/2025 15:12:03 - INFO - utils.ConfigLogger -   \n",
      "\n",
      "11/04/2025 15:12:03 - INFO - utils.ConfigLogger -    ###########  End Training Epoch 2  ###########\n",
      "11/04/2025 15:12:03 - INFO - utils.ConfigLogger -   \n",
      "\n",
      "Epoch: 100%|██████████| 2/2 [00:02<00:00,  1.22s/it]\n",
      "11/04/2025 15:12:04 - INFO - utils.ConfigLogger -   The final model has been save\n",
      "11/04/2025 15:12:04 - INFO - utils.ConfigLogger -   *** The Training Stage is Ended ***\n",
      "11/04/2025 15:12:04 - INFO - utils.ConfigLogger -   \n",
      "\n",
      "Best EM is 13.79310. Best F1 is 24.43514\n",
      "11/04/2025 15:12:04 - INFO - utils.ConfigLogger -   \n",
      "\n",
      "Final EM is 13.79310. Best F1 is 24.43514\n"
     ]
    }
   ],
   "source": [
    "# 로깅 함수로 덮어쓰기\n",
    "globals()['comb_adversarial_training_stage'] = comb_adversarial_training_stage_with_logging\n",
    "model = prepare_model(args, device)\n",
    "adaptation_stage(args, tokenizer, device, logger, debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "da",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
