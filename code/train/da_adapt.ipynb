{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34c05814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch:  True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "from abc import ABCMeta\n",
    "import argparse\n",
    "import datetime \n",
    "import collections\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import sys\n",
    "import io\n",
    "from tqdm import tqdm, trange\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, WeightedRandomSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "from pytorch_pretrained_bert.modeling import BertForQuestionAnswering\n",
    "from pytorch_pretrained_bert.modeling import BertForQuestionAnsweringQC4QA\n",
    "\n",
    "from pytorch_pretrained_bert.optimization import BertAdam\n",
    "from utils.ConfigLogger import config_logger\n",
    "from utils.evaluate import f1_score, exact_match_score, metric_max_over_ground_truths\n",
    "from utils.BERTRandomSampler import BERTRandomSampler\n",
    "\n",
    "PYTORCH_PRETRAINED_BERT_CACHE = Path(os.getenv('PYTORCH_PRETRAINED_BERT_CACHE',\n",
    "                                               Path.home() / '.pytorch_pretrained_bert'))\n",
    "\n",
    "from da_data_utils import * \n",
    "############################\n",
    "import importlib, types, argparse\n",
    "from utils.ConfigLogger import config_logger\n",
    "print('torch: ',torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b491535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_stage(args, device, tokenizer, logger, debug=False):\n",
    "    # Load a trained model that you have fine-tuned\n",
    "    output_model_file = os.path.join(args.output_dir, args.output_model_file)\n",
    "    model_state_dict = torch.load(output_model_file)\n",
    "    model = BertForQuestionAnswering.from_pretrained(args.bert_model, state_dict=model_state_dict, args=args)\n",
    "    model.to(device)\n",
    "    # Read prediction samples\n",
    "    read_limit = None\n",
    "    if debug:\n",
    "        read_limit = 100 # 샘플 100개만 사용\n",
    "    logger.info(\"***** Reading Prediction Samples *****\")\n",
    "    eval_features, eval_examples = read_features_and_examples(args, args.predict_file, tokenizer, logger,\n",
    "            use_simple_feature=False, read_examples=True, limit=read_limit)\n",
    "    acc, f1 = evaluation_stage(args, eval_examples, eval_features, device, model, logger)\n",
    "    logger.info('***** Prediction Performance *****')\n",
    "    logger.info('EM is %.5f, F1 is %.5f', acc, f1)\n",
    "\n",
    "\n",
    "def evaluate_acc_and_f1(predictions, raw_data, logger, threshold=-1, all_probs=None):\n",
    "    f1 = exact_match = total = 0\n",
    "    eval_threshold = True\n",
    "    if threshold is None or all_probs is None:\n",
    "        eval_threshold = False\n",
    "    for sample in raw_data:\n",
    "        if (sample.qas_id not in predictions) or (eval_threshold and sample.qas_id not in all_probs):\n",
    "            message = 'Unanswered question ' + sample.qas_id + ' will receive score 0.'\n",
    "            logger.warn(message)\n",
    "            continue\n",
    "        if not eval_threshold or (eval_threshold and all_probs[sample.qas_id] >= threshold):\n",
    "            ground_truths = sample.orig_answers\n",
    "            prediction = predictions[sample.qas_id]\n",
    "            exact_match += metric_max_over_ground_truths(\n",
    "                exact_match_score, prediction, ground_truths)\n",
    "            f1 += metric_max_over_ground_truths(\n",
    "                f1_score, prediction, ground_truths)\n",
    "            total += 1\n",
    "\n",
    "    exact_match = 100.0 * exact_match / total\n",
    "    f1 = 100.0 * f1 / total\n",
    "\n",
    "    return exact_match, f1\n",
    "\n",
    "\n",
    "def keep_high_prob_samples(all_probs, all_features, prob_threshold, removed_feature_index, all_indices,\n",
    "        keep_generated=False):\n",
    "    '''\n",
    "    셀프 트레이닝용: 높은 확률의 예측을 pseudo-label로 변환\n",
    "    '''\n",
    "    new_train_features = []\n",
    "    for i, feature in enumerate(all_features):\n",
    "        if keep_generated:\n",
    "            if feature.example_index not in removed_feature_index and all_probs[feature.example_index] > prob_threshold:\n",
    "                feature.start_position, feature.end_position = all_indices[i][0] = all_indices[i][1]\n",
    "                new_train_features.append(feature)\n",
    "                removed_feature_index.add(feature.example_index)\n",
    "        else:\n",
    "            if all_probs[feature.example_index] > prob_threshold:\n",
    "                feature.start_position, feature.end_position = all_indices[i][0], all_indices[i][1]\n",
    "                new_train_features.append(feature)\n",
    "    return new_train_features, removed_feature_index\n",
    "\n",
    "\n",
    "def compare_performance(args, best_acc, best_f1, acc, f1, model, logger):\n",
    "    if not (best_f1 is None or best_acc is None):\n",
    "        if best_acc < acc:\n",
    "            logger.info('Current model BEATS previous best model, previous best is EM = %.5F, F1 = %.5f',\n",
    "                best_acc, best_f1)\n",
    "            best_acc, best_f1 = acc, f1\n",
    "            logger.info('Current best model has been saved!')\n",
    "            model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
    "            torch.save(model_to_save.state_dict(), os.path.join(args.output_dir, args.output_model_file))\n",
    "        else:\n",
    "            logger.info('Current model CANNOT beat previous best model, previous best is EM = %.5F, F1 = %.5f',\n",
    "                best_acc, best_f1)\n",
    "    else:\n",
    "        best_acc, best_f1 = acc, f1\n",
    "    return best_acc, best_f1\n",
    "\n",
    "\n",
    "def evaluation_stage(args, eval_examples, eval_features, device, model, logger, generate_prob_th=0.6,\n",
    "        removed_feature_index=None, global_step=None, best_acc=None, best_f1=None, generate_label=False):\n",
    "    if not global_step:\n",
    "        logger.info(\"***** Running Evaluation Stage *****\")\n",
    "    else:\n",
    "        logger.info(\"***** Running Predictions *****\")\n",
    "    logger.info(\"  Num orig examples = %d\", len(eval_examples))\n",
    "    logger.info(\"  Num split examples = %d\", len(eval_features))\n",
    "    logger.info(\"  Batch size = %d\", args.predict_batch_size)\n",
    "\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\n",
    "    all_example_index = torch.arange(all_input_ids.size(0), dtype=torch.long)\n",
    "    eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_example_index)\n",
    "    # Run prediction for full data\n",
    "    eval_sampler = SequentialSampler(eval_data)\n",
    "    eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=args.predict_batch_size)\n",
    "\n",
    "    model.eval()\n",
    "    all_results = []\n",
    "    logger.info(\"Start evaluating\")\n",
    "    for input_ids, input_mask, segment_ids, example_indices in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "        input_ids = input_ids.to(device)\n",
    "        input_mask = input_mask.to(device)\n",
    "        segment_ids = segment_ids.to(device)\n",
    "        with torch.no_grad():\n",
    "             batch_start_logits, batch_end_logits, _ = model(input_ids, segment_ids, input_mask)\n",
    "        for i, example_index in enumerate(example_indices):\n",
    "            start_logits = batch_start_logits[i].detach().cpu().tolist()\n",
    "            end_logits = batch_end_logits[i].detach().cpu().tolist()\n",
    "            eval_feature = eval_features[example_index.item()]\n",
    "            unique_id = int(eval_feature.unique_id)\n",
    "            all_results.append(RawResult(unique_id=unique_id,\n",
    "                start_logits=start_logits,\n",
    "                end_logits=end_logits))\n",
    "\n",
    "    if global_step:\n",
    "        prediction_file_name = 'predictions_' + str(global_step) + f'_{datetime.datetime.now().strftime(\"%Y%m%d_%H:%M:%S\")}.json'\n",
    "        nbest_file_name = 'nbest_predictions_' + str(global_step) + f'_{datetime.datetime.now().strftime(\"%Y%m%d_%H:%M:%S\")}.json'\n",
    "        output_prediction_file = os.path.join(args.output_dir, prediction_file_name)\n",
    "        output_nbest_file = os.path.join(args.output_dir, nbest_file_name)\n",
    "    else:\n",
    "        output_prediction_file = os.path.join(args.output_dir, f'predictions_{datetime.datetime.now().strftime(\"%Y%m%d_%H:%M:%S\")}.json')\n",
    "        output_nbest_file = os.path.join(args.output_dir, f'nbest_predictions_{datetime.datetime.now().strftime(\"%Y%m%d_%H:%M:%S\")}.json')\n",
    "    all_predictions, all_probs, all_indices = write_predictions(args, eval_examples, eval_features, all_results,\n",
    "        args.n_best_size, args.max_answer_length,\n",
    "        args.do_lower_case, output_prediction_file,\n",
    "        output_nbest_file, args.verbose_logging, logger, args.output_prediction)\n",
    "    if generate_label:\n",
    "        return keep_high_prob_samples(all_probs, eval_features, generate_prob_th, removed_feature_index, all_indices,\n",
    "                keep_generated=args.keep_previous_generated)\n",
    "    else:\n",
    "        acc, f1 = evaluate_acc_and_f1(all_predictions, eval_examples, logger)\n",
    "        logger.info('Current EM is %.5f, F1 is %.5f', acc, f1)\n",
    "        if not (best_f1 is None or best_acc is None):\n",
    "            best_acc, best_f1 = compare_performance(args, best_acc, best_f1, acc, f1, model, logger)\n",
    "            return best_acc, best_f1\n",
    "        else:\n",
    "            return acc, f1\n",
    "\n",
    "\n",
    "def generate_self_training_samples(args, train_examples, train_features, device, model, removed_feature_index,\n",
    "        new_generated_train_features, generate_prob_th, logger):\n",
    "    '''\n",
    "    타겟 도메인 데이터에서 pseudo-label 생성\n",
    "    '''\n",
    "    logger.info('***** Generating training data for this epoch *****')\n",
    "    if args.keep_previous_generated:\n",
    "        train_features_removed_previous = []\n",
    "        for index in range(len(train_features)):\n",
    "            if index not in removed_feature_index:\n",
    "                train_features_removed_previous.append(train_features[index])\n",
    "    else:\n",
    "        train_features_removed_previous = train_features\n",
    "    cur_train_features, removed_feature_index = \\\n",
    "        evaluation_stage(args, train_examples, train_features_removed_previous, device, model, logger,\n",
    "            removed_feature_index=removed_feature_index, generate_label=True, generate_prob_th=generate_prob_th)\n",
    "    if len(cur_train_features) == 0:\n",
    "        logger.info(\"  No new training samples were generated, training procedure ends\")\n",
    "        return None, None\n",
    "    if args.keep_previous_generated:\n",
    "        new_generated_train_features.extend(cur_train_features)\n",
    "    else:\n",
    "        new_generated_train_features = cur_train_features\n",
    "    return new_generated_train_features, removed_feature_index\n",
    "\n",
    "\n",
    "def get_bert_model_parameters(model):\n",
    "    '''\n",
    "    역할:BERT optimizer 파라미터 그룹 생성 (weight decay 적용/미적용 분리)\n",
    "    반환: optimizer_grouped_parameters\n",
    "    '''\n",
    "    # Prepare optimizer\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "\n",
    "    # hack to remove pooler, which is not used\n",
    "    # thus it produce None grad that break apex\n",
    "    param_optimizer = [n for n in param_optimizer if 'pooler' not in n[0]]\n",
    "\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "    return optimizer_grouped_parameters\n",
    "\n",
    "\n",
    "def comb_adversarial_training_stage(args, target_train_features, target_train_examples, source_train_features,\n",
    "            eval_features, eval_examples, removed_feature_index, new_generated_train_features, model, epoch,\n",
    "            device, best_acc, best_f1, logger):\n",
    "    '''\n",
    "    1. Self-training: 타겟 데이터에서 pseudo-label 생성\n",
    "    2. Question Type Probability 기반 Source-Target 매칭:\n",
    "        타겟 배치의 각 샘플에서 q_type_prob 상위 3개를 추출하여\n",
    "        각 타입에 해당하는 소스 샘플을 샘플링 (타겟 1개 → 소스 3개)\n",
    "    3. Combined Training: 타겟(pseudo) + 소스(labeled) 데이터를 concat하여 학습\n",
    "    '''\n",
    "\n",
    "    def sample_source_batch_top3(source_data, source_q_type_dict, sample_pointer, q_type_probs):\n",
    "        \"\"\"\n",
    "        q_type_probs 기반 상위 3개 타입에서 소스 샘플링\n",
    "        Args:\n",
    "            q_type_probs: [batch_size, 6] 텐서\n",
    "        Returns:\n",
    "            타겟 배치의 최대 3배 크기 소스 배치\n",
    "        \"\"\"\n",
    "        output_idx = []\n",
    "\n",
    "        for q_type_prob in q_type_probs:  # 각 타겟 샘플\n",
    "            # 상위 3개 q_type 인덱스 추출\n",
    "            top3_indices = torch.topk(q_type_prob, k=3).indices.tolist()\n",
    "\n",
    "            for q_type in top3_indices:\n",
    "                # 해당 타입에 소스 샘플이 없으면 스킵\n",
    "                if len(source_q_type_dict[q_type]) == 0:\n",
    "                    continue\n",
    "\n",
    "                next_q_idx = sample_pointer[q_type] % len(source_q_type_dict[q_type])\n",
    "                output_idx.append(source_q_type_dict[q_type][next_q_idx])\n",
    "                sample_pointer[q_type] += 1\n",
    "\n",
    "        input_ids_source, input_masks_source, segment_ids_source, start_positions_source, end_positions_source, \\\n",
    "            q_types_source = [], [], [], [], [], []\n",
    "        for idx in output_idx:\n",
    "            input_ids_source.append(source_data[idx][0].unsqueeze(0))\n",
    "            input_masks_source.append(source_data[idx][1].unsqueeze(0))\n",
    "            segment_ids_source.append(source_data[idx][2].unsqueeze(0))\n",
    "            start_positions_source.append(source_data[idx][3].unsqueeze(0))\n",
    "            end_positions_source.append(source_data[idx][4].unsqueeze(0))\n",
    "            q_types_source.append(source_data[idx][5].unsqueeze(0))\n",
    "\n",
    "        return torch.vstack(input_ids_source), torch.vstack(input_masks_source), torch.vstack(segment_ids_source), \\\n",
    "            torch.cat(start_positions_source, -1), torch.cat(end_positions_source, -1), torch.cat(q_types_source, -1)\n",
    "\n",
    "    # Generate self-training samples\n",
    "    # 1. Pseudo-label 생성\n",
    "    new_generated_train_features, removed_feature_index = generate_self_training_samples(args, target_train_examples,\n",
    "        target_train_features, device, model, removed_feature_index, new_generated_train_features, args.generate_prob_th,\n",
    "        logger)\n",
    "    if new_generated_train_features is None:\n",
    "        sys.exit()\n",
    "    \n",
    "    logger.info('\\n')\n",
    "    logger.info('====================  Start Adversarial Training Stage  ====================')\n",
    "    \n",
    "    # q_type_prob 추출 (데이터에서 가져오기)\n",
    "    all_q_type_probs = []\n",
    "    for f in new_generated_train_features:\n",
    "        # InputFeatures에 q_type_prob가 있는지 확인\n",
    "        if hasattr(f, 'q_type_prob') and f.q_type_prob is not None:\n",
    "            all_q_type_probs.append(f.q_type_prob)\n",
    "        else:\n",
    "            # q_type_prob가 없으면 one-hot 인코딩 사용\n",
    "            prob = [0.0] * 6\n",
    "            prob[f.q_type] = 1.0\n",
    "            all_q_type_probs.append(prob)\n",
    "    \n",
    "    all_input_ids = torch.tensor([f.input_ids for f in new_generated_train_features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in new_generated_train_features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in new_generated_train_features], dtype=torch.long)\n",
    "    all_start_positions = torch.tensor([f.start_position for f in new_generated_train_features], dtype=torch.long)\n",
    "    all_end_positions = torch.tensor([f.end_position for f in new_generated_train_features], dtype=torch.long)\n",
    "    all_q_types = torch.tensor([f.q_type for f in new_generated_train_features], dtype=torch.long)\n",
    "    all_q_type_probs = torch.tensor(all_q_type_probs, dtype=torch.float)\n",
    "    \n",
    "    train_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids,\n",
    "        all_start_positions, all_end_positions, all_q_types, all_q_type_probs)\n",
    "    \n",
    "    source_input_ids = torch.tensor([f.input_ids for f in source_train_features], dtype=torch.long)\n",
    "    source_input_mask = torch.tensor([f.input_mask for f in source_train_features], dtype=torch.long)\n",
    "    source_segment_ids = torch.tensor([f.segment_ids for f in source_train_features], dtype=torch.long)\n",
    "    source_start_positions = torch.tensor([f.start_position for f in source_train_features], dtype=torch.long)\n",
    "    source_end_positions = torch.tensor([f.end_position for f in source_train_features], dtype=torch.long)\n",
    "    source_q_types = []\n",
    "    source_q_type_dict = {\n",
    "        0: [],\n",
    "        1: [],\n",
    "        2: [],\n",
    "        3: [],\n",
    "        4: [],\n",
    "        5: []\n",
    "    }\n",
    "    for idx, f in enumerate(source_train_features):\n",
    "        source_q_types.append(f.q_type)\n",
    "        source_q_type_dict[f.q_type].append(idx)\n",
    "    source_q_types = torch.tensor(source_q_types, dtype=torch.long)\n",
    "    for key in source_q_type_dict.keys():\n",
    "        random.shuffle(source_q_type_dict[key])\n",
    "    sample_pointer = [0] * 6\n",
    "    source_data = TensorDataset(source_input_ids, source_input_mask, source_segment_ids, source_start_positions, \n",
    "        source_end_positions, source_q_types)\n",
    "\n",
    "    train_sampler = BERTRandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=args.train_batch_size)\n",
    "    \n",
    "    data_len = len(new_generated_train_features)\n",
    "    logger.info(\"  Num split examples = %d\", data_len)\n",
    "    logger.info(\"  Batch size = %d\", args.train_batch_size)\n",
    "    num_train_steps = math.ceil(data_len / args.train_batch_size / args.gradient_accumulation_steps)\n",
    "    if num_train_steps == 0 and data_len > 0:\n",
    "        num_train_steps = 1\n",
    "    t_total = num_train_steps\n",
    "    logger.info(\"  Num steps = %d\", num_train_steps)\n",
    "\n",
    "    loss_sum = 0\n",
    "    optimizer_grouped_parameters = get_bert_model_parameters(model)\n",
    "    optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "            lr=args.adapt_learning_rate,\n",
    "            warmup=args.warmup_proportion,\n",
    "            t_total=t_total)\n",
    "    global_step = 0\n",
    "\n",
    "    # 타겟 배치 순회(pseudo-labeling->소스 매칭->결합 학습)\n",
    "    for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\")):\n",
    "        model.train()\n",
    "        # 소스 배치 샘플링 (question type probability 기반 상위 3개)\n",
    "        batch_source = sample_source_batch_top3(source_data, source_q_type_dict, sample_pointer, batch[-1])\n",
    "        batch = tuple(t.to(device) for t in batch[:-1])  # q_type_probs는 제외\n",
    "        batch_source = tuple(t.to(device) for t in batch_source)\n",
    "        input_ids, input_masks, segment_ids, start_positions, end_positions, q_types = batch\n",
    "        input_ids_source, input_masks_source, segment_ids_source, start_positions_source, end_positions_source, q_types_source = batch_source\n",
    "        # 타겟 + 소스 concat\n",
    "        input_ids = torch.cat((input_ids, input_ids_source), 0)\n",
    "        input_masks = torch.cat((input_masks, input_masks_source), 0)\n",
    "        segment_ids = torch.cat((segment_ids, segment_ids_source), 0)\n",
    "        start_positions = torch.cat((start_positions, start_positions_source), 0)\n",
    "        end_positions = torch.cat((end_positions, end_positions_source), 0)\n",
    "        q_types = torch.cat((q_types, q_types_source), 0)\n",
    "        # QC4QA loss 계산 및 역전파\n",
    "        loss = model.forward_ours(input_ids, segment_ids, input_masks, start_positions,\n",
    "                end_positions, q_types, lambda_c=args.lambda_c)\n",
    "        if args.gradient_accumulation_steps > 1:\n",
    "            loss = loss / args.gradient_accumulation_steps\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        if (step + 1) % args.gradient_accumulation_steps == 0:\n",
    "            # modify learning rate with special warm up BERT uses\n",
    "            lr_this_step = args.adapt_learning_rate * warmup_linear(global_step / t_total, args.warmup_proportion)\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr_this_step\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "        \n",
    "    final_acc, final_f1 = None, None\n",
    "    if epoch == args.num_train_epochs - 1:\n",
    "        final_acc, final_f1 = evaluation_stage(args, eval_examples, eval_features, device, model,\n",
    "            global_step=global_step, best_acc=None, best_f1=None, logger=logger)\n",
    "        best_acc, best_f1 = compare_performance(args, best_acc, best_f1, final_acc, final_f1, model, logger)\n",
    "    else:\n",
    "        best_acc, best_f1 = evaluation_stage(args, eval_examples, eval_features, device, model,\n",
    "            global_step=global_step, best_acc=best_acc, best_f1=best_f1, logger=logger)\n",
    "    return best_acc, best_f1, final_acc, final_f1\n",
    "\n",
    "\n",
    "def prepare_model(args, device):\n",
    "    # Source 도메인에서 fine-tuned 모델 로드(run_source.py는 사전학습 모델 로드)\n",
    "    input_model_file = os.path.join(args.input_dir, args.input_model_file)\n",
    "    model_state_dict = torch.load(input_model_file)\n",
    "    model = BertForQuestionAnsweringQC4QA.from_pretrained(args.bert_model, state_dict=model_state_dict, args=args)\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "\n",
    "def adaptation_stage(args, tokenizer, device, logger, debug=True):\n",
    "    '''\n",
    "    역할: 도메인 적응 메인 루프\n",
    "    '''\n",
    "    ### 데이터 수 조절 ### \n",
    "    sample_limit = 100\n",
    "    \n",
    "    model = prepare_model(args, device)\n",
    "    best_acc, best_f1 = 0, 0\n",
    "    \n",
    "    read_limit = None\n",
    "    if debug:\n",
    "        read_limit = 50\n",
    "\n",
    "    ## Read target training examples\n",
    "    logger.info(\"***** Reading Target Unlabeled Training Samples *****\")\n",
    "    train_features, train_examples = read_features_and_examples(args, args.target_train_file, tokenizer, logger,\n",
    "        use_simple_feature=False, read_examples=True, limit=read_limit)\n",
    "\n",
    "    ## Read source training examples\n",
    "    logger.info(\"***** Reading Source Training Samples *****\")\n",
    "    source_train_features, _ = read_features_and_examples(args, args.source_train_file, tokenizer, logger,\n",
    "        use_simple_feature=False, read_examples=True, limit=read_limit)\n",
    "\n",
    "    # Read evaluation samples\n",
    "    logger.info(\"***** Reading Evaluation Samples *****\")\n",
    "    eval_features, eval_examples = read_features_and_examples(args, args.target_predict_file, tokenizer, logger,\n",
    "        use_simple_feature=False, read_examples=True, limit=read_limit)\n",
    "\n",
    "    removed_feature_index = set()\n",
    "    new_generated_train_features = []\n",
    "    final_acc, final_f1 = 0.0, 0.0\n",
    "    for epoch in trange(int(args.num_train_epochs), desc=\"Epoch\"):\n",
    "        logger.info('\\n')\n",
    "        logger.info(' ###########  Start Training Epoch %d  ###########', epoch + 1)\n",
    "        logger.info('\\n')\n",
    "        best_acc, best_f1, final_acc, final_f1 = comb_adversarial_training_stage(args, train_features, train_examples,\n",
    "                source_train_features, eval_features, eval_examples, removed_feature_index, new_generated_train_features,\n",
    "                model, epoch, device, best_acc, best_f1, logger)\n",
    "        logger.info('\\n')\n",
    "        logger.info(' ###########  End Training Epoch %d  ###########', epoch + 1)\n",
    "        logger.info('\\n')\n",
    "\n",
    "    # Save the final trained model\n",
    "    model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
    "    output_model_file = os.path.join(args.output_dir, args.output_model_file + '.final')\n",
    "    torch.save(model_to_save.state_dict(), output_model_file)\n",
    "    logger.info('The final model has been save')\n",
    "    logger.info('*** The Training Stage is Ended ***')\n",
    "    logger.info('\\n\\nBest EM is %.5f. Best F1 is %.5f', best_acc, best_f1)\n",
    "    logger.info('\\n\\nFinal EM is %.5f. Best F1 is %.5f', final_acc, final_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b504532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# argument parsing\n",
    "args = argparse.Namespace(\n",
    "    debug = True, # sample_limit 사이즈로 디버깅\n",
    "    bert_model='bert-base-uncased',\n",
    "    do_adaptation=True,\n",
    "    do_predict=False,\n",
    "    do_lower_case=True,\n",
    "    source_train_file=\"../../data/squad/train-v1.1_classified_qtype_prob.jsonl\",\n",
    "    target_train_file=\"../../data/cnn/cnn_train_classified_qtype_prob.jsonl\",\n",
    "    target_predict_file=\"../../data/cnn/cnn_dev.json\",\n",
    "    input_dir=\"../../model/fine_tuning\",\n",
    "    input_model_file=\"ft_squad_1105_1314.bin\",\n",
    "    output_dir=\"../../model/adapt\",\n",
    "    output_model_file=\"squad2cnn_1105.bin\",\n",
    "    logger_path=\"../../logs/adapt/squad2cnn\",\n",
    "    max_seq_length=512,\n",
    "    seed=42,\n",
    "    gradient_accumulation_steps=1,\n",
    "    train_batch_size=4,\n",
    "    predict_batch_size=12,\n",
    "    num_workers=4,\n",
    "    evaluation_interval=2000,\n",
    "    loss_logging_interval=500,\n",
    "    train_learning_rate=3e-5,\n",
    "    num_train_epochs=2,\n",
    "    warmup_proportion=0.1,\n",
    "    n_best_size=20,\n",
    "    max_answer_length=30,\n",
    "    verbose_logging=False,\n",
    "    use_simple_feature=False,\n",
    "    generate_prob_th=0.6,\n",
    "    keep_previous_generated=False,\n",
    "    use_BN=True,\n",
    "    output_prediction=True,\n",
    "    source_sampling_ratio=3,\n",
    "    doc_stride=128,\n",
    "    max_query_length=64,\n",
    "    adapt_learning_rate=1e-5,\n",
    "    lambda_c=0.1,\n",
    "    sample_limit= 100  ### 디버깅용 데이터셋 크기\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9468b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/05/2025 15:45:14 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/gayeon43/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = cuda\n"
     ]
    }
   ],
   "source": [
    "# 3) 로거/디바이스/토크나이저 준비\n",
    "logger = config_logger(args.logger_path)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = BertTokenizer.from_pretrained(args.bert_model, do_lower_case=args.do_lower_case)\n",
    "print(f\"device = {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e6e9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) 입력 모델 로드 및 적응 단계 실행\n",
    "model = prepare_model(args, device)\n",
    "adaptation_stage(args, tokenizer, device, logger, debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "da",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
